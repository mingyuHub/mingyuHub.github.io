<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>但行好事 莫问前程</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="但行好事 莫问前程">
<meta property="og:url" content="https://chenmingyu.top/page/2/index.html">
<meta property="og:site_name" content="但行好事 莫问前程">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="陈明羽">
<meta property="article:tag" content="陈明羽">
<meta property="article:tag" content="chenmingyu">
<meta property="article:tag" content="java">
<meta property="article:tag" content="架构">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="但行好事 莫问前程" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">但行好事 莫问前程</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">明羽</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://chenmingyu.top"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-java-exception" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/java-exception/" class="article-date">
  <time datetime="2019-08-21T10:20:26.000Z" itemprop="datePublished">2019-08-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/java-exception/">java异常体系</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>异常是一个在程序执行期间发生的事件，它中断正在执行的程序的正常指令流。为了能够及时有效地处理程序中的运行错误，必须使用异常类</p>
<p>异常类如果使用正确，可以提高程序的可读性，可靠性和可维护性，如果使用不当会带来负面效果</p>
<p><strong>java异常体系</strong></p>
<p>Java 异常强制用户考虑程序的强健性和安全性。异常处理不应用来控制程序的正常流程，其主要作用是捕获程序在运行时发生的异常并进行相应处理</p>
<p><img src="java-exception/throwable.png" alt=""></p>
<p> java中所有的异常类型都是 <strong>java.lang.Throwable</strong>的子类，分为两种类型<strong>Error错误</strong>和<strong>Exception异常</strong></p>
<p><strong>Error</strong></p>
<p>程序中无法处理的错误，表示运行应用程序中出现了严重的错误，出现此类异常，JVM将终止线程</p>
<p>比如：</p>
<p><strong>Exception</strong></p>
<ul>
<li><p><strong>运行时异常</strong>：</p>
<p>此类异常实现都是RuntimeException类及其子类</p>
<p>运行时异常不必在代码中强制进行try-catch</p>
<p>这类异常通常由程序逻辑错误引起，应尽量避免此类异常的发生</p>
</li>
<li><p><strong>非运行时异常</strong></p>
<p>除了运行时异常外，继承了Exception的异常类</p>
<p>非运行时异常必须要在程序中进行try-catch，如果不处理，则程序编译不通过</p>
</li>
</ul>
<p><strong>自定义异常</strong></p>
<p>自定义异常需要继承Exception类</p>
<pre><code class="java">public class WarnException extends Exception {

    public WarnException(String message) {
        super(message);
    }
}</code></pre>
<p>测试：</p>
<pre><code class="java">public static void test() throws WarnException{
    try {
         int i= 1/0;
    }catch (Exception e){
        throw new WarnException(&quot;自定义异常&quot;);
    }
}</code></pre>
<p>异常信息：</p>
<p><img src="java-exception/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BC%82%E5%B8%B8.png" alt=""></p>
<p><strong>异常处理流程</strong></p>
<p>捕获异常：</p>
<pre><code class="java">try {

} catch (Exception e) {
    e.printStackTrace();
} finally {
}</code></pre>
<ul>
<li><p>执行流程：</p>
<p>正常try-catch中无异常时：执行顺序是try - finally</p>
<p>正常try-catch中有异常时：执行顺序是try - catch - finally</p>
</li>
</ul>
<p>捕获多重异常：</p>
<pre><code class="java">try{

}catch(WarnException we){

}catch(Exception e){

}finally{

}</code></pre>
<p>try代码块后跟多个catch代码块，这种情况就叫<strong>多重捕获</strong></p>
<p>抛出异常：</p>
<pre><code class="java">public static void test() throws WarnException{
    try {
         int i= 1/0;
    }catch (Exception e){
        throw new WarnException(&quot;自定义异常&quot;);
    }
}</code></pre>
<p>在方法上抛出异常使用<strong>throws</strong>关键字，如果一个方法没有捕获一个检查性异常，那么该方法必须使用 <strong>throws</strong> 关键字来抛出这个异常</p>
<p>在方法内抛出异常使用<strong>throw</strong>关键字</p>
<p><strong>常见异常</strong></p>
<p>Error：</p>
<ul>
<li>NoClassDefFoundError：类定义错误</li>
<li>OutOfMemoryError：内存溢出错误</li>
<li>StackOverflowError：堆栈溢出错误</li>
<li>UnknownError：未知错误</li>
</ul>
<p>RuntimeException/运行时异常：</p>
<ul>
<li>NullPointerException：空指针异常</li>
<li>NumberFormatException：数字格式异常</li>
<li>ClassCastException：类型转换异常</li>
<li>IndexOutOfBoundsException：索引越界异常</li>
</ul>
<p>非运行时异常：</p>
<ul>
<li>IOException：IO异常</li>
<li>SQLException：sql异常</li>
<li>FileNotFoundException：文件找不到异常</li>
<li>ClassNotFoundException：找不到类异常</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/java-exception/" data-id="ckdn6w7zw0038aktw3iiu3d3n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8/" rel="tag">异常</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-nio" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/nio/" class="article-date">
  <time datetime="2019-08-17T07:35:03.000Z" itemprop="datePublished">2019-08-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/nio/">一文看懂java io系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>学习java IO系统，重点是学会IO模型，了解了各种IO模型之后就可以更好的理解java IO</p>
</blockquote>
<p>Java IO 是一套Java用来读写数据（输入和输出）的API。大部分程序都要处理一些输入，并由输入产生一些输出。Java为此提供了java.io包</p>
<p>java中io系统可以分为Bio，Nio，Aio三种io模型</p>
<ol>
<li>关于Bio，我们需要知道什么是同步阻塞IO模型，Bio操作的对象：流，以及如何使用Bio进行网络编程，使用Bio进行网络编程的问题</li>
<li>关于Nio，我们需要知道什么是同步非阻塞IO模型，什么是多路复用Io模型，以及Nio中的Buffer,Channel,Selector的概念，以及如何使用Nio进行网络编程</li>
<li>关于Aio，我们需要知道什么是异步非阻塞IO模型，Aio可以使用几种方式实现异步操作，以及如何使用Aio进行网络编程</li>
</ol>
<h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>BIO是同步阻塞IO，JDK1.4之前只有这一个IO模型，BIO操作的对象是流，一个线程只能处理一个流的IO请求，如果想要同时处理多个流就需要使用多线程</p>
<p>流包括字符流和字节流，流从概念上来说是一个连续的数据流。当程序需要读数据的时候就需要使用输入流读取数据，当需要往外写数据的时候就需要输出流</p>
<h4 id="阻塞IO模型"><a href="#阻塞IO模型" class="headerlink" title="阻塞IO模型"></a>阻塞IO模型</h4><p><img src="nio/bio%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<p>在Linux中，当应用进程调用<strong>recvfrom</strong>方法调用数据的时候，如果内核没有把数据准备好不会立刻返回，而是会经历等待数据准备就绪，数据从内核复制到用户空间之后再返回，这期间应用进程一直阻塞直到返回，所以被称为阻塞IO模型</p>
<h4 id="流"><a href="#流" class="headerlink" title="流"></a>流</h4><p>BIO中操作的流主要有两大类，字节流和字符流，两类根据流的方向都可以分为输入流和输出流</p>
<p>按照类型和输入输出方向可分为：</p>
<ol>
<li>输入字节流：InputStream</li>
<li>输出字节流：OutputStream</li>
<li>输入字符流：Reader</li>
<li>输出字符流：Writer</li>
</ol>
<p>字节流主要用来处理字节或二进制对象，字符流用来处理字符文本或字符串</p>
<p>使用<code>InputStreamReader</code>可以将输入字节流转化为输入字符流</p>
<pre><code class="java">Reader reader  =  new InputStreamReader(inputStream);</code></pre>
<p>使用<code>OutputStreamWriter</code>可以将输出字节流转化为输出字符流</p>
<pre><code>Writer writer = new OutputStreamWriter(outputStream)</code></pre><p>我们可以在程序中通过InputStream和Reader从数据源中读取数据，然后也可以在程序中将数据通过OutputStream和Writer输出到目标媒介中</p>
<p><img src="nio/1.png" alt=""></p>
<p>在使用字节流的时候，InputStream和OutputStream都是抽象类，我们实例化的都是他们的子类，每一个子类都有自己的作用范围</p>
<p><img src="nio/%E5%AD%97%E8%8A%82%E6%B5%81.png" alt="图是网上的，侵删"></p>
<p>在使用字符流的时候也是，Reader和Writer都是抽象类，我们实例化的都是他们的子类，每一个子类都有自己的作用范围</p>
<p><img src="nio/%E5%AD%97%E7%AC%A6%E6%B5%81.png" alt="图是网上的，侵删"></p>
<p><strong>以读写文件为例</strong></p>
<p>从数据源中读取数据</p>
<p>输入字节流：<strong>InputStream</strong></p>
<pre><code class="java">public static void main(String[] args) throws Exception{
    File file = new File(&quot;D:/a.txt&quot;);
    InputStream inputStream = new FileInputStream(file);
    byte[] bytes = new byte[(int) file.length()];
    inputStream.read(bytes);
    System.out.println(new String(bytes));
    inputStream.close();
}</code></pre>
<p>输入字符流：<strong>Reader</strong></p>
<pre><code class="java">public static void main(String[] args) throws Exception{
    File file = new File(&quot;D:/a.txt&quot;);
    Reader reader = new FileReader(file);
    char[] bytes = new char[(int) file.length()];
    reader.read(bytes);
    System.out.println(new String(bytes));
    reader.close();
}</code></pre>
<p>输出到目标媒介</p>
<p>输出字节流：<strong>OutputStream</strong></p>
<pre><code class="java">public static void main(String[] args) throws Exception{
    String var = &quot;hai this is a test&quot;;
    File file = new File(&quot;D:/b.txt&quot;);
    OutputStream outputStream = new FileOutputStream(file);
    outputStream.write(var.getBytes());
    outputStream.close();
}</code></pre>
<p>输出字符流：<strong>Writer</strong></p>
<pre><code class="java">public static void main(String[] args) throws Exception{
    String var = &quot;hai this is a test&quot;;
    File file = new File(&quot;D:/b.txt&quot;);
    Writer writer = new FileWriter(file);
    writer.write(var);
    writer.close();
}</code></pre>
<p><strong>BufferedInputStream</strong></p>
<p>在使用InputStream的时候，都是一个字节一个字节的读或写，而BufferedInputStream为输入字节流提供了缓冲区，读数据的时候会一次读取一块数据放到缓冲区里，当缓冲区里的数据被读完之后，输入流会再次填充数据缓冲区，直到输入流被读完，有了缓冲区就能够提高很多io速度</p>
<p>使用方式将输入流包装到BufferedInputStream中</p>
<pre><code class="java">/**
 * inputStream 输入流
 * 1024 内部缓冲区大小为1024byte
 */
BufferedInputStream bufferedInputStream = new BufferedInputStream(inputStream,1024);</code></pre>
<p><strong>BufferedOutputStream</strong></p>
<p>BufferedOutputStream可以为输出字节流提供缓冲区，作用与BufferedInputStream类似</p>
<p>使用方式将输出流包装到BufferedOutputStream中</p>
<pre><code class="java">/**
 * outputStream 输出流
 * 1024 内部缓冲区大小为1024byte
 */
BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(outputStream,1024);</code></pre>
<p>字节流提供了带缓冲区的，那字符流肯定也提供了BufferedReader和BufferedWriter</p>
<p><strong>BufferedReader</strong></p>
<p>为输入字符流提供缓冲区，使用方式如下</p>
<pre><code class="java">BufferedReader bufferedReader = new BufferedReader(reader,1024);</code></pre>
<p><strong>BufferedWriter</strong></p>
<p>为输出字符流提供缓冲区，使用方式如下</p>
<pre><code class="java">BufferedWriter bufferedWriter = new BufferedWriter(writer,1024);</code></pre>
<h4 id="BIO模型-网络编程"><a href="#BIO模型-网络编程" class="headerlink" title="BIO模型 网络编程"></a>BIO模型 网络编程</h4><p>当使用BIO模型进行Socket编程的时候，服务端通常使用while循环中调用accept方法，在没有客户端请求时，accept方法会一直阻塞，直到接收到请求并返回处理的相应，这个过程都是线性的，只有处理完当前的请求之后才会接受处理后面的请求，这样通常会导致通信线程被长时间阻塞</p>
<p>BIO模型处理多个连接： </p>
<p><img src="nio/bio%E7%BA%BF%E7%A8%8B.png" alt=""></p>
<p>在这种模式中我们通常用一个线程去接受请求，然后用一个线程池去处理请求，用这种方式并发管理多个Socket客户端连接，像这样：</p>
<p><img src="nio/BIO%E7%BA%BF%E7%A8%8B+%E7%BA%BF%E7%A8%8B%E6%B1%A0.png" alt=""></p>
<p>使用BIO模型进行网络编程的问题在于缺乏弹性伸缩能力，客户端并发访问数量和服务器线程数量是1:1的关系，而且平时由于阻塞会有大量的线程处于等待状态，等待输入或者输出数据就绪，造成资源浪费，在面对大量并发的情况下，如果不使用线程池直接new线程的话，就会大致线程膨胀，系统性能下降，有可能导致堆栈的内存溢出，而且频繁的创建销毁线程，更浪费资源</p>
<p>使用线程池可能是更优一点的方案，但是无法解决阻塞IO的阻塞问题，而且还需要考虑如果线程池的数量设置较小就会拒绝大量的Socket客户端的连接，如果线程池数量设置较大的时候，会导致大量的上下文切换，而且程序要为每个线程的调用栈都分配内存，其默认值大小区间为 64 KB 到 1 MB，浪费虚拟机内存</p>
<p>BIO模型适用于链接数目固定而且比较少的架构，但是使用这种模型写的代码更直观简单易于理解</p>
<h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p>JDK 1.4版本以来，JDK发布了全新的I/O类库，简称NIO，是一种同步非阻塞IO模型</p>
<h4 id="非阻塞IO模型"><a href="#非阻塞IO模型" class="headerlink" title="非阻塞IO模型"></a>非阻塞IO模型</h4><p>同步非阻塞IO模型实现：</p>
<p><strong>非阻塞IO模型</strong></p>
<p><img src="nio/%E9%9D%9E%E9%98%BB%E5%A1%9EIO%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<p>应用进程调用<strong>recvfrom</strong>系统调用，如果内核数据没有准备好，会直接返回一个EWOULDBLOCK错误，应用进程不会阻塞，但是需要应用进程不断的轮询调用<strong>recvfrom</strong>，直到内核数据准备就绪，之后等待数据从内核复制到用户空间（这段时间会阻塞，但是耗时极小），复制完成后返回</p>
<p><strong>IO复用模型</strong></p>
<p><img src="nio/IO%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<p>IO复用模型，利用Linux系统提供的<strong>select，poll</strong>系统调用，将一个或者多个文件句柄（网络编程中的客户端链接）传递给select或者poll系统调用，应用进程阻塞在select上，这样就形成了一个进程对应多个Socket链接，然后select/poll会线性扫描这个Socket链接的集合，当只有少数socket有数据的时候，会导致效率下降，而且select/poll受限于所持有的文件句柄数量，默认值是1024个</p>
<p><strong>信号驱动 IO模型</strong></p>
<p><img src="nio/%E4%BF%A1%E5%8F%B7%E9%A9%B1%E5%8A%A8IO%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<p>系统调用sigaction执行一个信号处理函数，这个系统调用不会阻塞应用进程，当数据准备就绪的时候，就为该进程生成一个SIGIO信号，通过信号回调通知应用程序调用recvfrom来读取数据</p>
<h4 id="NIO的核心概念"><a href="#NIO的核心概念" class="headerlink" title="NIO的核心概念"></a>NIO的核心概念</h4><p><strong>Buffer</strong>（缓冲区）</p>
<p>Buffer是一个对象，它包含一些要写入或者读出的数据，在NIO中所有数据都是用缓存区处理的，在读数据的时候要从缓冲区中读，写数据的时候会先写到缓冲区中，缓冲区本质上是一块可以写入数据，然后可以从中读取数据的一个数组，提供了对数据的结构化访问以及在内部维护了读写位置等信息</p>
<p>实例化一个ByteBuffer</p>
<pre><code class="java">//创建一个容量为1024个byte的缓冲区
ByteBuffer buffer=ByteBuffer.allocate(1024);</code></pre>
<p>如何使用Buffer：</p>
<ol>
<li>写入数据到Buffer</li>
<li>调用<code>flip()</code>方法将Buffer从写模式切换到读模式</li>
<li>从Buffer中读取数据</li>
<li>调用<code>clear()</code>方法或者<code>compact()</code>方法清空缓冲区，让它可以再次被写入</li>
</ol>
<p>更多详细信息看这个：<a href="http://ifeve.com/buffers/" target="_blank" rel="noopener">http://ifeve.com/buffers/</a></p>
<p><strong>Channel</strong>（通道）</p>
<p>Channel（通道）数据总是从通道读取到缓冲区，或者从缓冲区写入到通道中，Channel只负责运输数据，而操作数据是Buffer</p>
<p>通道与流类似，不同地方:</p>
<ol>
<li>在于条通道是双向的，可以同时进行读，写操作，而流是单向流动的，只能写入或者读取</li>
<li>流的读写是阻塞的，通道可以异步读写</li>
</ol>
<p><img src="nio/overview-channels-buffers.png" alt=""></p>
<p>数据从Channel读到Buffer</p>
<pre><code class="java">inChannel.read(buffer);</code></pre>
<p>数据从Buffer写到Channel</p>
<pre><code class="java">outChannel.write(buffer);</code></pre>
<p>更多详细信息看这个：&lt;<a href="http://ifeve.com/channels/" target="_blank" rel="noopener">http://ifeve.com/channels/</a>&gt;</p>
<p><strong>以复制文件为例</strong></p>
<pre><code class="java">FileInputStream fileInputStream=new FileInputStream(new File(src));
FileOutputStream fileOutputStream=new FileOutputStream(new File(dst));
//获取输入输出channel通道
FileChannel inChannel=fileInputStream.getChannel();
FileChannel outChannel=fileOutputStream.getChannel();
//创建容量为1024个byte的buffer
ByteBuffer buffer=ByteBuffer.allocate(1024);
while(true){
    //从inChannel里读数据，如果读不到字节了就返回-1，文件就读完了
    int eof =inChannel.read(buffer);
    if(eof==-1){
        break;
    }
    //将Buffer从写模式切换到读模式
    buffer.flip();
    //开始往outChannel写数据
    outChannel.write(buffer);
    //清空buffer
    buffer.clear();
}
inChannel.close();
outChannel.close();
fileInputStream.close();
fileOutputStream.close();</code></pre>
<p><strong>Selector</strong>（多路复用选择器）</p>
<p>Selector是NIO编程的基础，主要作用就是将多个Channel注册到Selector上，如果Channel上发生读或写事件，Channel就处于就绪状态，就会被Selector轮询出来，然后通过SelectionKey就可以获取到已经就绪的Channel集合，进行IO操作了</p>
<p>Selector与Channel，Buffer之间的关系</p>
<p><img src="nio/Selector.png" alt=""></p>
<p>更多详细信息看这个：&lt;<a href="http://ifeve.com/selectors/" target="_blank" rel="noopener">http://ifeve.com/selectors/</a></p>
<h4 id="NIO模型-网络编程"><a href="#NIO模型-网络编程" class="headerlink" title="NIO模型 网络编程"></a>NIO模型 网络编程</h4><p>JDK中NIO使用多路复用的IO模型，通过把多个IO阻塞复用到一个select的阻塞上，实现系统在单线程中可以同时处理多个客户端请求，节省系统开销，在JDK1.4和1.5 update10版本之前，JDK的Selector基于select/poll模型实现，在JDK 1.5 update10以上的版本，底层使用epoll代替了select/poll</p>
<p>epoll较select/poll的优点在于：</p>
<ol>
<li>epoll支持打开的文件描述符数量不在受限制，select/poll可以打开的文件描述符数量有限</li>
<li>select/poll使用轮询方式遍历整个文件描述符的集合，epoll基于每个文件描述符的callback函数回调</li>
</ol>
<p><strong>select，poll，epoll</strong>都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写</p>
<p>NIO提供了两套不同的套接字通道实现网络编程，服务端：ServerSocketChannel和客户端SocketChannel，两种通道都支持阻塞和非阻塞模式</p>
<p><strong>服务端代码</strong></p>
<p>服务端接受客户端发送的消息输出，并给客户端发送一个消息</p>
<pre><code class="java">        //创建多路复用选择器Selector
        Selector selector=Selector.open();
        //创建一个通道对象Channel，监听9001端口
        ServerSocketChannel channel = ServerSocketChannel.open().bind(new InetSocketAddress(9001));
        //设置channel为非阻塞
        channel.configureBlocking(false);
        //
        /**
         * 1.SelectionKey.OP_CONNECT：连接事件
         * 2.SelectionKey.OP_ACCEPT：接收事件
         * 3.SelectionKey.OP_READ：读事件
         * 4.SelectionKey.OP_WRITE：写事件
         *
         * 将channel绑定到selector上并注册OP_ACCEPT事件
         */
        channel.register(selector,SelectionKey.OP_ACCEPT);

        while (true){
            //只有当OP_ACCEPT事件到达时，selector.select()会返回（一个key），如果该事件没到达会一直阻塞
            selector.select();
            //当有事件到达了，select()不在阻塞，然后selector.selectedKeys()会取到已经到达事件的SelectionKey集合
            Set keys = selector.selectedKeys();
            Iterator iterator = keys.iterator();
            while (iterator.hasNext()){
                SelectionKey key = (SelectionKey) iterator.next();
                //删除这个SelectionKey，防止下次select方法返回已处理过的通道
                iterator.remove();
                //根据SelectionKey状态判断
                if (key.isConnectable()){
                    //连接成功
                } else if (key.isAcceptable()){
                    /**
                     * 接受客户端请求
                     *
                     * 因为我们只注册了OP_ACCEPT事件，所以有客户端链接上，只会走到这
                     * 我们要做的就是去读取客户端的数据，所以我们需要根据SelectionKey获取到serverChannel
                     * 根据serverChannel获取到客户端Channel，然后为其再注册一个OP_READ事件
                     */
                    // 1，获取到ServerSocketChannel
                    ServerSocketChannel serverChannel = (ServerSocketChannel) key.channel();
                    // 2，因为已经确定有事件到达，所以accept()方法不会阻塞
                    SocketChannel clientChannel = serverChannel.accept();
                    // 3，设置channel为非阻塞
                    clientChannel.configureBlocking(false);
                    // 4，注册OP_READ事件
                    clientChannel.register(key.selector(),SelectionKey.OP_READ);
                } else if (key.isReadable()){
                    // 通道可以读数据
                    /**
                     * 因为客户端连上服务器之后，注册了一个OP_READ事件发送了一些数据
                     * 所以首先还是需要先获取到clientChannel
                     * 然后通过Buffer读取clientChannel的数据
                     */
                    SocketChannel clientChannel = (SocketChannel) key.channel();
                    ByteBuffer byteBuffer = ByteBuffer.allocate(BUF_SIZE);
                    long bytesRead = clientChannel.read(byteBuffer);
                    while (bytesRead&gt;0){
                        byteBuffer.flip();
                        System.out.println(&quot;client data ：&quot;+new String(byteBuffer.array()));
                        byteBuffer.clear();
                        bytesRead = clientChannel.read(byteBuffer);
                    }

                    /**
                     * 我们服务端收到信息之后，我们再给客户端发送一个数据
                     */
                    byteBuffer.clear();
                    byteBuffer.put(&quot;客户端你好，我是服务端，你看这NIO多难&quot;.getBytes(&quot;UTF-8&quot;));
                    byteBuffer.flip();
                    clientChannel.write(byteBuffer);
                } else if (key.isWritable() &amp;&amp; key.isValid()){
                    //通道可以写数据
                }

            }
        }</code></pre>
<p><strong>客户端代码</strong></p>
<p>客户端连接上服务端后，先给服务端发送一个消息，并接受服务端发送的消息</p>
<pre><code class="java">Selector selector = Selector.open();
SocketChannel clientChannel = SocketChannel.open();
//将channel设置为非阻塞
clientChannel.configureBlocking(false);
//连接服务器
clientChannel.connect(new InetSocketAddress(9001));
//注册OP_CONNECT事件
clientChannel.register(selector, SelectionKey.OP_CONNECT);
while (true){
    //如果事件没到达就一直阻塞着
    selector.select();
    Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();
    while (iterator.hasNext()){
        SelectionKey key = iterator.next();
        iterator.remove();
        if (key.isConnectable()){
            /**
             * 连接服务器端成功
             *
             * 首先获取到clientChannel，然后通过Buffer写入数据，然后为clientChannel注册OP_READ时间
             */
            clientChannel = (SocketChannel) key.channel();
            if (clientChannel.isConnectionPending()){
                clientChannel.finishConnect();
            }
            clientChannel.configureBlocking(false);
            ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
            byteBuffer.clear();
            byteBuffer.put(&quot;服务端你好，我是客户端，你看这NIO难吗&quot;.getBytes(&quot;UTF-8&quot;));
            byteBuffer.flip();
            clientChannel.write(byteBuffer);
            clientChannel.register(key.selector(),SelectionKey.OP_READ);
        } else if (key.isReadable()){
            //通道可以读数据
            clientChannel = (SocketChannel) key.channel();
            ByteBuffer byteBuffer = ByteBuffer.allocate(BUF_SIZE);
            long bytesRead = clientChannel.read(byteBuffer);
            while (bytesRead&gt;0){
                byteBuffer.flip();
                System.out.println(&quot;server data ：&quot;+new String(byteBuffer.array()));
                byteBuffer.clear();
                bytesRead = clientChannel.read(byteBuffer);
            }
        } else if (key.isWritable() &amp;&amp; key.isValid()){
            //通道可以写数据
        }
    }
}</code></pre>
<p>使用原生NIO类库十分复杂，NIO的类库和Api繁杂，使用麻烦，需要对网络编程十分熟悉，才能编写出高质量的NIO程序，所以并不建议直接使用原生NIO进行网络编程，而是使用一些成熟的框架，比如Netty</p>
<h3 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h3><p>JDK1.7升级了Nio类库，成为Nio2.0，最主要的是提供了异步文件的IO操作，以及事件驱动IO，AIO的异步套接字通道是真正的异步非阻塞IO</p>
<h4 id="异步IO模型"><a href="#异步IO模型" class="headerlink" title="异步IO模型"></a>异步IO模型</h4><p><img src="nio/%E5%BC%82%E6%AD%A5IO%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<p>在Linux系统中，应用进程发起read操作，立刻可以去做其他的事，内核会将数据准备好并且复制到用空间后告诉应用进程，数据已经复制完成read操作</p>
<h4 id="aio模型-网络编程"><a href="#aio模型-网络编程" class="headerlink" title="aio模型 网络编程"></a>aio模型 网络编程</h4><p><strong>异步操作</strong></p>
<p>aio不需要通过多路复用器对注册的通道进行轮询操作就可以实现异步读写，从而简化了NIO的编程模型</p>
<p>aio通过异步通道实现异步操作，异步通道提供了两种方式获取操作结果：</p>
<ol>
<li>通过Future类来获取异步操作的结果，不过要注意的是future.get()是阻塞方法，会阻塞线程</li>
<li>通过回调的方式进行异步，通过传入一个CompletionHandler的实现类进行回调，CompletionHandler定义了两个方法，completed和failed两方法分别对应成功和失败</li>
</ol>
<p>Aio中的Channel都支持以上两种方式</p>
<p>AIO提供了对应的异步套接字通道实现网络编程，服务端：AsynchronousServerSocketChannel和客户端AsynchronousSocketChannel </p>
<p><strong>服务端</strong></p>
<p>服务端向客户端发送消息，并接受客户端发送的消息</p>
<pre><code class="java">AsynchronousServerSocketChannel server = AsynchronousServerSocketChannel.open().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 9001));
//异步接受请求
server.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Void&gt;() {
    //成功时
    @Override
    public void completed(AsynchronousSocketChannel result, Void attachment) {
        try {
            ByteBuffer buffer = ByteBuffer.allocate(1024);
            buffer.put(&quot;我是服务端，客户端你好&quot;.getBytes());
            buffer.flip();
            result.write(buffer, null, new CompletionHandler&lt;Integer, Void&gt;(){
                @Override
                public void completed(Integer result, Void attachment) {
                    System.out.println(&quot;服务端发送消息成功&quot;);
                }

                @Override
                public void failed(Throwable exc, Void attachment) {
                    System.out.println(&quot;发送失败&quot;);
                }
            });

            ByteBuffer readBuffer = ByteBuffer.allocate(1024);
            result.read(readBuffer, null, new CompletionHandler&lt;Integer, Void&gt;() {
                //成功时调用
                @Override
                public void completed(Integer result, Void attachment) {
                    System.out.println(new String(readBuffer.array()));
                }
                //失败时调用
                @Override
                public void failed(Throwable exc, Void attachment) {
                    System.out.println(&quot;读取失败&quot;);
                }
            });

        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    //失败时
    @Override
    public void failed(Throwable exc, Void attachment) {
        exc.printStackTrace();
    }
});
//防止线程执行完
TimeUnit.SECONDS.sleep(1000L);</code></pre>
<p><strong>客户端</strong></p>
<p>客户端向服务端发送消息，并接受服务端发送的消息</p>
<pre><code class="java">AsynchronousSocketChannel client = AsynchronousSocketChannel.open();
Future&lt;Void&gt; future = client.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 9001));
//阻塞，获取连接
future.get();

ByteBuffer buffer = ByteBuffer.allocate(1024);
//读数据
client.read(buffer, null, new CompletionHandler&lt;Integer, Void&gt;() {
    //成功时调用
    @Override
    public void completed(Integer result, Void attachment) {
        System.out.println(new String(buffer.array()));
    }
    //失败时调用
    @Override
    public void failed(Throwable exc, Void attachment) {
        System.out.println(&quot;客户端接收消息失败&quot;);
    }
});

ByteBuffer writeBuffer = ByteBuffer.allocate(1024);
writeBuffer.put(&quot;我是客户端，服务端你好&quot;.getBytes());
writeBuffer.flip();
//阻塞方法
Future&lt;Integer&gt; write = client.write(writeBuffer);
Integer r = write.get();
if(r&gt;0){
    System.out.println(&quot;客户端消息发送成功&quot;);
}
//休眠线程
TimeUnit.SECONDS.sleep(1000L);</code></pre>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>各IO模型对比：</p>
<p><img src="nio/%E5%90%84IO%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.png" alt=""></p>
<p><em>伪异步IO是指使用线程池处理请求的Bio模型</em></p>
<p>参考：</p>
<p>netty权威指南 第二版</p>
<p><a href="http://ifeve.com/java-nio-all/" target="_blank" rel="noopener">http://ifeve.com/java-nio-all/</a> 并发编程网</p>
<p><a href="https://tech.meituan.com/2016/11/04/nio.html" target="_blank" rel="noopener">https://tech.meituan.com/2016/11/04/nio.html</a> 美团技术团队</p>
<p><em>文中图片如有侵权，联系我删除</em></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/nio/" data-id="ckdn6w80q0044aktw1qhi6ewl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/io/" rel="tag">io</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nio/" rel="tag">nio</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-java-collection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/java-collection/" class="article-date">
  <time datetime="2019-08-16T02:23:48.000Z" itemprop="datePublished">2019-08-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/java-collection/">深入java集合体系</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>java中为了方便操作多个对象，需要将它们存放到一个容器中，这个容器就是集合类</p>
<p>集合类提供了丰富的api来简化我们的编程，对于多个元素我们可能会有不同的需求，为此提供了多种集合类，底层数据结构包括数组，链表，队列，栈，哈希表等，所有我们就可以根据不同的需求选择合理的集合类进行解决</p>
<p>集合类作为容器类可以存储任何类型的数据（存储对象的引用），无法存储基础类型，对于基础类型需要将其包装为包装类在进行存储，底层实现使用数组的集合类支持动态扩容</p>
<p>java中的集合类都在java.util包中，可分为Collection集合和Map映射两种</p>
<h3 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h3><p>实现Collection接口的集合类主要包括：List，Set，Queue</p>
<p><img src="java-collection/collection.png" alt=""></p>
<h4 id="List集合"><a href="#List集合" class="headerlink" title="List集合"></a>List集合</h4><p>有序列表，可以存储重复数据</p>
<h5 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h5><p>那基于数组实现，所以随机访问快，增删慢（需要移动数据），线程不安全</p>
<p><img src="java-collection/ArrayList.png" alt=""></p>
<p>ArrayList实现过程不难</p>
<p>我们看一下<strong>添加元素</strong>的时候如何进行扩容</p>
<pre><code class="java">public boolean add(E e) {
    //扩容方法
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}

private void ensureCapacityInternal(int minCapacity) {
    //如果数组是空的，使用默认初始容量 10
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    //扩容
    ensureExplicitCapacity(minCapacity);
}
private void ensureExplicitCapacity(int minCapacity) {
    modCount++;
    // overflow-conscious code
    if (minCapacity - elementData.length &gt; 0)
        grow(minCapacity);
}
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    // 新的数组容量扩充为原来的1.5倍
    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);
    if (newCapacity - minCapacity &lt; 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
        newCapacity = hugeCapacity(minCapacity);
    // 调用System.arraycopy方法进行扩容
    elementData = Arrays.copyOf(elementData, newCapacity);
}</code></pre>
<p>默认扩容的大小为原来的1.5倍</p>
<p><strong>删除方法</strong></p>
<pre><code class="java">public E remove(int index) {
    rangeCheck(index);

    modCount++;
    E oldValue = elementData(index);

    int numMoved = size - index - 1;
    if (numMoved &gt; 0)
        System.arraycopy(elementData, index+1, elementData, index,
                         numMoved);
    elementData[--size] = null; // clear to let GC do its work

    return oldValue;
}</code></pre>
<p>删除数据的时候，如果删除的数据后面还有数据需要在删除数据后将删除数据后面的数据往前移动<br>扩容和新增删除需要移动数组，底层使用方法都是<strong>System.arraycopy()</strong></p>
<h5 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h5><p>基于双向链表实现，所以增删快，查询慢，线程不安全</p>
<p><img src="java-collection/LinkedList.png" alt=""></p>
<p>LinkedList中维护了双向链表的头节点和尾节点，让我们看一下节点的结构Node</p>
<p><img src="java-collection/LinkedList-node.png" alt=""></p>
<p>Node的属性有当前节点的值，下一个节点和前一个节点，LinkedList整个结构非常清晰</p>
<p><strong>添加元素</strong></p>
<pre><code class="java">public boolean add(E e) {
    linkLast(e);
    return true;
}

/**
 * Links e as last element.
 */
void linkLast(E e) {
    // 将最后一个元素赋给变量 l
    final Node&lt;E&gt; l = last;
    // 构造新的节点 newNode
    final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null);
    // 将newNode放到队列尾部
    last = newNode;
    // 如果原队列尾部的节点为null
    if (l == null)
        // 新构造的节点为队列头节点
        first = newNode;
    else
        // 不为空则将 l 的next节点指向 newNode
        l.next = newNode;
    // 队列数量加1
    size++;
    // 操作次数加1
    modCount++;
}     </code></pre>
<p>代码逻辑清晰，新添加的元素加到队列的尾部</p>
<p><strong>删除元素</strong></p>
<pre><code class="java">public E remove() {
    return removeFirst();
}

public E removeFirst() {
    final Node&lt;E&gt; f = first;
    if (f == null)
        throw new NoSuchElementException();
    return unlinkFirst(f);
}

/**
 * Unlinks non-null first node f.
 */
private E unlinkFirst(Node&lt;E&gt; f) {
    // 获取当前节点的元素及下一个节点
    final E element = f.item;
    final Node&lt;E&gt; next = f.next;
    f.item = null;
    f.next = null; // help GC
    // 将下一个元素设置为队列首元素
    first = next;
    if (next == null)
        // 队列为空队列
        last = null;
    else
        // 队列首元素的前一个节点引用置为null
        next.prev = null;
    size--;
    modCount++;
    return element;
}</code></pre>
<p>删除的操作逻辑也比较清晰，删除队列的头节点</p>
<p>还有一些其他方法，代码逻辑也比较清晰，可自行查看</p>
<p>LinkedList实现了Deque接口，而Deque接口继承自Queue接口，因此LinkedList也提供了对于队列的实现，能实现队列肯定也能实现栈</p>
<h5 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h5><p>Vector也是数组实现，线程安全，性能较ArrayList差</p>
<p><strong>添加元素</strong></p>
<pre><code class="java">public synchronized boolean add(E e) {
    modCount++;
    ensureCapacityHelper(elementCount + 1);
    elementData[elementCount++] = e;
    return true;
}
private void ensureCapacityHelper(int minCapacity) {
    // overflow-conscious code
    if (minCapacity - elementData.length &gt; 0)
        grow(minCapacity);
}
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    // 扩容为原来的一倍
    int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ?                                         capacityIncrement : oldCapacity);
    if (newCapacity - minCapacity &lt; 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
        newCapacity = hugeCapacity(minCapacity);
    elementData = Arrays.copyOf(elementData, newCapacity);
}</code></pre>
<p>看源码的时候可以看到，Vector的方法都使用synchronized进行修饰，所以线程安全，但是加锁就意味着性能损耗，与ArrayList不同的是扩容时容量会扩为原来的一倍</p>
<p><strong>Stack</strong></p>
<p><strong>栈：保证数据先进后出，简称FILO原则</strong></p>
<p>Stack继承Vector类，实现了栈操作，看源码可以看到它调用的都是Vector的方法，这个类也基本不怎么会用，如果想要实现一个栈可以用实现了<strong>Dueue</strong>接口的子类，比如LinkedList，后面会讲到</p>
<h4 id="Queue队列"><a href="#Queue队列" class="headerlink" title="Queue队列"></a>Queue队列</h4><p><strong>队列一种特殊的线性表，遵循的原则就是“先入先出”，简称FIFO</strong></p>
<p>先看一下Queue接口定义的方法</p>
<p><img src="java-collection/Queue.png" alt=""></p>
<ul>
<li>add：添加元素到队列尾部，如果操作失败会报异常</li>
</ul>
<ul>
<li>remove：获取队列首部第一个元素，并从队列中删除，如果操作失败会报异常</li>
</ul>
<ul>
<li>element：获取队列首部第一个元素，单不从队列中删除，如果操作失败会报异常</li>
</ul>
<ul>
<li>offer：添加一个元素到队列尾部，操作失败不会报异常</li>
</ul>
<ul>
<li>poll：获取队列首部第一个元素，并从队列中删除，操作失败不会报异常</li>
</ul>
<ul>
<li>peek：获取队列首部第一个元素，单不从队列中删除，操作失败不会报异常</li>
</ul>
<p><strong>队列新元素都插入队列的末尾，移除元素都移除队列的头部</strong></p>
<p><strong>队列</strong></p>
<p><strong>Queue</strong>接口的子类按不同维度可以分为两种，一种是阻塞还是非阻塞队列，一种是单端还是双端队列</p>
<p>阻塞与非阻塞主要看是否实现了<strong>BlockingQueue</strong>接口或<strong>BlockingDeque</strong>接口，实现了的是阻塞队列，比如：ArrayBlockingQueue，LinkedBlockingQueue，LinkedBlockingDeque</p>
<p>未实现的是非阻塞队列，比如：ArrayDeque，LinkedList，PriorityQueue</p>
<p>*<em>Deque *</em>接口是Queue接口的子接口，代表一个双端队列，比如前面学过的LinkedList</p>
<p>Deque 接口提供的方法：</p>
<p><img src="java-collection/deque.png" alt=""></p>
<p>方法的作用可以根据方法名看出来，对比queue接口提供的方法，queue接口只提供了在队列尾部添加元素，获取移除队列首部的元素，而Deque接口实现了对于队列双端的添加删除操作</p>
<p>Deque 接口的实现类不仅可以当做队列，也可以实现栈，比如使用入栈方法：<em>offerFirst(E e);</em> 出栈方法：<em>E peekFirst()</em></p>
<h5 id="阻塞队列与非阻塞队列实现区别"><a href="#阻塞队列与非阻塞队列实现区别" class="headerlink" title="阻塞队列与非阻塞队列实现区别"></a>阻塞队列与非阻塞队列实现区别</h5><p>阻塞接口提供的方法：</p>
<p>看下BlockingQueue接口</p>
<p><img src="java-collection/blockingQueue.png" alt=""></p>
<p>阻塞接口中的阻塞方法</p>
<ul>
<li>put : 用来向队尾存入元素，如果队列满，则等待； </li>
<li>take: 用来从队首取元素，如果队列为空，则等待； </li>
<li>offer(E e,long timeout, TimeUnit unit) : 用来向队尾存入元素，如果队列满，则等待一定的时间，当时间期限达到时，如果还没有插入成功，则返回false；否则返回true； </li>
<li>poll(long timeout, TimeUnit unit) : 用来从队首取元素，如果队列空，则等待一定的时间，当时间期限达到时，如果取到，则返回null；否则返回取得的元素；</li>
</ul>
<p>以ArrayBlockingQueue为例：</p>
<p><img src="java-collection%5Carrayblockingqueue.png" alt=""></p>
<p>阻塞队列与非阻塞队列的实现区别就是是否使用了ReentrantLock和Condition</p>
<p><strong>添加元素：put(E e) 方法</strong></p>
<pre><code class="java">public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
           // 队列满了
        while (count == items.length)
            //进入等待状态
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}</code></pre>
<p>当数组里的数量等于数组的长度，也就是队列满了，执行<em>notFull.await();</em>进行阻塞，直到当前线程被中断或者其他线程调用了改notFull这个Condition的signal()方法或signalAll()方法</p>
<p>删除元素时阻塞的原理也是一样的，调用notEmpty.await()进行阻塞，唤醒条件也是一样的</p>
<pre><code class="java">public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}</code></pre>
<p>所以，阻塞队列的实现原理就是用ReentrantLock和Condition实现的</p>
<h4 id="Set集合"><a href="#Set集合" class="headerlink" title="Set集合"></a>Set集合</h4><p>无序集合，不允许存放重复的元素</p>
<h5 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h5><p>无序集合，允许元素为null</p>
<p><img src="java-collection%5CHashSet.png" alt=""></p>
<p>HashSet底层使用HashMap实现，采用HashCode算法来存取集合中的元素，因此具有比较好的读取和查找性能</p>
<p>对于添加的元素key为要添加值，value为一个static final object对象，对于添加重复的值，以前的值会被覆盖</p>
<p>对于HashSet的迭代，只需要调用的是HashMap的keySet()来获取到map中的key值的Set集合进行迭代</p>
<pre><code class="java">public Iterator&lt;E&gt; iterator() {
    return map.keySet().iterator();
}</code></pre>
<h5 id="LinkedHashSet"><a href="#LinkedHashSet" class="headerlink" title="LinkedHashSet"></a>LinkedHashSet</h5><p>HashSet的子类，底层实现是LinkedHashMap，利用双向链表保证了元素的有序性</p>
<pre><code class="java">public LinkedHashSet() {
    super(16, .75f, true);
}
HashSet(int initialCapacity, float loadFactor, boolean dummy) {
    map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);
}</code></pre>
<h5 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a>TreeSet</h5><p>TreeSet实现了SortedSet接口，所以这个是一种有序的Set集合，查看源码发现底层实现是用的TreeMap，而TreeMap使用红黑树实现</p>
<pre><code class="java">public TreeSet() {
    this(new TreeMap&lt;E,Object&gt;());
}</code></pre>
<p>使用TreeSet时需要注意，添加到TreeSet中的对象需要实现Comparable重写compareTo接口，或者自定义一个类实现Comparator接口重写compare方法，否则会报异常（讲TreeMap时会详解）</p>
<p><img src="java-collection/treeSet-exception.png" alt=""></p>
<p>Set集合的实现基本都是复用了Map的实现，使用map中的key存储set中的数据</p>
<h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><p>Map，散列表，它存储的内容是键值对映射(key-value)，先上个图，介绍下要讲的四种map实现</p>
<p><img src="java-collection/map.png" alt=""></p>
<h4 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h4><p>最常用的当属HashMap，jdk1.7时底层实现的数据结构是散列表（数组+链表），jdk1.8时底层数据结构为数组+链表/红黑树，1.8加入红黑树是为了解决链表过长所带来的性能消耗</p>
<p>结构如下：<em>网上找的图片</em></p>
<p><img src="java-collection/hashMap.jpg" alt=""></p>
<p>常用的属性：</p>
<pre><code class="java">/**
 * 默认容量
 */
static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16

/**
 * 默认的平衡因子
 */
static final float DEFAULT_LOAD_FACTOR = 0.75f;

/**
 * 由链表转为红黑树的阈值
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 由红黑树转为链表的阈值
 */
static final int UNTREEIFY_THRESHOLD = 6;

/*
 * 负载因子
 */
final float loadFactor;

/**
 * 是否扩容的阈值 threshold = 容量 * loadFactor
 */
int threshold;

/**
 * 数组，桶，槽位 存储该位置上的链表的头节点
 */
transient Node&lt;K,V&gt;[] table;</code></pre>
<p>我们知道Hashmap中的数组存储的是链表的头节点的引用，那我们看下节点的结构：</p>
<p>为链表时节点的结构：</p>
<p><img src="java-collection/map.Entry.png" alt=""></p>
<p>包括hash值，key，value，以及指向下一个节点的引用</p>
<p>为红黑树时节点的结构：</p>
<p><img src="java-collection/map.TreeNode.png" alt=""></p>
<p>包括父节点，左右节点，和节点颜色</p>
<p>对元素进行操作时，比如添加操作，会通过key的hash值找对应的数组下标位置，如果该位置对应的链表或红黑树为空，则该元素为头节点，如果有元素，则调用equals方法进行比较，如果相等就进行覆盖，如果不相等就进行添加</p>
<h4 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h4><p>LinkedHashMap继承自HashMap，与hashMap相比最大的区别在于LinkedHashMap存储的数据是有序的</p>
<p>在LinkedHashMap内部维护了一个双端队列，保证添加的数据的顺序性</p>
<p><img src="java-collection/LinkedHashMap.Entry.png" alt=""></p>
<p>LinkedHashMap重写了HashMap提供的模板方法来对<strong>链表</strong>进行维护</p>
<p>在HashMap中的put操作</p>
<p><img src="java-collection/LinkedHashMap%E9%87%8D%E5%86%99%E6%96%B9%E6%B3%951.png" alt=""></p>
<p>其中afterNodeAccess(e)就是暴露给子类的模板方法，此外还有：</p>
<p><img src="java-collection/HashMap%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95.png" alt=""></p>
<h4 id="TreeMap"><a href="#TreeMap" class="headerlink" title="TreeMap"></a>TreeMap</h4><p>TreeMap是SortedMap接口的实现类</p>
<p>TreeMap 是一个有序的key-value集合，通过红黑树实现，每个key-value作为红黑树的一个节点</p>
<p><img src="java-collection/treeMap.png" alt=""></p>
<p>Comparator，在讲TreeSet的时候说过，TreeSet支持两种排序方式，自然排序和定制排序</p>
<p>自然排序：key需要实现Comparable接口重写compareTo接口，而且所有的key应该是同一个类的对象，否则会抛出异常</p>
<p>定制排序：自定义一个类实现Comparator接口重写compare方法，这个类负责对TreeMap中的所有key进行排序，否则会抛出异常</p>
<p>我们看下红黑树的节点：</p>
<p><img src="java-collection/TreeMap.Entry.png" alt=""></p>
<p>包括：key，value信息，父节点，左右节点和节点颜色</p>
<p>在HashMap中判断节点是否相等时，是先比较key的hash值，如果相等在用equals进行比较</p>
<p>而在TreeMap中是两个key通过compareTo()方法如果返回值是0，则两个key相等</p>
<h4 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h4><p>Hashtable，散列表，存储的也是键值对，继承自Dictionary抽象类，其提供的方法都是同步的，key和value都不可以为null，数据结构为散列表（数组+链表）</p>
<p><img src="java-collection/hashtable.png" alt=""></p>
<p>实现原理与HashMap相同，使用Synchronize实现线程安全，看了源码，扩容时容量为newCapacity = (oldCapacity &lt;&lt; 1) + 1;  感兴趣的可以自行查看一下源码</p>
<blockquote>
<p>终于写完了，Java中常用的集合类都有讲到，不过有些地方只是一概而过，感兴趣的可自行看一下源码实现</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/java-collection/" data-id="ckdn6w7zs0031aktw9cpzcduv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9B%86%E5%90%88/" rel="tag">集合</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-data-structure-tree" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/data-structure-tree/" class="article-date">
  <time datetime="2019-07-17T08:39:15.000Z" itemprop="datePublished">2019-07-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/data-structure-tree/">【数据结构】| 众树纷纭</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>数据结构中的树有多种形式，如：二叉树，二叉搜索树，平衡二叉搜索树，红黑树，线段树，trie树，二叉堆等</strong></p>
<p>每一种树结构都是由最基础的树演化而来，每种树的产生都是为了解决某些问题，所以学习的过程也是先学习基础树结构的概念，之后会按照演化顺序进行讲解</p>
<p><strong>树是由有限个结点（假设为n）构成的集合</strong></p>
<p>比如下面这棵树：</p>
<p><img src="data-structure-tree/tree.png" alt=""></p>
<p><strong>基础概念：</strong></p>
<p><strong>父节点：</strong>A是B的父节点，A也是C的父节点，B是D的父节点</p>
<p><strong>子节点：</strong>B是A的子节点，C是A的子节点，G是C的子节点</p>
<p><strong>兄弟节点：</strong>B，C拥有共同的父节点A，所以B和C叫兄弟节点</p>
<p><strong>根节点：</strong>没有父节点的节点，叫做根节点，如图中的A就是根节点，一棵树只有一个根节点</p>
<p><strong>叶子节点：</strong>没有子节点的节点，叫做叶子节点，如图中的D，E，F，G节点</p>
<h3 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h3><p>二叉树是众多树型结构中的一种</p>
<p>顾名思义，二叉树中的每个节点最多只能有两个节点，此为二叉，两个节点分别是左子节点和右子节点 ，每个子节点也可是一棵树，也可称为左子树和右子树</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt=""></p>
<p>上图中的三棵树都属二叉树，而二叉树中又有两种比较特殊的树：满二叉树和完全二叉树</p>
<p><strong>满二叉树：</strong></p>
<p>​    在一棵二叉树中，如果每个结点都存在左子节点和右子节点，并且所有的叶子节点都在同一层中，这种二叉树叫满二叉树，如上图中的<strong>树1</strong></p>
<p><strong>完全二叉树：</strong></p>
<p>​    在一棵二叉树中，如果叶子节点都在最底下两层，最后一层叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树，如上图中的<strong>树2</strong></p>
<p><em>满二叉树也是一种特殊的完全二叉树</em></p>
<h4 id="二叉树的存储"><a href="#二叉树的存储" class="headerlink" title="二叉树的存储"></a>二叉树的存储</h4><p>在了解了二叉树的概念之后，我们思考一下该使用何种数据结构如何进行二叉树的存储？</p>
<h5 id="顺序存储结构"><a href="#顺序存储结构" class="headerlink" title="顺序存储结构"></a>顺序存储结构</h5><p>使用数组存储二叉树节点</p>
<p>以一颗完全二叉树为例，<strong>如果父节点的下标为<code>i</code>，则父节点的左子节点为<code>2*i</code>，右子节点为`2*i+1</strong>`，所以为了方便计算子节点，我们将数组0位置空置，树中节点从根节点开始从数组下标为1的位置进行顺序插入，这样进行节点计算时较为方便</p>
<p><img src="data-structure-tree/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8.png" alt=""></p>
<p>完全二叉树的可以按顺序的填满数组，只浪费数组下标为0的那块内存，那我们接下来看下非完全二叉树的顺序存储</p>
<p><img src="data-structure-tree/%E9%9D%9E%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8.png" alt=""></p>
<p>我们根据计算节点的公式，可以算出所有子节点对应数组的下标位置，树5这棵二叉树由于B节点没有左子节点，可以计算出这个缺失的节点下标位置为4，这样下标为4的内存就浪费了，如上图</p>
<p>对于这种内存的浪费，树5其实并不明显，可以想象一下如果一棵二叉树有大量的子节点缺失就会导致浪费大量的内存空间</p>
<p><strong>所以如果二叉树是一颗完全二叉树，我们使用数组进行存储，是最节省内存的一种方式</strong></p>
<h5 id="链式存储"><a href="#链式存储" class="headerlink" title="链式存储"></a>链式存储</h5><p>那非完全二叉树有没有什么好的存储方式那？</p>
<p>使用链表存储二叉树节点</p>
<p>使用链表存储节点的时候，链表的每个节点包括三个字段：二叉树的节点数据，二叉树节点的左子节点的引用，下图中简称左引用，二叉树节点的右子节点的引用，下图中简称右引用</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%93%BE%E5%BC%8F%E5%AD%98%E5%82%A8.png" alt=""></p>
<p>使用链表方式存储比使用数组方式存储需要额外存储二叉树节点的左右子节点的引用，但是对于存储大量缺失子节点的二叉树，无疑是比数组更优的一种方法</p>
<h4 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h4><p>在已经了解了二叉树的存储方式后，我们看一下如何遍历二叉树</p>
<p>常见的遍历方式有四种：前序遍历，中序遍历，后序遍历，层次遍历</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86.png" alt=""></p>
<h5 id="前序遍历"><a href="#前序遍历" class="headerlink" title="前序遍历"></a>前序遍历</h5><p><strong>对于树中的任意节点来说，先打印这个节点，然后再打印它的左子节点，最后打印它的右子节点</strong> </p>
<p>以树6为例：</p>
<ol>
<li>从根节点出发，首先输出这个节点，输出A</li>
<li>向左到达B，输出B，之后继续向左到达D，输出D，在到达H，输出H</li>
<li>H是叶子节点，所以返回D，但是D已经输出过了，所以访问D的右子节点I，输出I</li>
<li>I是叶子节点，所以继续返回到B，访问B的右子节点E，输出E</li>
<li>依照这种方式进行输出</li>
</ol>
<p>输出结果为：A-&gt;B-&gt;D-&gt;H-&gt;I-&gt;E-&gt;C-&gt;F-&gt;G</p>
<h5 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h5><p><strong>对于树中的任意节点来说，先打印它的左子节点，然后再打印它本身，最后打印它的右子节点</strong> </p>
<p>以树6为例：</p>
<ol>
<li>从根节点出发，先不输出他本身，继续向左访问到B，在向左访问到D，再到H</li>
<li>H没有子节点，因此输出自己，再返回到D，输出D，之后访问D的右子节点I，输出I</li>
<li>之后再返回到D，因为D已经输出，在往上返回，到B，输出B，之后访问B的右子节点E，输出E</li>
<li>依照这种方式进行输出</li>
</ol>
<p>输出结果为：H-&gt;D-&gt;I-&gt;B-&gt;E-&gt;A-&gt;F-&gt;C-&gt;G</p>
<h5 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h5><p><strong>对于树中的任意节点来说，先打印它的左子节点，然后再打印它的右子节点，最后打印这个节点本身</strong> </p>
<p>以树6为例：</p>
<ol>
<li>从根节点出发，首先输出自己，继续向左访问到B，直到叶子节点H</li>
<li>H无子节点，输出H，返回到D，继续访问D的右子节点I，I无子节点，输出I</li>
<li>再次返回到D，此时D的子节点都已输出，所以此时输出D，继续返回到B，访问B的右子节点E</li>
<li>E无子节点，故输出E</li>
<li>依照这种方式进行输出</li>
</ol>
<p>输出结果为：H-&gt;I-&gt;D-&gt;E-&gt;B-&gt;F-&gt;G-&gt;C-&gt;A</p>
<h5 id="层次遍历"><a href="#层次遍历" class="headerlink" title="层次遍历"></a>层次遍历</h5><p><strong>从二叉树的根结点开始，从上至下逐层遍历，在同一层，则按从左至右的顺序对每个结点逐个访问</strong></p>
<p>以树6为例：</p>
<p>输出结果为：A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;F-&gt;G-&gt;H-&gt;I</p>
<h3 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h3><p><strong>概念：</strong>在二叉搜索树中，任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，其右子树中的每个节点的值都大于这个节点的值</p>
<p>如下图：</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91.png" alt=""></p>
<h4 id="查找操作"><a href="#查找操作" class="headerlink" title="查找操作"></a>查找操作</h4><p>因为二叉搜索树中任意一个节点的左子树中的节点都小于这个节点的值，右子树中的节点都大于这个节点的值，查询时从根节点开始，如果查询的值小于根节点的值，就去左子树中查询，如果大于根节点的值，就去右子树中查询</p>
<p><strong>在树7中以查找4为例：</strong></p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%E6%9F%A5%E8%AF%A2.png" alt=""></p>
<h4 id="插入操作"><a href="#插入操作" class="headerlink" title="插入操作"></a>插入操作</h4><p>插入操作跟查找操作类似，都是根据二叉查找树的特性进行查询可以插入新节点的位置</p>
<p><strong>在树7中以插入12为例：</strong></p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%E6%8F%92%E5%85%A5.png" alt=""></p>
<h4 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h4><p>删除节点比较复杂，主要是根据要删除的子节点数量进行不同处理</p>
<p><strong>情况1：删除的节点没有子节点，这种情况直接找到节点删除即可</strong></p>
<p>比如删除节点4：</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%A0%E9%99%A41.png" alt=""></p>
<p><strong>情况2：删除的节点有一个子节点，删除节点，移动其子节点</strong></p>
<p>比如删除节点3：</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%A0%E9%99%A42.png" alt=""></p>
<p><strong>情况3：删除的节点有两个子节点，首先需要找到右子树中最小的节点，将当前节点替换为最小节点，然后删除最小节点</strong></p>
<p>比如删除节点5：</p>
<p><img src="data-structure-tree/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%A0%E9%99%A4%E6%83%85%E5%86%B53.png" alt=""></p>
<h4 id="退化为链表"><a href="#退化为链表" class="headerlink" title="退化为链表"></a>退化为链表</h4><p>当二叉搜索树是满二叉树或完全二叉树时，其查找，添加，删除的时间复杂度是log(n)，当一颗二叉搜索树极度不平衡时，其操作的时间复杂度退化为O(n)</p>
<p>比如向二叉搜索树中按顺序添加 1,2,3,4 ，其二叉搜索树的结构如下图：</p>
<p><img src="data-structure-tree/%E6%9E%81%E5%BA%A6%E4%B8%8D%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91.png" alt=""></p>
<p>这时二叉搜索树退化为链表，即便不是退化为链表这种极端情况，只要有左右两颗子树不平衡的情况在（实际上使用时绝大部分都是不平衡的），其操作的时间复杂度就会退化</p>
<h3 id="平衡二叉搜索树（AVL）"><a href="#平衡二叉搜索树（AVL）" class="headerlink" title="平衡二叉搜索树（AVL）"></a>平衡二叉搜索树（AVL）</h3><p>为了解决将有顺序数据添加到二叉查找树时导致二叉搜索树性能变差的情况出现，就需要二叉搜索树可以自己进行自平衡操作，进而使二叉搜索树达到平衡状态，在进行自平衡操作之前，需要了解下平衡的概念</p>
<h4 id="平衡二叉搜索树的平衡"><a href="#平衡二叉搜索树的平衡" class="headerlink" title="平衡二叉搜索树的平衡"></a>平衡二叉搜索树的平衡</h4><p>对于任意一个节点，左右子树的高度之差的绝对值不超过1，那么这棵二叉搜索树是平衡的</p>
<p><strong>节点高度：</strong>左右子树最高的节点高度+1</p>
<p><strong>平衡因子：</strong>左右子树的高度差的绝对值，所以一个平衡二叉搜索树的任意一个节点的平衡因子不能大于1</p>
<p>在二叉搜索树的基础上，满足平衡条件的二叉树，就是平衡二叉搜索树，如下图：</p>
<p><img src="data-structure-tree/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt=""></p>
<p>使用这种方式，我们就可以计算出二叉搜索树是否是平衡的，树8的任意一个节点的平衡因子都在-1,0,1之间，所以树8是平衡二叉搜索树</p>
<h4 id="平衡二叉搜索树的自平衡"><a href="#平衡二叉搜索树的自平衡" class="headerlink" title="平衡二叉搜索树的自平衡"></a>平衡二叉搜索树的自平衡</h4><p>一颗平衡二叉搜索树当添加节点的时候，必须更新其父节点的平衡因子，可分为两种情况：</p>
<ol>
<li>递归更新父节点的平衡因子，直到根节点</li>
<li>当父节点的平衡因子为0时其祖先节点的平衡因子不会发生改变，停止更新</li>
</ol>
<p>根据添加的节点位置可以分为4种情况：</p>
<h5 id="情况1：添加的节点在左子树的左边，简称为LL"><a href="#情况1：添加的节点在左子树的左边，简称为LL" class="headerlink" title="情况1：添加的节点在左子树的左边，简称为LL"></a>情况1：添加的节点在左子树的左边，简称为LL</h5><p><img src="data-structure-tree/LL.png" alt=""></p>
<ol>
<li>添加的节点F为D节点的左子节点</li>
<li>递归更新父节点的平衡因子，A节点额平衡因子为2</li>
<li>因此以A节点为根节点的子树需要进行自平衡操作</li>
<li>对A节点进行右旋转操作</li>
</ol>
<p>此时自平衡操作完成，二叉搜索树重新变为平衡二叉搜索树</p>
<h5 id="情况2：添加的节点在右子树的右边，简称为RR"><a href="#情况2：添加的节点在右子树的右边，简称为RR" class="headerlink" title="情况2：添加的节点在右子树的右边，简称为RR"></a>情况2：添加的节点在右子树的右边，简称为RR</h5><p><img src="data-structure-tree/RR.png" alt=""></p>
<ol>
<li>添加节点F为E的右子节点</li>
<li>递归更新父节点的平衡因子，A节点额平衡因子为2</li>
<li>因此以A节点为根节点的子树需要进行自平衡操作</li>
<li>对A节点进行左旋转操作</li>
</ol>
<h5 id="情况3：添加的节点在左子树的右边，简称为LR"><a href="#情况3：添加的节点在左子树的右边，简称为LR" class="headerlink" title="情况3：添加的节点在左子树的右边，简称为LR"></a>情况3：添加的节点在左子树的右边，简称为LR</h5><p>首先我们尝试使用LL解决方法，对A节点进行右旋转，不过很明显平衡之后的二叉搜索树肯定不是平衡的，B的平衡因子还是2</p>
<p><img src="data-structure-tree/LR%E6%8F%92%E5%85%A5.png" alt=""></p>
<p>所以直接使用右旋转操作是行不通的</p>
<p>针对这种情况，<strong>需要先将LR转为LL，之后就可以进LL的自平衡操作了</strong>，具体流程如下</p>
<p><img src="data-structure-tree/LR%E6%97%8B%E8%BD%AC.png" alt=""></p>
<ol>
<li>对B进行左旋转，使LR转化为LL</li>
<li>转化为LL后，使用处理LL的自平衡操作，对A进行右旋转</li>
</ol>
<p><strong>无论添加的节点F是E的左子节点还是右子节点，对以上整个自平衡的操作并无影响</strong></p>
<h5 id="情况4：添加的节点在右子树的左边，简称为RL"><a href="#情况4：添加的节点在右子树的左边，简称为RL" class="headerlink" title="情况4：添加的节点在右子树的左边，简称为RL"></a>情况4：添加的节点在右子树的左边，简称为RL</h5><p>这种情况和LR情况类似，需要先将RL转为RR，之后进行RR的自平衡操作即可</p>
<p><img src="E:%5Cmy%5Cmyblog%5Csource_posts%5Cdata-structure-tree%5CRL%E6%97%8B%E8%BD%AC.png" alt=""></p>
<ol>
<li>对C进行右旋转，使RL转换为RR</li>
<li>转化为RR之后，使用RR的自平衡操作，对A进行左旋转</li>
</ol>
<h5 id="总结一下自平衡转换的规则"><a href="#总结一下自平衡转换的规则" class="headerlink" title="总结一下自平衡转换的规则"></a>总结一下自平衡转换的规则</h5><p>如果是LL，对不平衡的节点进行右旋转</p>
<p>如果是RR，对不平衡的节点进行左旋转</p>
<p>如果是LR，先左旋，变成LL，在右旋转</p>
<p>如果是RL，先右旋，变成RR，在左旋转</p>
<p><em>L对应右旋转，R对应左旋转</em></p>
<p>本来想一篇把开头写的二叉树，二叉搜索树，平衡二叉搜索树，红黑树，线段树，trie树，二叉堆等都讲明白，但是写到平衡二叉搜索树的时候发现篇幅太长了，所以剩下的树放到下一篇去写</p>
<p>画图不易，欢迎点赞</p>
<p>有问题可以评论，一起讨论</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/data-structure-tree/" data-id="ckdn6w7wz000baktw71bafnto" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" rel="tag">二叉树</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-concurrent-lock" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/concurrent-lock/" class="article-date">
  <time datetime="2019-07-11T02:18:15.000Z" itemprop="datePublished">2019-07-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/concurrent-lock/">java并发编程 | 锁详解：AQS，Lock，ReentrantLock，ReentrantReadWriteLock</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>锁是用来控制多个线程访问共享资源的方式，<code>java</code>中可以使用<code>synchronized</code>和<code>Lock</code>实现锁的功能</p>
<p><code>synchronized</code>是java中的关键字，隐藏获取和释放锁的过程，<code>Lock</code>是java中的接口，需要主动的获取锁和释放锁，<code>synchronized</code>是排他锁，而<code>Lock</code>支持可中断获取锁，超时获取锁</p>
<p><code>Lock</code>提供的接口</p>
<pre><code class="java">public interface Lock {

    /**
     * 获取锁，调用该方法后当前线程获取锁，获取到锁之后从该方法返回
     */
    void lock();

    /**
     * 可中断的获取锁，在获取锁的过程中可以中断当前线程
     */
    void lockInterruptibly() throws InterruptedException;

    /**
     * 尝试非阻塞的获取锁，调用方法后立即返回，获取到锁则返回true，否则返回false
     */
    boolean tryLock();

    /**
     * 超时获取锁，在超时时间内获取到锁，在超时时间被中断，超时时间内为获取到锁，三种情况下会从该方法返回
     */
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

    /**
     * 释放锁
     */
    void unlock();

    /**
     * 获取等待通知组件，只有当前线程获取到锁之后才可以调用该组件的wait()方法，释放锁
     */
    Condition newCondition();
}</code></pre>
<h4 id="队列同步器"><a href="#队列同步器" class="headerlink" title="队列同步器"></a>队列同步器</h4><p>队列同步器<code>AbstractQueuedSynchronizer</code>（<code>AQS</code>简称同步器）是用来构建锁或者其他同步组件的基础框架</p>
<p><code>java</code>中锁的实现基本都是通过聚合了一个同步器的子类完成线程访问控制的，同步器是实现锁的关键，可以这么理解，锁面向编程者，隐藏了实现细节，同步器面向锁的实现，简化了锁的实现方式，屏蔽了同步状态管理，线程排队，等待与唤醒等底层操作，通过<code>AbstractQueuedSynchronizer</code>我们可以很方便的实现一个锁</p>
<h5 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h5><p>同步器的设计基于模板方法模式，提供的模板方法主要包括：独占锁获取锁与释放同步状态，共享式获取与释放同步状态，获取同步队列中等待线程情况</p>
<p><strong>独占式操作</strong></p>
<p>想要实现一个独占式锁需要重写以下方法</p>
<table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>void acquire(int arg)</td>
<td>独占式获取同步状态，同一时刻只能有一个线程可以获取到同步状态，获取失败进入同步队列等待</td>
</tr>
<tr>
<td>void acquireInterruptibly(int arg)</td>
<td>独占式获取同步状态，响应中断操作，被中断时会抛异常并返回</td>
</tr>
<tr>
<td>boolean tryAcquireNanos(int arg, long nanosTimeout)</td>
<td>独占式获取同步状态，响应中断操作，并且增加了超时限制，如果规定时间没有获得同步状态就返回false，否则返回true</td>
</tr>
<tr>
<td>boolean release(int arg)</td>
<td>独占式释放同步状态，在释放同步状态之后，将同步队列中的第一个节点包含的线程唤醒</td>
</tr>
</tbody></table>
<p><strong>共享式操作</strong></p>
<p>想要实现一个共享锁需要重写以下方法</p>
<table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>void acquireShared(int arg)</td>
<td>共享式获取同步状态，同一时刻可以有多个线程获取到同步状态</td>
</tr>
<tr>
<td>void acquireSharedInterruptibly(int arg)</td>
<td>共享式获取同步状态，响应中断操作</td>
</tr>
<tr>
<td>boolean tryAcquireSharedNanos(int arg, long nanosTimeout)</td>
<td>共享式获取同步状态，响应中断操作，并且增加了超时限制，如果规定时间没有获得同步状态就返回false，否则返回true</td>
</tr>
<tr>
<td>boolean releaseShared(int arg)</td>
<td>共享式释放同步状态</td>
</tr>
</tbody></table>
<h5 id="获取同步队列线程信息"><a href="#获取同步队列线程信息" class="headerlink" title="获取同步队列线程信息"></a>获取同步队列线程信息</h5><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>Collection<Thread> getQueuedThreads()</td>
<td>获取同步队列上的线程集合</td>
</tr>
</tbody></table>
<p>在这些模板方法中，多次提到了同步队列，我们看一下<code>AQS</code>是如何实现同步队列的</p>
<p>首先看下<code>AbstractQueuedSynchronizer</code>的类图</p>
<p><img src="concurrent-lock/abstractQueuedSynchronizer.png" alt=""></p>
<h5 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h5><p><code>Node</code>类是<code>AbstractQueuedSynchronizer</code>类的内部类，同步器依靠内部的一个同步队列来完成同步状态的管理，当前线程获取同步状态失败的时候，同步器会将当前线程及等待信息构造成一个<code>Node</code>节点加入到同步队列中</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>waitStatus</td>
<td>该线程等待状态，包含如下：<br />CANCELLED 值为1，表示需要从同步队列中取消等待<br />SIGNAL值为-1，表示后继节点处于等待状态，如果当前节点释放同步状态会通知后继节点，使得后继节点的线程能够运行<br />CONDITION值为-2，表示节点在等待队列中<br />PROPAGATE值为-3，表示下一次共享式同步状态获取将会无条件传播下去<br />INITIAL值为0，表示初始状态</td>
</tr>
<tr>
<td>prev:Node</td>
<td>前驱节点</td>
</tr>
<tr>
<td>next:Node</td>
<td>后继节点</td>
</tr>
<tr>
<td>thread:Thread</td>
<td>当前线程</td>
</tr>
<tr>
<td>nextWaiter:Node</td>
<td>下一个等待节点</td>
</tr>
</tbody></table>
<p>可以看到<code>AQS中</code>的节点信息包含前驱和后继节点，所以我们知道了AQS的同步队列是双向链表结构的</p>
<h5 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h5><p><code>AQS</code>中的几个重要属性</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>state:int</td>
<td>同步状态：如果等于0，锁属于空闲状态，如果等于1，标识锁被占用，如果大于1，则表示锁被当前持有的线程多次加锁，即重入状态</td>
</tr>
<tr>
<td>head:Node</td>
<td>队列的头节点</td>
</tr>
<tr>
<td>tail:Node</td>
<td>队列的尾节点</td>
</tr>
<tr>
<td>unsafe:Unsafe</td>
<td>AQS中的cas算法实现</td>
</tr>
</tbody></table>
<p><code>AQS</code>中提供了三个方法对同步状态进行操作</p>
<ol>
<li><code>getState()</code>获取到同步状态</li>
<li><code>setState(int newState)</code>设置同步状态</li>
<li><code>compareAndSetState(int expect, int update)</code>使用<code>CAS</code>设置当前状态，该方法能够保证设置的原子性</li>
</ol>
<p><code>AQS</code>的基本结构如下图所示</p>
<p><img src="concurrent-lock/AQS.png" alt=""></p>
<p>在同步器中<code>head</code>和<code>tail</code>的节点的引用指向同步队列的头，尾节点，这样在后面操作节点入列和出列的时候只需要操作同步器中的<code>head</code>和<code>tail</code>节点就可以</p>
<h4 id="独占式锁"><a href="#独占式锁" class="headerlink" title="独占式锁"></a>独占式锁</h4><h5 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h5><p><code>ReentrantLock</code>重入锁，内部AQS的实现是基于独占式获取/释放同步状态的。我们学习一下<code>ReentrantLock</code>的实现原理来进一步加深对<code>AQS</code>的理解</p>
<p>重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁阻塞，它表示一个线程可以对资源重复加锁，同时支持获取锁时使用公平锁还是非公平锁</p>
<p>例：</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/12 15:09
 * @description: ReentrantLock
 */
public class ReentrantLockTest {

    private static Lock LOCK = new ReentrantLock();

    public static void main(String[] args) {
        Runnable r1 = new TestThread();
        new Thread(r1,&quot;r1&quot;).start();
        Runnable r2 = new TestThread();
        new Thread(r2,&quot;r2&quot;).start();
    }

    public static class TestThread implements Runnable{

        @Override
        public void run() {
            LOCK.lock();
            try {
                System.out.println(Thread.currentThread().getName()+&quot;：获取到锁 &quot;+LocalTime.now());
                TimeUnit.SECONDS.sleep(3L);
            }catch (Exception e){
                e.printStackTrace();
            }finally {
                LOCK.unlock();
            }
        }
    }
}</code></pre>
<p>输出</p>
<p><img src="concurrent-lock/reenTrantLock.png" alt=""></p>
<p>只有在<code>r1</code>线程释放锁之后<code>r2</code>线程才获取到锁去执行代码打印数据</p>
<h5 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h5><p>创建的实例，默认使用非公平锁，如果需要公平锁，需要调用有参的构造函数</p>
<pre><code class="java">/**
 * 非公平锁
 * 创建ReentrantLock实例，默认使用非公平锁
 */
public ReentrantLock() {
    sync = new NonfairSync();
}

/**
 * 公平锁
 * 创建ReentrantLock实例，fair为true使用公平锁
 */
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}</code></pre>
<p><code>NonfairSync</code>与<code>FairSync</code>都是<code>ReentrantLock</code>类的内部类，继承自<code>ReentrantLock</code>类的内部类<code>Sync</code>，<code>Sync</code>类继承了<code>AbstractQueuedSynchronizer</code></p>
<p>类图如下</p>
<p><img src="concurrent-lock/%E7%B1%BB%E5%9B%BE.png" alt=""></p>
<h5 id="独占式锁的获取"><a href="#独占式锁的获取" class="headerlink" title="独占式锁的获取"></a>独占式锁的获取</h5><p>非公平锁的实现</p>
<pre><code class="java">/**
 * Performs lock.  Try immediate barge, backing up to normal
 * acquire on failure.
 */
final void lock() {
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}</code></pre>
<p>非公平锁会在调用<code>lock()</code>方法的时候首先调用<code>compareAndSetState(0, 1)</code>方法尝试获取锁，如果没有获取到锁则调用<code>acquire(1)</code>方法</p>
<p><code>compareAndSetState(0, 1)</code>方法是一个<code>CAS</code>操作，如过设置成功，则为获取到同步状态，并调用<code>setExclusiveOwnerThread(Thread.currentThread());</code>方法将当前线程设置为独占模式同步状态的所有者</p>
<p>我们所说的获取同步状态其实指的就是获取锁的状态，获取同步状态成功则加锁成功</p>
<pre><code class="java">protected final boolean compareAndSetState(int expect, int update) {
    // See below for intrinsics setup to support this
    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}</code></pre>
<p><code>acquire(1)</code>方法是提供的模板方法，调用<code>tryAcquire(arg)</code>和<code>acquireQueued(addWaiter(Node.EXCLUSIVE), arg)</code></p>
<pre><code class="java">public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}</code></pre>
<p><code>tryAcquire(arg)</code>方法调用的是子类的实现，<code>NonfairSync</code>的<code>tryAcquire</code>方法</p>
<pre><code class="java">protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}</code></pre>
<p><code>nonfairTryAcquire(acquires)</code>方法</p>
<pre><code class="java">/**
 * 非公平尝试获取同步状态
 */
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        /**
         * 首先根据`getState()`方法获取同步状态，如果等于0尝试调用`compareAndSetState(0,                 * acquires)`方法获取同步状态，如果设置成功则获取同步状态成功，设置当前线程为独占模式同步状态的          * 所有者
         */
        int nextc = c + acquires;
        if (nextc &lt; 0) // overflow
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);
        return true;
    }
    return false;
}</code></pre>
<ol>
<li>根据<code>getState()</code>方法获取同步状态，如果等于0尝试调用<code>compareAndSetState(0, acquires)</code>方法获取同步状态，如果设置成功则获取同步状态成功，设置当前线程为独占模式同步状态的所有者</li>
<li>如果当前线程等于独占式同步状态所有者的线程，那么就将<code>state</code>+1，表示当前线程多次加锁</li>
</ol>
<p>如果<code>tryAcquire(arg)</code>  返回false，表示没有获取到同步状态，即没有拿到锁，所以需要调用 <code>acquireQueued(addWaiter(Node.EXCLUSIVE), arg)</code>方法将当前线程加入到同步队列中，并且以死循环的方式获取同步状态，如果获取不到则阻塞节点中的线程，而被阻塞的线程只能通过前驱节点的出队，或者阻塞线程被中断来实现唤醒</p>
<p><code>addWaiter(Node.EXCLUSIVE)</code>方法的作用就是构造同步队列的节点信息，然后加入到同步队列尾部</p>
<pre><code class="java">private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}</code></pre>
<p>首先调用<code>Node</code>类的构造方法创建一个实例，<code>tail</code>是<code>AQS</code>中队列的尾节点</p>
<p>如果<code>tail</code>节点不为空，将实例的前驱节点置为<code>tail</code>指向的节点，然后调用<code>compareAndSetTail(pred, node)</code>方法，<code>compareAndSetTail(pred, node)</code>方法调用<code>unsafe.compareAndSwapObject(this, tailOffset, expect, update)</code>，此方法是一个<code>CAS</code>操作，不可中断，用来保证节点能够被线程安全的添加，设置成功后，将节点<code>tail</code>的后继节点指向当前实例，以此来实现将当前实例加入到同步队列尾部</p>
<p>如果<code>tail</code>节点等于空或者<code>compareAndSetTail(pred, node)</code>设置失败，则会调用<code>enq(node)</code>方法</p>
<pre><code class="java">private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}</code></pre>
<p>在这个方法中利用<code>for</code>循环构造了一个死循环，如果当前<code>AQS</code>的<code>tail</code>节点为空，则证明当前同步队列中没有等待的线程，也就是没有节点，调用<code>compareAndSetHead(new Node())</code>方法构造了一个头节点，然后循环调用<code>compareAndSetTail(t, node)</code>将当前实例加入到队列的尾部，如果失败就一直调用，直到成功为止</p>
<p><img src="concurrent-lock/AQS%E8%AE%BE%E7%BD%AE%E5%B0%BE%E8%8A%82%E7%82%B9.png" alt=""></p>
<p>在调用<code>addWaiter(Node mode)</code>方法后会调用<code>acquireQueued(final Node node, int arg)</code>方法，作用是在每个节点进入到同步队列中后就进入了一个自旋的状态，通过校验自己的前驱节点是否是头节点，并且是否获取到同步状态为条件进行判断，如果满足条件则从自旋中退出，负责一直自旋</p>
<pre><code class="java">final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}</code></pre>
<p>方法内也是一个<code>for</code>的死循环，通过<code>node.predecessor()</code>方法获取传入的<code>Node</code>实例的前驱节点并与<code>AQS</code>的<code>head</code>节点进行比较，如果相等，则尝试获取同步状态获取锁，如果获取成功就调用<code>setHead(node);</code>方法将当前<code>Node</code>实例节点设置为<code>head</code>节点，将原来<code>head</code>节点的后继节点置为null，有助于GC回收</p>
<p><code>setHead(node);</code></p>
<pre><code class="java">private void setHead(Node node) {
    head = node;
    node.thread = null;
    node.prev = null;
}</code></pre>
<p>如果传入的<code>Node</code>实例的前驱节点与<code>AQS</code>的<code>head</code>节点不相等或者获取同步状态失败，则调用<code>shouldParkAfterFailedAcquire(p, node)</code>和<code>parkAndCheckInterrupt()</code>方法</p>
<pre><code class="java">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        /*
         * This node has already set status asking a release
         * to signal it, so it can safely park.
         */
        return true;
    if (ws &gt; 0) {
        /*
         * Predecessor was cancelled. Skip over predecessors and
         * indicate retry.
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next = node;
    } else {
        /*
         * waitStatus must be 0 or PROPAGATE.  Indicate that we
         * need a signal, but don&#39;t park yet.  Caller will need to
         * retry to make sure it cannot acquire before parking.
         */
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}</code></pre>
<p>通过<code>CAS</code>操作，设置节点的前驱节点等待状态为<code>Node.SIGNAL</code>，如果设置失败，返回false，因为外层是死循环，会重复当前方法直到设置成功</p>
<p><code>parkAndCheckInterrupt()</code>方法调用<code>LookSupport.park()</code>阻塞线程，然后清除掉中断标识</p>
<pre><code class="java">private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}</code></pre>
<p>从<code>acquireQueued(addWaiter(Node.EXCLUSIVE), arg)</code>方法返回后，调用<code>selfInterrupt()</code>，将线程中断</p>
<p><strong>公平锁的实现</strong></p>
<p>在了解<code>acquire(1);</code>方法的作用之后，在理解公平锁的实现就容易了</p>
<pre><code class="java">final void lock() {
    acquire(1);
}</code></pre>
<p>对比非公平锁的实现少了一步上来就获取同步状态的操作，其余操作跟非公平锁的实现一样</p>
<p><strong>公平锁与非公平锁总结</strong>：</p>
<ol>
<li>公平锁，在加锁之前如果有同步对列，则加入到同步队列尾部</li>
<li>非公平锁，在加锁之前不管有没有同步队列，先尝试获取同步状态，获取不到在加入到同步队列尾部</li>
<li>非公平锁比公平锁效率要高很多，公平锁保证了同步状态的获取按照FIFO原则，代价是需要进行大量的线程切换，而非公平锁情况下，当前线程在释放了同步状态之后再次获取到同步状态的记录非常大，可以减少大量的线程切换，但是可能会出现在同步队列中的某个线程一直获取不到锁的情况</li>
</ol>
<p><strong>独占式获取锁的流程</strong></p>
<p><img src="concurrent-lock/%E7%8B%AC%E5%8D%A0%E5%BC%8F%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt=""></p>
<h5 id="独占式锁的释放"><a href="#独占式锁的释放" class="headerlink" title="独占式锁的释放"></a>独占式锁的释放</h5><p><code>ReentrantLock</code>的<code>unlock()</code>方法实际调用的<code>AQS</code>的<code>release(int arg)</code>方法</p>
<pre><code class="java">public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}</code></pre>
<p>首先调用<code>tryRelease(arg)</code>释放同步状态</p>
<pre><code class="java">protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}</code></pre>
<p>获取同步状态，并减1，如果此时c==0则释放锁，将当前独占式锁的拥有线程置为null，然后设置<code>state</code>为0</p>
<p>然后调用<code>unparkSuccessor(Node node)</code>方法唤醒后继节点的线程</p>
<pre><code class="java">private void unparkSuccessor(Node node) {

    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);

    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        /*
         * 唤醒后继节点的线程
         */
        LockSupport.unpark(s.thread);
}</code></pre>
<p>总结一下独占式获取锁和释放锁的过程：</p>
<ol>
<li>获取锁的时候，首先会获取同步状态，如果获取成功则加锁成功，如果获取失败，将当前线程信息构造成节点信息并则加入到<code>AQS</code>维护的同步队列的尾部，并且开始自旋，跳出自旋的条件就是前驱节点为<code>AQS</code>的头节点并且获取到了同步状态，此时将节点移除同步队列</li>
<li>释放锁的时候，首先会释放同步状态，然后唤醒节点的后继节点</li>
<li>一个线程N次加锁之后，在释放锁的时候需要释放N次，之后才会被别的线程获取到锁</li>
</ol>
<h5 id="自己实现一个独占式锁"><a href="#自己实现一个独占式锁" class="headerlink" title="自己实现一个独占式锁"></a>自己实现一个独占式锁</h5><p>在了解了<code>ReentrantLock</code>的实现原理之后，我们就可以仿照着自己去实现一个自定义独占式锁了</p>
<p><strong>步骤</strong></p>
<ol>
<li>创建一个<code>LockTest</code>类，实现<code>Lock</code>接口，重写必要的接口</li>
<li>在<code>LockTest</code>类里创建一个内部类<code>Sync</code>，继承<code>AQS</code>，因为要实现独占式锁，所以重写<code>tryAcquire(int arg)</code>和<code>tryRelease(int arg)</code>方法就可以了</li>
</ol>
<p><code>LockTest</code>代码</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/11 15:11
 * @description: 自定义独占式锁
 */
public class LockTest implements Lock{

    private final Sync SYNC = new Sync();

    public static class Sync extends AbstractQueuedSynchronizer{

        @Override
        protected boolean tryAcquire(int arg) {
            if(compareAndSetState(0,1)){
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }

        @Override
        protected boolean tryRelease(int arg) {
            if(getState()&lt;1){
                throw new IllegalMonitorStateException(&quot;释放同步状态不可小于1&quot;);
            }
            int c = getState() - arg;
            if (c == 0) {
                setExclusiveOwnerThread(null);
            }
            setState(c);
            return true;
        }
    }

    @Override
    public void lock() {
        SYNC.acquire(1);
    }

    @Override
    public void lockInterruptibly() throws InterruptedException {
        SYNC.acquireInterruptibly(1);
    }

    @Override
    public boolean tryLock() {
        return SYNC.tryAcquire(1);
    }

    @Override
    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
        return false;
    }

    @Override
    public void unlock() {
        SYNC.release(1);
    }

    @Override
    public Condition newCondition() {
        return null;
    }
}</code></pre>
<h5 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h5><pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/12 15:09
 * @description: LockTest
 */
public class ReentrantLockTest {

    private static Lock LOCKTEST = new LockTest();

    public static void main(String[] args) {
        Runnable r1 = new TestThread();
        new Thread(r1,&quot;LockTest 1&quot;).start();
        Runnable r2 = new TestThread();
        new Thread(r2,&quot;LockTest 2&quot;).start();
    }

    public static class TestThread implements Runnable{

        @Override
        public void run() {
            LOCKTEST.lock();
            try {
                System.out.println(Thread.currentThread().getName()+&quot;：获取到锁 &quot;+LocalTime.now());
                TimeUnit.SECONDS.sleep(3L);
            }catch (Exception e){
                e.printStackTrace();
            }finally {
                LOCKTEST.unlock();
            }
        }
    }
}</code></pre>
<p>输出</p>
<p><img src="concurrent-lock/LockTest.png" alt=""></p>
<h4 id="共享式锁"><a href="#共享式锁" class="headerlink" title="共享式锁"></a>共享式锁</h4><h5 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h5><p><code>ReentrantReadWriteLock</code>是读写锁的实现，实现<code>ReadWriteLock</code>接口</p>
<p><code>ReentrantReadWriteLock</code>内部同样维护这一个<code>Sync</code>内部类，实现了<code>AQS</code>，通过重写对应方法实现读锁和写锁</p>
<p>现在已经知道了同步状态是由<code>AQS</code>维护的一个整型变量<code>state</code>，独占式锁获取到锁时会对其进行加1，支持重入，而读写锁<code>ReentrantReadWriteLock</code>在设计的时候也是通过一个整型变量进行读锁的同步状态和写锁的同步状态维护，在一个变量上维护两种状态就需要对整型变量进行按位分割，一个int类型的变量包含4个字符，一个字符8个bit，就是32bit，在<code>ReentrantReadWriteLock</code>中，高16位表示读，低16位表示写</p>
<p><strong>写锁的获取</strong></p>
<p>读写锁中的写锁，支持重进入的排它锁</p>
<p>重写<code>ReentrantReadWriteLock</code>的内部类<code>Sync</code>中的<code>tryAcquire(int acquires)</code>方法</p>
<pre><code class="java">protected final boolean tryAcquire(int acquires) {

    Thread current = Thread.currentThread();
    int c = getState();
    int w = exclusiveCount(c);
    /*
     * 1，如果同步状态c不等于0，代表着有读锁或者写锁
     */
    if (c != 0) {
        // 2，如果c不等于0，w写锁的同步状态为0，切当前线程不是持有锁的线程，返回false
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        // Reentrant acquire
        setState(c + acquires);
        return true;
    }
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}</code></pre>
<p><strong>解读</strong></p>
<p>如果存在读锁，写锁不能被获取，必须要等到其他读线程释放读锁，才可以获取到写锁，这么做的原因是要确保写锁做的操作对读锁可见，如果写锁被获取，则其他读写线程的后续访问均会被阻塞</p>
<p><strong>写锁的释放</strong></p>
<p>读写锁中的读锁，支持重进入的共享锁</p>
<p>写锁的释放与独占式锁释放过程相似，每次都是减少写锁的同步状态，直到为0时，表示写锁已被释放</p>
<p><strong>读锁的获取与释放</strong></p>
<p>读锁是一个支持重入的共享锁，重写<code>ReentrantReadWriteLock</code>的内部类<code>Sync</code>中的<code>tryAcquireShared(int unused)</code>方法</p>
<pre><code class="java">protected final boolean tryReleaseShared(int unused) {
    Thread current = Thread.currentThread();
    if (firstReader == current) {
        // assert firstReaderHoldCount &gt; 0;
        if (firstReaderHoldCount == 1)
            firstReader = null;
        else
            firstReaderHoldCount--;
    } else {
        HoldCounter rh = cachedHoldCounter;
        if (rh == null || rh.tid != getThreadId(current))
            rh = readHolds.get();
        int count = rh.count;
        if (count &lt;= 1) {
            readHolds.remove();
            if (count &lt;= 0)
                throw unmatchedUnlockException();
        }
        --rh.count;
    }
    for (;;) {
        int c = getState();
        int nextc = c - SHARED_UNIT;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}</code></pre>
<p>如果其他线程获取了写锁，则当前线程获取读锁状态失败进入等待状态，如果当前线程获取了写锁或者写锁未被获取，则当前线程获取同步状态成功，获取到读锁</p>
<p>释放读锁的时候就是每次释放都会对同步状态进行-1，直到为0时，表示读锁已被释放</p>
<p><strong>锁降级</strong></p>
<p>锁降级是指将写锁降级为读锁，这个过程就是当前线程已经获取到写锁的时候，在获取到读锁，随后释放写锁的过程，这么做的目的为的就是保证数据的可见性</p>
<p>当前线程A获取到写锁后，对数据进行修改，之后在获取到读锁，然后释放写锁，完成锁降级，这时候线程A还没释放读锁，别的线程就无法获取到写锁，就无法对数进行修改，以此来保证数据的可见性</p>
<p><strong>参考：java并发编程的艺术</strong></p>
<p><strong>推荐：</strong></p>
<p><a href="https://chenmingyu.top/concurrent-thread/">java并发编程 | 线程详解</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/concurrent-lock/" data-id="ckdn6w7w00000aktw28efd2y7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%94%81/" rel="tag">锁</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-es-query" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/es-query/" class="article-date">
  <time datetime="2019-07-10T02:11:03.000Z" itemprop="datePublished">2019-07-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/elasticsearch/">elasticsearch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/es-query/">Elasticsearch 查询语句详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要详细介绍es中常用的查询语句，以及使用的时候一些需要注意的事项</p>
<p>如对es不了解，建议先看 es基础: <a href="https://juejin.im/post/5cdc07446fb9a0322e73b5b5" target="_blank" rel="noopener">https://juejin.im/post/5cdc07446fb9a0322e73b5b5</a></p>
<h3 id="url参数搜索"><a href="#url参数搜索" class="headerlink" title="url参数搜索"></a>url参数搜索</h3><p>这种方式就是类似于get请求，将请求参数拼接到链接上，例<code>GET /school/student/_search?参数</code>，多个参数用&amp;分开</p>
<h4 id="查询所有"><a href="#查询所有" class="headerlink" title="查询所有"></a>查询所有</h4><p>命令：<code>GET /school/student/_search</code></p>
<p>返回：</p>
<pre><code class="json">{
  &quot;took&quot;: 7, //查询耗时，毫秒
  &quot;timed_out&quot;: false, //是否超时，timeout 不是停止执行查询，它仅仅是告知正在协调的节点返回到目前为止收集的结果并且关闭连接
  &quot;_shards&quot;: {
    &quot;total&quot;: 5, //请求的分片数量，索引拆成了5个分片，所以对于搜索请求，会打到所有的primary shard
    &quot;successful&quot;: 5,
    &quot;skipped&quot;: 0,
    &quot;failed&quot;: 0
  },
  &quot;hits&quot;: {
    &quot;total&quot;: 2, //符合条件的总条数，这里查的是所有
    &quot;max_score&quot;: 1, //匹配分数
    &quot;hits&quot;: [ //数据
      {
        &quot;_index&quot;: &quot;school&quot;,
        &quot;_type&quot;: &quot;student&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;name&quot;: &quot;houyi&quot;,
          &quot;age&quot;: 23,
          &quot;class&quot;: 2,
          &quot;gender&quot;: &quot;男&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;school&quot;,
        &quot;_type&quot;: &quot;student&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;name&quot;: &quot;吕布&quot;,
          &quot;age&quot;: 21,
          &quot;class&quot;: 2,
          &quot;gender&quot;: &quot;男&quot;
        }
      }
    ]
  }
}</code></pre>
<h4 id="多索引，多type搜索"><a href="#多索引，多type搜索" class="headerlink" title="多索引，多type搜索"></a>多索引，多type搜索</h4><p>在URL中指定特殊的索引和类型进行多索引，多type搜索</p>
<ol>
<li><code>/_search</code>：在所有的索引中搜索所有的类型</li>
<li><code>/school/_search</code>：在 <code>school</code> 索引中搜索所有的类型</li>
<li><code>/school,ad/_search</code>：在 <code>school</code> 和<code>ad</code>索引中搜索所有的类型</li>
<li><code>/s*,a*/_search</code>：在所有以<code>g</code>和<code>a</code>开头的索引中所有所有的类型</li>
<li><code>/school/student/_search</code>：在<code>school</code>索引中搜索<code>student</code>类型</li>
<li><code>/school,ad/student,phone/_search</code>：在<code>school</code>和<code>ad</code>索引上搜索<code>student</code>和<code>phone</code>类型</li>
<li><code>/_all/student,phone/_search</code>：在所有的索引中搜索<code>student</code>和<code>phone</code>类型</li>
</ol>
<h4 id="按条件查询"><a href="#按条件查询" class="headerlink" title="按条件查询"></a>按条件查询</h4><p>命令：<code>GET /school/student/_search?q=name:houyi</code></p>
<p>查询name是houyi的记录</p>
<p>更多查询参数：</p>
<p><img src="E:/my/myblog/source/_posts/es-basics/url%E6%90%9C%E7%B4%A2%E5%8F%82%E6%95%B0.png" alt=""></p>
<h3 id="查询DSL"><a href="#查询DSL" class="headerlink" title="查询DSL"></a>查询DSL</h3><p>elasticsearch提供了基于JSON的完整查询DSL来定义查询，DSL拥有一套查询组件，这些组件可以以无限组合的方式进行搭配，构建各种复杂的查询</p>
<h4 id="叶子语句"><a href="#叶子语句" class="headerlink" title="叶子语句"></a>叶子语句</h4><p>叶子语句：就像match语句，被用于将查询的字符串与一个字段或多个字段进行对比（单个条件）<br>比如：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;name&quot;: &quot;phone&quot;
       }
     }
   }</code></pre>
<h4 id="复合查询"><a href="#复合查询" class="headerlink" title="复合查询"></a>复合查询</h4><p>用户合并其他查询语句，比如一个<code>bool</code>语句，允许你在需要的时候组合其他语句，包括<code>must</code>，<code>must_not</code>，<code>should</code>和<code>filter</code>语句（多条件组合查询）<br>比如：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;must&quot;: [
           {&quot;match&quot;: {
             &quot;name&quot;: &quot;phone&quot;
           }}
         ]
         , &quot;must_not&quot;: [
           {&quot;match&quot;: {
             &quot;color&quot;: &quot;red&quot;
           }}
         ]
         , &quot;should&quot;: [
           {&quot;match&quot;: {
             &quot;price&quot;: 5000
           }}
         ]
         , &quot;filter&quot;: {
             &quot;term&quot;: {
               &quot;label&quot;: &quot;phone&quot;
             }
         }
       }
     }
   }</code></pre>
<p><code>must</code>：表示文档一定要包含查询的内容</p>
<p><code>must_not</code>：表示文档一定不要包含查询的内容</p>
<p><code>should</code>：表示如果文档匹配上可以增加文档相关性得分</p>
<p>事实上我们可以使用两种结构化语句： 结构化查询<code>query DSL</code>和结构化过滤<code>Filter DSL</code></p>
<ol>
<li><p>结构化查询<code>query DSL</code></p>
<p>用于检查内容与条件是否匹配，内容查询中使用的bool和match字句，用于计算每个文档的匹配得分，元字段_score表示匹配度，查询的结构中以query参数开始来执行内容查询</p>
</li>
<li><p>结构化过滤<code>Filter DSL</code></p>
<p>只是简单的决定文档是否匹配，内容过滤中使用的term和range字句，会过滤 调不匹配的文档，并且不影响计算文档匹配得分</p>
<p>使用过滤查询会被es自动缓存用来提高效率</p>
</li>
</ol>
<p>原则上来说，使用查询语句做全文本搜索或其他需要进行相关性评分的时候，剩下的全部用过滤语句</p>
<p><strong>新建一个稍微复杂的索引，添加三条文档</strong></p>
<pre><code class="json">PUT /ad/phone/1
{
  &quot;name&quot;:&quot;phone 8&quot;,
  &quot;price&quot;: 6000,
  &quot;color&quot;:&quot;white&quot;,
  &quot;ad&quot;:&quot;this is a white phone&quot;,
  &quot;label&quot;:[&quot;white&quot;,&quot;nice&quot;]
}

PUT /ad/phone/2
{
  &quot;name&quot;:&quot;xiaomi 8&quot;,
  &quot;price&quot;: 4000,
  &quot;color&quot;:&quot;red&quot;,
  &quot;ad&quot;:&quot;this is a red phone&quot;,
  &quot;label&quot;:[&quot;white&quot;,&quot;xiaomi&quot;]
}

PUT /ad/phone/3
{
  &quot;name&quot;:&quot;huawei p30&quot;,
  &quot;price&quot;: 5000,
  &quot;color&quot;:&quot;white&quot;,
  &quot;ad&quot;:&quot;this is a white phone&quot;,
  &quot;label&quot;:[&quot;white&quot;,&quot;huawei&quot;]
}
</code></pre>
<h3 id="查询示例"><a href="#查询示例" class="headerlink" title="查询示例"></a>查询示例</h3><h4 id="1-获取所有"><a href="#1-获取所有" class="headerlink" title="1. 获取所有"></a>1. 获取所有</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     }
   }</code></pre>
<p><code>match_all</code>匹配所有数据，返回的结果中元字段<code>_score</code>得分为1</p>
<h4 id="2-分页查询，从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题）"><a href="#2-分页查询，从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题）" class="headerlink" title="2. 分页查询，从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题）"></a>2. 分页查询，从第二条开始，查两条（不要使用<code>from</code>，<code>size</code>进行深度分页，会有性能问题）</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     },
     &quot;from&quot;: 1,
     &quot;size&quot;: 2
   }</code></pre>
<p>这种分页方式如果进行深度分页，比如到100页，每页十条数据，它会从每个分片都查询出100*10条数据，假设有五个分片，就是5000条数据，然后在内存中进行排序，然后返回拍过序之后的集合中的第1000-1010条数据</p>
<h4 id="3-指定查询出来的数据返回的字段"><a href="#3-指定查询出来的数据返回的字段" class="headerlink" title="3. 指定查询出来的数据返回的字段"></a>3. 指定查询出来的数据返回的字段</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     },
     &quot;_source&quot;: [&quot;name&quot;,&quot;price&quot;]
   }</code></pre>
<p>返回的数据中只返回<code>name</code>和<code>price</code>字段</p>
<h4 id="4-ad字段中包含单词white"><a href="#4-ad字段中包含单词white" class="headerlink" title="4. ad字段中包含单词white"></a>4. ad字段中包含单词white</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: &quot;white&quot;
       }
     }
   }</code></pre>
<p>返回的结果中元字段<code>_score</code>有评分，说明使用<code>query</code>会计算评分</p>
<h4 id="5-ad字段中包含单词white，并按照价格升序排列"><a href="#5-ad字段中包含单词white，并按照价格升序排列" class="headerlink" title="5. ad字段中包含单词white，并按照价格升序排列"></a>5. ad字段中包含单词white，并按照价格升序排列</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: &quot;white&quot;
       }
     }, 
     &quot;sort&quot;: [
       {
         &quot;price&quot;: {
           &quot;order&quot;: &quot;asc&quot;
         }
       }
     ]
   }</code></pre>
<h4 id="6-价格字段大于5000"><a href="#6-价格字段大于5000" class="headerlink" title="6. 价格字段大于5000"></a>6. 价格字段大于5000</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;filter&quot;: {
           &quot;range&quot;: {
             &quot;price&quot;: {
               &quot;gt&quot;: 5000
             }
           }
         }
       }
     }
   }</code></pre>
<p>返回的结果中元字段<code>_score</code>字段等于0，没评分，说明使用<code>filter</code>不会计算评分</p>
<h4 id="7-ad字段中包含单词white，价格字段大于5000"><a href="#7-ad字段中包含单词white，价格字段大于5000" class="headerlink" title="7. ad字段中包含单词white，价格字段大于5000"></a>7. ad字段中包含单词white，价格字段大于5000</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;must&quot;: [
           {
             &quot;match&quot;: {
               &quot;ad&quot;: &quot;white&quot;
             }
           }
         ], 
         &quot;filter&quot;: {
           &quot;range&quot;: {
             &quot;price&quot;: {
               &quot;gt&quot;: 5000
             }
           }
         }
       }
     }
   }</code></pre>
<h4 id="8-查询name字段包含单词phone的文档的数量"><a href="#8-查询name字段包含单词phone的文档的数量" class="headerlink" title="8. 查询name字段包含单词phone的文档的数量"></a>8. 查询<code>name</code>字段包含单词<code>phone</code>的文档的数量</h4><pre><code class="json">   GET /ad/phone/_count
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;name&quot;: &quot;phone&quot;
       }
     }
   }</code></pre>
<h3 id="关键词详解"><a href="#关键词详解" class="headerlink" title="关键词详解"></a>关键词详解</h3><h4 id="1-match-all查询"><a href="#1-match-all查询" class="headerlink" title="1. match_all查询"></a>1. <code>match_all</code>查询</h4><p>查询简单的匹配所有文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     }
   }</code></pre>
<h4 id="2-match查询"><a href="#2-match查询" class="headerlink" title="2. match查询"></a>2. <code>match</code>查询</h4><p>支持全文搜索和精确查询，取决于字段是否支持全文检索</p>
<p>全文检索：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: &quot;a red&quot;
       }
     }
   }</code></pre>
<p>全文检索会将查询的字符串先进行分词，<code>a red</code>会分成为<code>a</code>和<code>red</code>，然后在倒排索引中进行匹配，所以这条语句会将三条文档都查出来</p>
<p>精确查询：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;price&quot;: &quot;6000&quot;
       }
     }
   }</code></pre>
<p>对于精确值的查询，可以使用 filter 语句来取代 query，因为 filter 将会被缓存</p>
<p><code>operator</code>操作：</p>
<p><code>match</code> 查询还可以接受 <code>operator</code> 操作符作为输入参数，默认情况下该操作符是 <code>or</code> 。我们可以将它修改成 <code>and</code> 让所有指定词项都必须匹配</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: {
           &quot;query&quot;: &quot;a red&quot;,
           &quot;operator&quot;: &quot;and&quot;
         }
       }
     }
   }</code></pre>
<p>精确度匹配：</p>
<p><code>match</code> 查询支持 <code>minimum_should_match</code> 最小匹配参数， 可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字（指需要匹配倒排索引的词的数量），更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: {
           &quot;query&quot;: &quot;a red&quot;,
           &quot;minimum_should_match&quot;: &quot;2&quot;
         }
       }
     }
   }</code></pre>
<p>   只会返回匹配上<code>a</code>和<code>red</code>两个词的文档返回，如果<code>minimum_should_match</code>是1，则只要匹配上其中一个词，文档就会返回</p>
<h4 id="3-multi-match查询"><a href="#3-multi-match查询" class="headerlink" title="3. multi_match查询"></a>3. <code>multi_match</code>查询</h4><p>多字段查询，比如查询<code>color</code>和<code>ad</code>字段包含单词<code>red</code>的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;multi_match&quot;: {
         &quot;query&quot;: &quot;red&quot;,
         &quot;fields&quot;: [&quot;color&quot;,&quot;ad&quot;]
       }
     }
   }</code></pre>
<h4 id="4-range查询"><a href="#4-range查询" class="headerlink" title="4. range查询"></a>4. <code>range</code>查询</h4><p>   范围查询，查询价格大于4000小于6000的文档</p>
<pre><code>   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;range&quot;: {
         &quot;price&quot;: {
           &quot;gt&quot;: 4000,
           &quot;lt&quot;: 6000
         }
       }
     }
   }</code></pre><p>   范围查询操作符：<code>gt</code> （大于），<code>gte</code>（大于等于），<code>lt</code>（小于），<code>lte</code>（小于等于)；</p>
<h4 id="5-term查询"><a href="#5-term查询" class="headerlink" title="5. term查询"></a>5. <code>term</code>查询</h4><p>   精确值查询</p>
<p>   查询<code>price</code>字段等于6000的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;term&quot;: {
         &quot;price&quot;: {
           &quot;value&quot;: &quot;6000&quot;
         }
       }
     }
   }</code></pre>
<p>   查询<code>name</code>字段等于<code>phone 8</code>的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;term&quot;: {
         &quot;name&quot;: {
           &quot;value&quot;: &quot;phone 8&quot;
         }
       }
     }
   }</code></pre>
<p>   返回值如下，没有查询到名称为<code>phone 8</code>的文档</p>
<pre><code class="json">   {
     &quot;took&quot;: 5,
     &quot;timed_out&quot;: false,
     &quot;_shards&quot;: {
       &quot;total&quot;: 5,
       &quot;successful&quot;: 5,
       &quot;skipped&quot;: 0,
       &quot;failed&quot;: 0
     },
     &quot;hits&quot;: {
       &quot;total&quot;: 0,
       &quot;max_score&quot;: null,
       &quot;hits&quot;: []
     }
   }</code></pre>
<p>   为什么没有查到<code>phone 8</code>的这个文档那，这里需要介绍一下<code>term</code>的查询原理</p>
<pre><code>   `term`查询会去倒排索引中寻找确切的`term`,它并不会走分词器，只会去配倒排索引 ，而`name`字段的`type`类型是`text`，会进行分词，将`phone 8 ` 分为`phone`和`8`，我们使用`term`查询`phone 8`时倒排索引中没有`phone 8`，所以没有查询到匹配的文档</code></pre><p>   <code>term</code>查询与<code>match</code>查询的区别</p>
<ul>
<li><p><code>term</code>查询时，不会分词，直接匹配倒排索引</p>
</li>
<li><p><code>match</code>查询时会进行分词，查询<code>phone 8</code>时，会先分词成<code>phone</code>和<code>8</code>，然后去匹配倒排索引，所以结果会将<code>phone 8</code>和<code>xiaomi 8</code>两个文档都查出来</p>
<p>还有一点需要注意，因为<code>term</code>查询不会走分词器，但是回去匹配倒排索引，所以查询的结构就跟分词器如何分词有关系，比如新增一个<code>/ad/phone</code>类型下的文档，<code>name</code>字段赋值为<code>Oppo</code>，这时使用<code>term</code>查询<code>Oppo</code>不会查询出文档，这时因为es默认是用的<code>standard</code>分词器，它在分词后会将单词转成小写输出，所以使用<code>oppo</code>查不出文档，使用小写<code>oppo</code>可以查出来</p>
</li>
</ul>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;term&quot;: {
         &quot;name&quot;: {
           &quot;value&quot;: &quot;Oppo&quot; //改成oppo可以查出新添加的文档
         }
       }
     }
   }</code></pre>
<p>   这里说的并不是想让你了解<code>standard</code>分词器，而是要get到所有像<code>term</code>这类的查询结果跟选择的分词器有关系，了解选择的分词器分词方式有助于我们编写查询语句</p>
<h4 id="6-terms查询"><a href="#6-terms查询" class="headerlink" title="6. terms查询"></a>6. <code>terms</code>查询</h4><p>   <code>terms</code>查询与<code>term</code>查询一样，但它允许你指定多直进行匹配，如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;terms&quot;: {
         &quot;ad&quot;: [&quot;red&quot;,&quot;blue&quot;]
       }
     }
   }</code></pre>
<h4 id="7-exists-查询和-missing-查询"><a href="#7-exists-查询和-missing-查询" class="headerlink" title="7. exists 查询和 missing 查询"></a>7. <code>exists</code> 查询和 <code>missing</code> 查询</h4><p>   用于查找那些指定字段中有值 (<code>exists</code>) 或无值 (<code>missing</code>) 的文档</p>
<p>   指定<code>name</code>字段有值：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;filter&quot;: {
           &quot;exists&quot;: {
             &quot;field&quot;: &quot;name&quot;
           }
         }
       }
     }
   }</code></pre>
<p>   指定<code>name</code>字段无值：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;filter&quot;: {
           &quot;missing&quot;: {
             &quot;field&quot;: &quot;name&quot;
           }
         }
       }
     }
   }</code></pre>
<h4 id="8-match-phrase查询"><a href="#8-match-phrase查询" class="headerlink" title="8. match_phrase查询"></a>8. <code>match_phrase</code>查询</h4><p>   短语查询，精确匹配，查询<code>a red</code>会匹配<code>ad</code>字段包含<code>a red</code>短语的，而不会进行分词查询，也不会查询出包含<code>a 其他词 red</code>这样的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_phrase&quot;: {
         &quot;ad&quot;: &quot;a red&quot;
       }
     }
   }</code></pre>
<h4 id="9-scroll查询"><a href="#9-scroll查询" class="headerlink" title="9. scroll查询"></a>9. <code>scroll</code>查询</h4><p>   类似于分页查询，不支持跳页查询，只能一页一页往下查询，<code>scroll</code>查询不是针对实时用户请求，而是针对处理大量数据，例如为了将一个索引的内容重新索引到具有不同配置的新索引中</p>
<pre><code class="json">   POST /ad/phone/_search?scroll=1m
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     },
     &quot;size&quot;: 1,
     &quot;from&quot;: 0
   }</code></pre>
<p>   返回值包含一个  <code>&quot;_scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAAQFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAERZVek91amNjWlQwS0RubmV3YmdIRWFBAAAAAAAAABIWVXpPdWpjY1pUMEtEbm5ld2JnSEVhQQAAAAAAAAATFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAFBZVek91amNjWlQwS0RubmV3YmdIRWFB&quot;</code></p>
<p>   下次查询的时候使用<code>_scroll_id</code>就可以查询下一页的文档</p>
<pre><code class="json">   POST /_search/scroll 
   {
       &quot;scroll&quot; : &quot;1m&quot;, 
       &quot;scroll_id&quot; : &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAAYFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAGRZVek91amNjWlQwS0RubmV3YmdIRWFBAAAAAAAAABYWVXpPdWpjY1pUMEtEbm5ld2JnSEVhQQAAAAAAAAAXFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAFRZVek91amNjWlQwS0RubmV3YmdIRWFB&quot; 
   }</code></pre>
<h4 id="10-multi-get查询"><a href="#10-multi-get查询" class="headerlink" title="10. multi get查询"></a>10. <code>multi get</code>查询</h4><p>允许基于索引，类型（可选）和id（以及可能的路由）获取多个文档，如果某个文档获取失败则将错误信息包含在响应中</p>
<pre><code>​```json
GET /ad/phone/_mget
{
  &quot;ids&quot;: [&quot;1&quot;,&quot;8&quot;]
}
​```</code></pre><h4 id="11-bulk批量操作"><a href="#11-bulk批量操作" class="headerlink" title="11. bulk批量操作"></a>11. <code>bulk</code>批量操作</h4><p><code>bulk</code>批量操作可以在单次API调用中实现多个文档的<code>create</code>、<code>index</code>、<code>update</code>或<code>delete</code>。这可以大大提高索引速度</p>
<p><code>bulk</code>请求体如下</p>
<pre><code class="json">{ action: { metadata }}\n 
{ request body        }\n
{ action: { metadata }}\n
{ request body        }\n
...</code></pre>
<p><strong>action</strong>必须是以下几种：<br>| 行为   | 解释                     |<br>| —— | ———————— |<br>| create | 当文档不存在时创建       |<br>| index  | 创建新文档或替换已有文档 |<br>| update | 局部更新文档             |<br>| delete | 删除一个文档             |<br>在索引、创建、更新或删除时必须指定文档的<code>_index</code>、<code>_type</code>、<code>_id</code>这些元数据(<code>metadata</code>)</p>
<p>例：</p>
<pre><code class="json">    PUT _bulk
    { &quot;create&quot; : { &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;6&quot; }}
    { &quot;doc&quot; : {&quot;name&quot; : &quot;bulk&quot;}}
    { &quot;index&quot; : { &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;6&quot; }}
    { &quot;doc&quot; : {&quot;name&quot; : &quot;bulk&quot;}}
    { &quot;delete&quot;:{  &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;1&quot;}}
    { &quot;update&quot;:{  &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;3&quot;}}
    { &quot;doc&quot; : {&quot;name&quot; : &quot;huawei p20&quot;}}</code></pre>
<p>返回：</p>
<pre><code class="json">    {
      &quot;took&quot;: 137,
      &quot;errors&quot;: true, //如果任意一个文档出错，这里返回true,
      &quot;items&quot;: [ //items数组，它罗列了每一个请求的结果，结果的顺序与我们请求的顺序相同
        {
          //create这个文档已经存在，所以异常
          &quot;create&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;6&quot;,
            &quot;status&quot;: 409,
            &quot;error&quot;: {
              &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,
              &quot;reason&quot;: &quot;[phone][6]: version conflict, document already exists (current version [2])&quot;,
              &quot;index_uuid&quot;: &quot;9F5FHqgISYOra_P09HReVQ&quot;,
              &quot;shard&quot;: &quot;2&quot;,
              &quot;index&quot;: &quot;ad&quot;
            }
          }
        },
        {
          //index这个文档已经存在，会覆盖
          &quot;index&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;6&quot;,
            &quot;_version&quot;: 3,
            &quot;result&quot;: &quot;updated&quot;,
            &quot;_shards&quot;: {
              &quot;total&quot;: 2,
              &quot;successful&quot;: 1,
              &quot;failed&quot;: 0
            },
            &quot;_seq_no&quot;: 6,
            &quot;_primary_term&quot;: 5,
            &quot;status&quot;: 200
          }
        },
        {
          //删除  
          &quot;delete&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;1&quot;,
            &quot;_version&quot;: 1,
            &quot;result&quot;: &quot;not_found&quot;,
            &quot;_shards&quot;: {
              &quot;total&quot;: 2,
              &quot;successful&quot;: 1,
              &quot;failed&quot;: 0
            },
            &quot;_seq_no&quot;: 4,
            &quot;_primary_term&quot;: 5,
            &quot;status&quot;: 404
          }
        },
        {
          //修改  
          &quot;update&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;3&quot;,
            &quot;_version&quot;: 3,
            &quot;result&quot;: &quot;noop&quot;,
            &quot;_shards&quot;: {
              &quot;total&quot;: 2,
              &quot;successful&quot;: 1,
              &quot;failed&quot;: 0
            },
            &quot;status&quot;: 200
          }
        }
      ]
    }</code></pre>
<p><code>bulk</code>请求不是原子操作，它们不能实现事务。每个请求操作时分开的，所以每个请求的成功与否不干扰其它操作</p>
<h4 id="12-fuzzy查询"><a href="#12-fuzzy查询" class="headerlink" title="12. fuzzy查询"></a>12. <code>fuzzy</code>查询</h4><p>模糊查询，<code>fuzzy</code> 查询会计算与关键词的拼写相似程度</p>
<pre><code class="json">    GET /ad/phone/_search
    {
      &quot;query&quot;: {
        &quot;fuzzy&quot;: {
          &quot;color&quot;:{
            &quot;value&quot;: &quot;res&quot;
            , &quot;fuzziness&quot;: 2,
            &quot;prefix_length&quot;: 1
          }
        }
      }
    }</code></pre>
<p>参数设置：</p>
<p><code>fuzziness</code>：最大编辑距离，默认为<code>AUTO</code></p>
<p><code>prefix_length</code>：不会“模糊化”的初始字符数。这有助于减少必须检查的术语数量，默认为<code>0</code></p>
<p><code>max_expansions</code>：<code>fuzzy</code>查询将扩展到 的最大术语数。默认为<code>50</code>，设置小，有助于优化查询</p>
<p><code>transpositions</code>：是否支持模糊转置（<code>ab</code>→ <code>ba</code>），默认是<code>false</code></p>
<h4 id="13-wildcard查询"><a href="#13-wildcard查询" class="headerlink" title="13. wildcard查询"></a>13. <code>wildcard</code>查询</h4><p>支持通配符的模糊查询，？匹配单个字符，*匹配任何字符</p>
<p>为了防止极其缓慢通配符查询，<code>*</code>或<code>?</code>通配符项不应该放在通配符的开始</p>
<pre><code class="json">    GET /ad/phone/_search
    {
      &quot;query&quot;: {
        &quot;wildcard&quot;: {
          &quot;color&quot;: &quot;r?d&quot;
        }
      }
    }</code></pre>
<p>未完待续…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/es-query/" data-id="ckdn6w7zn002uaktwen7v5wuc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/" rel="tag">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-mysql-one" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/mysql-one/" class="article-date">
  <time datetime="2019-07-09T06:58:39.000Z" itemprop="datePublished">2019-07-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/mysql/">mysql</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/mysql-one/">mysql系列</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>本文内容为：极客时间《mysql45讲》的内容</p>
</blockquote>
<h3 id="1-基础架构：一条SQL查询语句是如何执行的"><a href="#1-基础架构：一条SQL查询语句是如何执行的" class="headerlink" title="1.基础架构：一条SQL查询语句是如何执行的 ?"></a>1.基础架构：一条SQL查询语句是如何执行的 ?</h3><p>执行下面这个查询语句时 ,在 MySQL 内部的执行过程 </p>
<pre><code class="sql">select * from T where id = 10;</code></pre>
<p><img src="mysql-one/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.png" alt=""></p>
<p>大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。</p>
<p>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服<br>务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都<br>在这一层实现，比如存储过程、触发器、视图等。</p>
<p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、<br>Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成<br>为了默认存储引擎 </p>
<p><strong>连接器：</strong></p>
<p>链接客户端，校验权限</p>
<p><strong>缓存：</strong></p>
<p>MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过<br>的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，<br>value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直<br>接返回给客户端 </p>
<p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存<br>中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结<br>果，这个效率会很高。 </p>
<p>但是很少使用缓存，因为只要更新表，表对应的缓存就全部失效</p>
<p>你可以将参数 query_cache_type 设置成<br>DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语<br>句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：</p>
<p>需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没</p>
<pre><code class="sql">select SQL_CACHE * from T where ID=10 ;</code></pre>
<p><strong>分析器：</strong></p>
<p>分析sql语句，是否满足 MySQL 语法</p>
<p>如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒 </p>
<p><strong>优化器：</strong></p>
<p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）<br>的时候，决定各个表的连接顺序 </p>
<p><strong>执行器：</strong></p>
<p>开始执行语句 </p>
<p>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没<br>有权限的错误 </p>
<pre><code class="sql">ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39; </code></pre>
<p>如果有权限，就打开表继续执行。打开表的时候，优化器就会根据表的引擎定义，去使用这个引<br>擎提供的接口 </p>
<h3 id="2-日志系统：一条SQL更新语句是如何执行的？"><a href="#2-日志系统：一条SQL更新语句是如何执行的？" class="headerlink" title="2.日志系统：一条SQL更新语句是如何执行的？"></a>2.日志系统：一条SQL更新语句是如何执行的？</h3><p>流程和查询相似，一条update语句会对应表的所有删除缓存</p>
<p><strong>redo log</strong></p>
<p>InnoDB 引擎特有的日志</p>
<p>在MySQL 中，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了redo log（重做日志） 来提升更新效率 </p>
<p>关键点就是先写日志，再写磁盘 ，mysql会先把记录写到redo log里面，并更新到内存，这个时候就算完成更新了，innoDB引擎会在适当的时候将这个操作记录更新到磁盘里</p>
<p><img src="mysql-one/2.png" alt=""></p>
<p>wirte pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。<br>checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据<br>文件 </p>
<p>有了redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，<br>这个能力称为crash-safe </p>
<p><strong>WAL</strong>的全称是<strong>Write-Ahead Logging</strong>，它的关键点就是先写日志，再写磁盘</p>
<p><strong>binlog</strong></p>
<p>binlog（归档日志） 是server层实现的，可用于恢复数据库，主从之间同步数据</p>
<p><img src="mysql-one/3.png" alt=""></p>
<p>Redo log是记录这个页 “做了什么改动”。<br>Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，<br>更新前和更新后都有</p>
<p>update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的</p>
<p><img src="mysql-one/4.png" alt=""></p>
<p><strong>两阶段提交</strong> </p>
<p>redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致 </p>
<p>更多详细阅读：<a href="https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html" target="_blank" rel="noopener">https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html</a></p>
<h3 id="3-事务隔离：为什么你改了我还看不见？"><a href="#3-事务隔离：为什么你改了我还看不见？" class="headerlink" title="3.事务隔离：为什么你改了我还看不见？"></a>3.事务隔离：为什么你改了我还看不见？</h3><p>SQL 标准的事务隔离级别包括：</p>
<ol>
<li><p>读未提交（readuncommitted）</p>
<p>一个事务还没提交时，它做的变更就能被别的事务看到</p>
</li>
<li><p>读提交（read committed）</p>
<p>一个事务提交之后，它做的变更才会被其他事务看到 </p>
</li>
<li><p>可重复读（repeatable read）</p>
<p>一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的 </p>
</li>
<li><p>串行化（serializable ） </p>
<p>顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行 </p>
</li>
</ol>
<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>
<ol>
<li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</li>
<li>在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。</li>
<li>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念</li>
<li>“串行化”隔离级别下直接用加锁的方式来避免并行访问 </li>
</ol>
<p>设置mysql事务隔离级别</p>
<p>将transaction-isolation 的值设置成 READ-COMMITTED </p>
<p>show variables like ‘transaction_isolation’; 查看当前事务隔离级别</p>
<p>oracle默认事务隔离级别为读提交</p>
<p>mysql默认事务隔离级别为可重复读</p>
<h3 id="4-深入浅出索引"><a href="#4-深入浅出索引" class="headerlink" title="4.深入浅出索引"></a>4.深入浅出索引</h3><p>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样 </p>
<p><strong>索引的常见模型</strong> </p>
<p>介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树 </p>
<p>哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。 </p>
<p>哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。</p>
<p> 如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 </p>
<p>所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据 </p>
<p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子 </p>
<p><strong>索引类型</strong></p>
<p>分为主键索引和非主键索引 </p>
<p>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。 </p>
<p>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引 </p>
<p>根据上面的索引结构说明，我们来讨论一个问题：<strong>基于主键索引和普通索引的查询有什么区别？</strong></p>
<ul>
<li>如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+树；</li>
<li>如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。</li>
</ul>
<p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 </p>
<p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。<br>显然，<strong>主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong> </p>
<p><strong>回到主键索引树搜索的过程，我们称为回表</strong> </p>
<p><strong>覆盖索引</strong><br>如果执行的语句是 <code>select ID from T where k between 3 and 5</code>，这时只需要查 ID 的值，而ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p>
<p><strong>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</strong> </p>
<p>如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。</p>
<p>当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作 （不建议这么做）</p>
<p><strong>最左前缀原则</strong> </p>
<p><strong>B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong> </p>
<p>在建立联合索引的时候，如何安排索引内的字段顺序？<br>这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，<strong>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</strong> </p>
<p>如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。<br>这时候，我们要<strong>考虑的原则就是空间</strong>了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引 </p>
<p><strong>索引下推</strong> </p>
<p>以联合索引（name, age）为例 。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： </p>
<pre><code class="sql">select * from tuser where name like &#39;张 %&#39; and age=10 and ismale=1;</code></pre>
<p>在 <strong>MySQL 5.6</strong> 之前 ，只能用 “张”，找到第一个满足条件的记录 ID3 ，从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 </p>
<p><strong>在联合索引中，匹配name后会进行回表，然后从主键索引上找出数据行，在数据上进行age字段比对</strong></p>
<p><img src="mysql-one/5.png" alt=""></p>
<p>而 <strong>MySQL 5.6</strong> 引入的<strong>索引下推</strong>优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 </p>
<p><img src="mysql-one/6.png" alt=""></p>
<p>在<strong>索引下推</strong>优化下，<strong>在联合索引中，先匹配name，在不回表的情况下，接着比对age字段，不满足条件的记录直接过滤，只有满足条件的的才会进行回表，减少回表次数</strong></p>
<h3 id="5-全局锁和表锁-：给表加个字段怎么有这么多阻碍"><a href="#5-全局锁和表锁-：给表加个字段怎么有这么多阻碍" class="headerlink" title="5.全局锁和表锁 ：给表加个字段怎么有这么多阻碍"></a>5.全局锁和表锁 ：给表加个字段怎么有这么多阻碍</h3><p>根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类 </p>
<p><strong>全局锁</strong> </p>
<p>全局锁就是对整个数据库实例加锁 </p>
<p>MySQL 提供了一个加全局读锁的方法，命令是<code>Flush tables with read lock (FTWRL)</code>。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句 </p>
<p><strong>全局锁的典型使用场景是，做全库逻辑备份</strong> </p>
<p>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数<code>–single-transaction</code> 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。 （前提是引擎要支持这个隔离级别 ）</p>
<p><strong>single-transaction 方法只适用于所有的表使用事务引擎的库 （innodb）</strong></p>
<p><strong>表级锁</strong> </p>
<p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 </p>
<p>表锁的语法是 <code>lock tables … read/write</code> </p>
<p>与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象 </p>
<p><strong>另一类表级的锁是 MDL（metadata lock)</strong> </p>
<p>MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。 </p>
<p>在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。</p>
<ol>
<li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li>
<li>读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 </li>
</ol>
<p>MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。 </p>
<p><img src="mysql-one/7.png" alt=""></p>
<p>我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。<br>之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要MDL 写锁，因此只能被阻塞。<br>如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。<br>如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session再请求的话，这个库的线程很快就会爆满。<br>你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放 </p>
<h3 id="6-行锁功过：怎么减少行锁对性能的影响？"><a href="#6-行锁功过：怎么减少行锁对性能的影响？" class="headerlink" title="6.行锁功过：怎么减少行锁对性能的影响？"></a>6.行锁功过：怎么减少行锁对性能的影响？</h3><p><strong>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议</strong> </p>
<p><img src="mysql-one/8.png" alt=""></p>
<p>实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。 </p>
<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、<strong>最可能影响并发度的锁尽量往后放</strong> </p>
<p><strong>死锁和死锁检测</strong> </p>
<p><img src="mysql-one/9.png" alt=""></p>
<p>事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p>
<ul>
<li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。</li>
<li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事<br>务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑 </li>
</ul>
<p>在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的 </p>
<p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的 </p>
<h3 id="7-事务到底是隔离的还是不隔离的？"><a href="#7-事务到底是隔离的还是不隔离的？" class="headerlink" title="7.事务到底是隔离的还是不隔离的？"></a>7.事务到底是隔离的还是不隔离的？</h3><p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的up_limit_id。普通查询语句是一致性读，一致性读会根据 row trx_id 和 up_limit_id 的大小决定数据版本的可见性。</p>
<ul>
<li>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；</li>
<li>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</li>
</ul>
<p>而当前读，总是读取已经提交完成的最新版本 </p>
<p><img src="mysql-one/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB.png" alt=""></p>
<p>语句 Q1 返回的 k 的值是 3，而语句 Q2 返回的 k 的值是 1 </p>
<p><strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读（current read） “</strong></p>
<p><strong>InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。版本号就是事务Id</strong> </p>
<h3 id="8-普通索引和唯一索引，应该怎么选择？"><a href="#8-普通索引和唯一索引，应该怎么选择？" class="headerlink" title="8.普通索引和唯一索引，应该怎么选择？"></a>8.普通索引和唯一索引，应该怎么选择？</h3><p>对于查询过程来说：<br>a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，知道第一个不满足条件的记录<br>b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索</p>
<p>但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。</p>
<p>对于更新过程来说：</p>
<p>概念：<strong>change buffer</strong></p>
<p>当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中的与这个页有关的操作。</p>
<p>change buffer是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上</p>
<p>purge:将change buffer中的操作应用到原数据页上，得到最新结果的过程，成为purge访问这个数据页会触发purge，系统有后台线程定期purge，在数据库正常关闭的过程中，也会执行purge</p>
<p><strong>唯一索引的更新不能使用change buffer</strong><br>change buffer用的是buffer pool里的内存，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。<br>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。<br>change buffer使用场景<br>在一个数据页做purge之前，change buffer记录的变更越多，收益就越大。对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer,但之后由于马上要访问这个数据页，会立即触发purge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。</p>
<p><strong>索引的选择和实践：</strong><br>尽可能使用普通索引。<br>redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是<br>随机读磁盘的IO消耗。 </p>
<p><strong>命令：</strong></p>
<p><strong>参数</strong>：innodb_buffer_pool_size</p>
<p><strong>介绍</strong>：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。</p>
<p><strong>参数</strong>：innodb_old_blocks_pct</p>
<p><strong>介绍</strong>：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。</p>
<p><em>画外音：如果把这个参数设为100，就退化为普通LRU了。</em></p>
<p><strong>参数</strong>：innodb_old_blocks_time</p>
<p><strong>介绍</strong>：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。</p>
<p><strong>总结</strong></p>
<p>（1）<strong>缓冲池(buffer pool)</strong>是一种<strong>常见的降低磁盘访问的机制；</strong></p>
<p>（2）缓冲池通常<strong>以页(page)为单位缓存数据；</strong></p>
<p>（3）缓冲池的<strong>常见管理算法是LRU</strong>，memcache，OS，InnoDB都使用了这种算法；</p>
<p>（4）InnoDB对普通LRU进行了优化：</p>
<ul>
<li>将缓冲池分为<strong>老生代和新生代</strong>，入缓冲池的页，优先进入老生代，页被访问，才进入新生代，以解决预读失效的问题</li>
<li>页被访问，且在老生代<strong>停留时间超过配置阈值</strong>的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题</li>
</ul>
<h3 id="9-MySQL为什么有时候会选错索引？"><a href="#9-MySQL为什么有时候会选错索引？" class="headerlink" title="9.MySQL为什么有时候会选错索引？"></a>9.MySQL为什么有时候会选错索引？</h3><p><strong>优化器的逻辑</strong> </p>
<p>优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 </p>
<p>MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。<br>这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好 </p>
<p><strong>使用  show index 方法，看到一个索引的基数</strong> </p>
<p><img src="mysql-one/cardinality.png" alt=""></p>
<p>从图中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。<br>其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行 </p>
<p><img src="mysql-one/explain.png" alt=""></p>
<p>rows 这个字段表示的是预计扫描行数 </p>
<p>rows 统计信息不对，那就修正。<strong>analyze table t</strong> 命令，可以用来重新统计索引信息 </p>
<p><strong>索引选择异常和处理</strong></p>
<p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？ </p>
<p><strong>第一种方法是，采用 force index 强行选择一个索引</strong> </p>
<p>不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容 </p>
<p><strong>第二种方法是，可以考虑修改语句，引导 MySQL 使用我们期望的索引</strong> </p>
<p>比如，在这个例子里，显然把“order by b limit 1”改成 “order by b,a limit 1” ，语义的逻辑是相同的 </p>
<p>![](mysql-one/force index.png)</p>
<p>之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。 </p>
<p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引</strong> </p>
<h3 id="10-怎么给字符串字段加索引？"><a href="#10-怎么给字符串字段加索引？" class="headerlink" title="10.怎么给字符串字段加索引？"></a>10.怎么给字符串字段加索引？</h3><p>比如，这两个在 email 字段上创建索引的语句： </p>
<pre><code class="sql">mysql&gt; alter table SUser add index index1(email);
或
mysql&gt; alter table SUser add index index2(email(6)); </code></pre>
<p>第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的index2 索引里面，对于每个记录都是只取前 6 个字节 <strong>(前缀索引)</strong></p>
<p>由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（如：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势 </p>
<p><strong>使用前缀索引后，可能会导致查询语句读数据的次数变多</strong> </p>
<p><strong>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本</strong> </p>
<p>实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀 </p>
<pre><code class="sql">mysql&gt; select count(distinct email) as L from SUser; </code></pre>
<p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句： </p>
<pre><code class="sql">mysql&gt; select
    count(distinct left(email,4)）as L4,
    count(distinct left(email,5)）as L5,
    count(distinct left(email,6)）as L6, 
    count(distinct left(email,7)）as L7
from SUser; </code></pre>
<p>当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6 </p>
<p><strong>前缀索引对覆盖索引的影响</strong> </p>
<p>使用前缀索引就<strong>用不上</strong>覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素 </p>
<p>如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值 </p>
<p><strong>小结</strong></p>
<p>字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：</p>
<ol>
<li>直接创建完整索引，这样可能比较占用空间；</li>
<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li>
<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li>
<li>创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不<br> 支持范围扫描 </li>
</ol>
<h3 id="11-为什么我的MySQL会“抖”一下？"><a href="#11-为什么我的MySQL会“抖”一下？" class="headerlink" title="11.为什么我的MySQL会“抖”一下？"></a>11.为什么我的MySQL会“抖”一下？</h3><p><strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</strong> </p>
<p>不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush） </p>
<p><strong>那么，什么情况会引发数据库的 flush 过程呢？</strong> </p>
<p><strong>第一种场景：</strong>对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把checkpoint 往前推进，redo log 留出空间可以继续写 </p>
<p><strong>第二种场景：</strong>系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘 </p>
<p><strong>第三种场景：</strong>当MySQL 认为系统“空闲” 时，会刷“脏页”</p>
<p><strong>第四种场景：</strong>MySQL 正常关闭的情况下会把内存中的脏页都flush到磁盘上</p>
<p><strong>分析一下上面四种场景对性能的影响</strong> </p>
<p>第三种属于系统空闲时间操作的没有什么压力，第四种是正常关闭也不会对性能有影响，所以我们主要分析前两种场景</p>
<p>第一种，“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0 </p>
<p>第二种，第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存</p>
<p>缓冲池中的内存页有三种状态： </p>
<ol>
<li>第一种是，还没有使用的；</li>
<li>第二种是，使用了并且是干净页； </li>
<li>第三种是，使用了并且是脏页。 </li>
</ol>
<p>InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。 而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。 </p>
<p><strong>刷脏页虽然是常态</strong>，但是出现以下这两种情况，都是会明显影响性能的 :</p>
<ol>
<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； </li>
<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； </li>
</ol>
<p>所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。 </p>
<p><strong>InnoDB 刷脏页的控制策略</strong> </p>
<p>设置innodb_io_capacity 参数，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS 。磁盘的 IOPS 可以通过 fio 这个工具来测试 </p>
<p>现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。  </p>
<p>要尽量避免这种情况，你就要合理地设置 <strong>innodb_io_capacity</strong> 的值 </p>
<p>一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷 </p>
<p>在 InnoDB 中，<strong>innodb_flush_neighbors</strong> 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。 </p>
<p>而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。<br>在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。</p>
<h3 id="12-count-这么慢，我该怎么办？"><a href="#12-count-这么慢，我该怎么办？" class="headerlink" title="12.count(*)这么慢，我该怎么办？"></a>12.count(*)这么慢，我该怎么办？</h3><p><code>count(*)</code> 的实现方式<br>你首先要明确的是，在不同的 MySQL 引擎中，<code>count(*)</code> 有不同的实现方式。</p>
<ol>
<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 <code>count(*)</code> 的时候会直接返回这个数，效率很高； </li>
<li>而 InnoDB 引擎就麻烦了，它执行 <code>count(*)</code> 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数 </li>
</ol>
<p>文章里讨论的是没有过滤条件的 <code>count(*)</code>，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的 </p>
<p><strong>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一</strong> </p>
<p>按照效率排序的话，<code>count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)</code>，所以我建议你，尽量使用 <code>count(*)</code> </p>
<h3 id="13-答疑文章（一）：日志和索引相关问题"><a href="#13-答疑文章（一）：日志和索引相关问题" class="headerlink" title="13.答疑文章（一）：日志和索引相关问题"></a>13.答疑文章（一）：日志和索引相关问题</h3><p>主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？ </p>
<p><strong>我们先来看一下崩溃恢复时的判断规则</strong> </p>
<ol>
<li>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；</li>
<li>如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完<br> 整：<br> a. 如果是，则提交事务；<br> b. 否则，回滚事务；</li>
</ol>
<p>这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交 </p>
<p><strong>追问 1： MySQL 怎么知道 binlog 是完整的?</strong> </p>
<p>回答：一个事务的 binlog 是有完整格式的：</p>
<ol>
<li>statement 格式的 binlog，最后会有 COMMIT；</li>
<li>row 格式的 binlog，最后会有一个 XID event；</li>
</ol>
<p>另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的 </p>
<p><strong>追问 2：redo log 和 binlog 是怎么关联起来的?</strong> </p>
<p>回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log： </p>
<ol>
<li>如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；</li>
<li>如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务；</li>
</ol>
<p><strong>追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?</strong> </p>
<p>回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。<br>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。 </p>
<p><strong>追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</strong> </p>
<p>回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。<br>两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。 </p>
<p><strong>追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？</strong> </p>
<p>回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么“的问题。实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况 </p>
<ol>
<li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。</li>
<li>在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态 </li>
</ol>
<p><strong>追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？</strong> </p>
<p>回答：这两个问题可以一起回答。<br>在一个事务的更新过程中，日志是要写多次的。比如下面这个事务： </p>
<pre><code class="sql">begin;
insert into t1 ...
insert into t2 ...
commit; </code></pre>
<p>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。</p>
<p>所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。</p>
<p>但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。</p>
<p>单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成 </p>
<h3 id="14-“order-by”是怎么工作的？"><a href="#14-“order-by”是怎么工作的？" class="headerlink" title="14.“order by”是怎么工作的？"></a>14.“order by”是怎么工作的？</h3><pre><code class="sql">select city,name,age from t where city=&#39;杭州&#39; order by name limit 1000 ; </code></pre>
<p><strong>全字段排序</strong> </p>
<p>通常情况下，这个语句执行流程如下所示 ：</p>
<ol>
<li>初始化 sort_buffer，确定放入 name、city、age 这三个字段；</li>
<li>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；</li>
<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li>
<li>从索引 city 取下一个记录的主键 id；</li>
<li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li>
<li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li>
<li>按照排序结果取前 1000 行返回给客户端 </li>
</ol>
<p><img src="mysql-one/order.png" alt=""></p>
<p>图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size </p>
<p>sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序 </p>
<p><strong>rowid 排序</strong> </p>
<p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。 </p>
<pre><code class="sql">SET max_length_for_sort_data = 16; </code></pre>
<p><strong>max_length_for_sort_data</strong>，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法 </p>
<p>新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。</p>
<p>但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子： </p>
<ol>
<li><p>初始化 sort_buffer，确定放入两个字段，即 name 和 id；</p>
</li>
<li><p>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；</p>
</li>
<li><p>到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；</p>
</li>
<li><p>从索引 city 取下一个记录的主键 id；</p>
</li>
<li><p>重复步骤 3、4 直到不满足 city=’杭州’条件为止，也就是图中的 ID_Y；</p>
</li>
<li><p>对 sort_buffer 中的数据按照字段 name 进行排序； </p>
</li>
<li><p>遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字<br> 段返回给客户端 </p>
</li>
</ol>
<p>![](mysql-one/order rowid.png)</p>
<p><strong>使用rowId进行排序需要进行回表，在根据主键索引查询一遍数据</strong></p>
<p>max_length_for_sort_data 代表的是字节，如果查询的所有字段字节数大于设置的字节，则使用rowid排序，否则使用全字段排序</p>
<p><strong>全字段排序 VS rowid 排序</strong> </p>
<p>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次</p>
<p>可以排序更多行，但是需要再回到原表去取数据</p>
<p>如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就</p>
<p>会直接从内存里面返回查询结果了，不用再回到原表去取数据 </p>
<p><strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong> </p>
<p>对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择 </p>
<p><strong>覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。</strong> </p>
<ol>
<li><p>无条件查询如果只有order by create_time,即便create_time上有索引,也不会使用到。</p>
<p>因为优化器认为走二级索引再去回表成本比全表扫描排序更高</p>
<p>所以选择走全表扫描,然后根据老师讲的两种方式选择一种来排序</p>
</li>
<li><p>无条件查询但是是order by create_time limit m.如果m值较小,是可以走索引的.</p>
<p>因为优化器认为根据索引有序性去回表查数据,然后得到m条数据,就可以终止循环,那么成本比全表扫描小,则选择走二级索引</p>
</li>
</ol>
<h3 id="15-如何正确地显示随机消息？"><a href="#15-如何正确地显示随机消息？" class="headerlink" title="15.如何正确地显示随机消息？"></a>15.如何正确地显示随机消息？</h3><p><strong>内存临时表</strong> </p>
<p>首先，你会想到用 order by rand() 来实现这个逻辑。 </p>
<pre><code class="sql">mysql&gt; select word from words order by rand() limit 3; </code></pre>
<p>explain 命令来看看这个语句的执行情况 </p>
<p><img src="mysql-one/rand.png" alt=""></p>
<p>Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。 </p>
<p>因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序 </p>
<p><strong>对于 InnoDB 表来说，对于内存表，</strong>回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不</p>
<p>会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所</p>
<p>以，MySQL 这时就会选择 <strong>rowid 排序</strong> </p>
<p>这条语句的执行流程是这样的： </p>
<ol>
<li><p>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。</p>
</li>
<li><p>从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。 </p>
</li>
<li><p>现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R排序。</p>
</li>
<li><p>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。</p>
</li>
<li><p>从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。</p>
</li>
<li><p>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</p>
</li>
<li><p>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003 </p>
</li>
</ol>
<p>应用的是归并排序算法 </p>
<p><strong>MySQL 的表是用什么方法来定位“一行数据”的</strong> </p>
<p>如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid </p>
<p>来作为主键，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。</p>
<ol>
<li>对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；</li>
<li>对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；</li>
<li>MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。 </li>
</ol>
<p><strong>order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。</strong> </p>
<p><strong>磁盘临时表</strong> </p>
<p><strong>tmp_table_size</strong> 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 <strong>tmp_table_size</strong>，那么内存临时表就会转成磁盘临时表。<br>磁盘临时表使用的引擎默认是 InnoDB，是由参数 <strong>internal_tmp_disk_storage_engine</strong> 控制的 </p>
<p><strong>优先队列算法</strong> </p>
<p>可以精确地只得到三个最小值，执行流程如下： </p>
<ol>
<li>对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆； </li>
<li>取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个(R,rowid) 从堆中去掉，换成 (R’,rowid’)； </li>
<li>重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。 </li>
</ol>
<p>如果需要维护的堆大小超过了我设置的 <strong>sort_buffer_size</strong> 大小，就只能使用归并排序算法。 </p>
<h3 id="16-为什么这些SQL语句逻辑相同，性能却差异巨大？"><a href="#16-为什么这些SQL语句逻辑相同，性能却差异巨大？" class="headerlink" title="16.为什么这些SQL语句逻辑相同，性能却差异巨大？"></a>16.为什么这些SQL语句逻辑相同，性能却差异巨大？</h3><pre><code class="sql">select count(*) from tradelog where month(t_modified)=7; </code></pre>
<p>因为对字段使用了month()函数，所以不会走索引</p>
<p><img src="mysql-one/%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0%E4%B8%8D%E8%B5%B0%E7%B4%A2%E5%BC%95.png" alt=""></p>
<p>需要注意的是，优化器并不是要放弃使用这个索引。<br>在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified（走这个索引不应是查询，还有可能是遍历，这里选择的就是遍历索引 t_modified）</p>
<p><strong>一定要注意，优化器会选择代价更小的方案，而这个方案并不固定</strong></p>
<p><strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</strong></p>
<p>不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。 </p>
<p><strong>隐式类型转换</strong> </p>
<pre><code class="sql">select * from tradelog where tradeid=110717; </code></pre>
<p>交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换 </p>
<p>在MySQL 中，字符串和数字做比较的话，是将字符串转换成数字 </p>
<p>所以对于优化器来说，上面的语句相当于：</p>
<pre><code class="sql">select * from tradelog where CAST(tradid AS signed int) = 110717; </code></pre>
<p>也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。 </p>
<p><strong>隐式字符编码转换</strong> </p>
<p>两个表使用的字符集不一样，会导致函数操作，进而导致优化器放弃走树搜索功能</p>
<p><strong>连接过程中要求在被驱动表的索引字段上加函数操作</strong>，是直接导致对被驱动表做全表扫描的原因 </p>
<p>三个例子，其实是在说同一件事儿，即：<strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能</strong> </p>
<p><strong>索引字段不能进行函数操作，但是索引字段的参数可以玩函数</strong></p>
<h3 id="17-为什么我只查一行的语句，也执行这么慢？"><a href="#17-为什么我只查一行的语句，也执行这么慢？" class="headerlink" title="17.为什么我只查一行的语句，也执行这么慢？"></a>17.为什么我只查一行的语句，也执行这么慢？</h3><p><strong>第一类：查询长时间不返回</strong> </p>
<p>等 MDL 锁 ，导致查询阻塞</p>
<p>等 flush ，导致查询阻塞（不过一般不会有这个问题）</p>
<p>等行锁 ，导致查询阻塞</p>
<p><strong>第二类：查询慢</strong> </p>
<p><em>坏查询不一定是慢查询</em> </p>
<p><img src="mysql-one/%E6%9F%A5%E8%AF%A2%E6%85%A2.png" alt=""></p>
<p>session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句 </p>
<p>ession B 更新完 100 万次，生成了 100 万个回滚日志 (undo log) </p>
<p>带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。 </p>
<h3 id="幻读是什么，幻读有什么问题？"><a href="#幻读是什么，幻读有什么问题？" class="headerlink" title="幻读是什么，幻读有什么问题？"></a>幻读是什么，幻读有什么问题？</h3><p><strong>幻读的定义</strong> </p>
<p><strong>幻读</strong>指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 </p>
<p><strong>如何解决幻读？</strong> </p>
<p><strong>间隙锁+行锁（间隙锁是在可重复读隔离级别下才会生效的）</strong> </p>
<p>现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。<br>顾名思义，<strong>间隙锁</strong>，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。 </p>
<p>*<em>间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。再加上 7 个间隙锁。这样就确保了无法再插入新的记录 *</em> </p>
<p>这里的七个间隙值是查询语句进行了全表扫描，所以锁住了整个表，不能进行增删改操作</p>
<p>间隙锁之间都不存在冲突关系</p>
<p><strong>间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间</strong> </p>
<p>使用行锁+间隙锁不会锁住表，只会锁住行锁和间隙锁之间的数据</p>
<h3 id="18-为什么我只改一行的语句，锁这么多？"><a href="#18-为什么我只改一行的语句，锁这么多？" class="headerlink" title="18.为什么我只改一行的语句，锁这么多？"></a>18.为什么我只改一行的语句，锁这么多？</h3><p>总结的加锁规则：</p>
<ol>
<li>原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区<br> 间。</li>
<li>原则 2：查找过程中访问到的对象才会加锁。</li>
<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>
<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key<br> lock 退化为间隙锁。</li>
<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 </li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/mysql-one/" data-id="ckdn6w80f003vaktwegaa4kcu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mysql/" rel="tag">mysql</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-concurrent-thread" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/concurrent-thread/" class="article-date">
  <time datetime="2019-07-08T03:10:54.000Z" itemprop="datePublished">2019-07-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/concurrent-thread/">java并发编程 | 线程详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h3><p>进程：操作系统在运行一个程序的时候就会为其创建一个进程（比如一个java程序），进程是资源分配的最小单位，一个进程包含多个线程</p>
<p>线程：线程是cpu调度的最小单位，每个线程拥有各自的计数器，对战和局部变量等属性，并且能过访问共享的内存变量</p>
<h4 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h4><p>java线程的生命周期总共包括6个阶段：</p>
<ol>
<li>初始状态：线程被创建，但是还没有调用<code>start()</code>方法</li>
<li>运行状态：java中将就绪状态和运行状态统称为运行状态</li>
<li>阻塞状态：线程阻塞，线程等待进入<code>synchronized</code>修饰的代码块或方法</li>
<li>等待状态：线程进入等待状态，需要调用<code>notify()</code>或<code>notifyAll()</code>进行唤醒</li>
<li>超时等待状态：线程进入等待状态，在指定时间后自行返回</li>
<li>终止状态：线程执行完毕</li>
</ol>
<p>在某一时刻，线程只能处于其中的一个状态</p>
<p><img src="concurrent-thread/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png" alt=""></p>
<p>线程初始化后，调用<code>start()</code>方法变为运行状态，调用<code>wait()</code>，<code>join()</code>等方法，线程由运行状态变为等待状态，调用<code>notify()</code>或<code>notifyAll()</code>等方法，线程由等待状态变成运行状态，超时等待状态就是在等待状态基础上加了时间限制，超过规定时间，自动更改为运行状态，当需要执行同步方法时，如果没有获得锁，这时线程状态就变为阻塞状态，直到获取到锁，变为运行状态，当执行完线程的<code>run()</code>方法后，线程变为终止状态</p>
<h5 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h5><p>创建线程有三种方式</p>
<ol>
<li>继承<code>Thread</code>类</li>
<li>实现<code>Runnable</code>接口</li>
<li>实现<code>Callable</code>接口</li>
</ol>
<p><strong>继承<code>Thread</code>类</strong></p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:13
 * @description: 继承Thread类
 */
public class ThreadTest extends Thread{

    @Override
    public void run() {
        IntStream.range(0,10).forEach(i-&gt;{
            System.out.println(this.getName()+&quot;:&quot;+i);
        });
    }

    public static void main(String[] args) {
        Thread thread = new ThreadTest();
        thread.start();
    }
}</code></pre>
<h5 id="实现Runnable接口"><a href="#实现Runnable接口" class="headerlink" title="实现Runnable接口"></a>实现<code>Runnable</code>接口</h5><pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:18
 * @description: 实现Runnable接口
 */
public class RunnableTest implements Runnable {

    @Override
    public void run() {
        IntStream.range(0,10).forEach(i-&gt;{
            System.out.println(Thread.currentThread().getName()+&quot;:&quot;+i);
        });
    }

    public static void main(String[] args) {
        Runnable runnable = new RunnableTest();
        new Thread(runnable,&quot;RunnableTest&quot;).start();
    }
}</code></pre>
<h5 id="实现Callable接口"><a href="#实现Callable接口" class="headerlink" title="实现Callable接口"></a>实现<code>Callable</code>接口</h5><pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:23
 * @description: 实现Callable接口
 */
public class CallableTest implements Callable&lt;Integer&gt; {

    @Override
    public Integer call() throws Exception {
        IntStream.range(0,10).forEach(i-&gt;{
            System.out.println(Thread.currentThread().getName()+&quot;:&quot;+i);
        });
        return -1;
    }

    public static void main(String[] args) throws Exception {
        Callable callable = new CallableTest();
        FutureTask futureTask = new FutureTask(callable);
        new Thread(futureTask,&quot;future&quot;).start();
        System.out.println(&quot;result:&quot;+futureTask.get());
    }
}</code></pre>
<h4 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h4><h5 id="不安全的线程暂停，恢复，停止操作"><a href="#不安全的线程暂停，恢复，停止操作" class="headerlink" title="不安全的线程暂停，恢复，停止操作"></a>不安全的线程暂停，恢复，停止操作</h5><p><code>Thread</code>提供的过期方法可以实现对线程进行暂停<code>suspend()</code>，恢复<code>resume()</code>，停止<code>stop()</code>的操作</p>
<p>例：创建一个线程，<code>run()</code>中循环输出当前时间，在<code>main()</code>方法中对新建线程进行暂停，恢复，停止的操作</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:51
 * @description: 线程的暂停，恢复，停止
 */
public class OperationThread implements Runnable{

    @Override
    public void run() {
        while (true){
            try {
                TimeUnit.SECONDS.sleep(1L);
                System.out.println(Thread.currentThread().getName()+&quot;运行中：&quot;+LocalTime.now());
            }catch (InterruptedException e){
                System.err.println(e.getMessage());
            }
        }
    }

    public static void main(String[] args) throws Exception{
        Runnable runnable = new OperationThread();
        Thread thread = new Thread(runnable,&quot;operationThread&quot;);
        /**
         * 启动，输出当前时间
         */
        thread.start();
        TimeUnit.SECONDS.sleep(3L);

        /**
         * 线程暂停，不在输出当前时间
         */
        System.out.println(&quot;此处暂停：&quot;+LocalTime.now());
        thread.suspend();
        TimeUnit.SECONDS.sleep(3L);

        /**
         * 线程恢复，继续输出当前时间
         */
        System.out.println(&quot;此处恢复：&quot;+LocalTime.now());
        thread.resume();
        TimeUnit.SECONDS.sleep(3L);

        /**
         * 线程停止，不在输出当前时间
         */
        thread.stop();
        System.out.println(&quot;此处停止：&quot;+LocalTime.now());
        TimeUnit.SECONDS.sleep(3L);
    }
}</code></pre>
<p>输出</p>
<p><img src="concurrent-thread/%E7%BA%BF%E7%A8%8B%E6%9A%82%E5%81%9C%EF%BC%8C%E6%81%A2%E5%A4%8D%EF%BC%8C%E5%81%9C%E6%AD%A2%E6%93%8D%E4%BD%9C.png" alt=""></p>
<p>因为是过期方法，所以不推荐使用，使用<code>suspend()</code>方法后，线程不会释放已经占有的资源，就进入睡眠状态，容易引发死锁问题，而使用<code>stop()</code>方法终结一个线程是不会保证线程的资源正常释放的，可能会导致程序异常</p>
<h5 id="安全的线程暂停，恢复（等待-通知机制）"><a href="#安全的线程暂停，恢复（等待-通知机制）" class="headerlink" title="安全的线程暂停，恢复（等待/通知机制）"></a>安全的线程暂停，恢复（等待/通知机制）</h5><p>线程安全的暂停，恢复操作可以使用等待/通知机制代替</p>
<p>相关方法：</p>
<table>
<thead>
<tr>
<th align="left">方法名</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">notify()</td>
<td align="left">通知一个在对象上等待的线程，使其重wait()方法中返回，前提是该线程获得了对象的锁</td>
</tr>
<tr>
<td align="left">notifyAll()</td>
<td align="left">通知所有等待在该对象上的线程</td>
</tr>
<tr>
<td align="left">wait()</td>
<td align="left">调用该方法线程进入等待状态，只有等待另外线程的通知或被中断才会返回，调用该方法会释放对象的锁</td>
</tr>
<tr>
<td align="left">wait(long)</td>
<td align="left">超时等待一段时间（毫秒），如果超过时间就返回</td>
</tr>
<tr>
<td align="left">wait(long,int)</td>
<td align="left">对于超时时间细粒度的控制，可以达到纳秒</td>
</tr>
</tbody></table>
<p>例：创建一个名为<code>waitThread</code>的线程，在<code>run()</code>方法,使用中使用<code>synchronized</code>进行加锁，以变量<code>flag</code>为条件进行<code>while</code>循环，在循环中调用<code>LOCK.wait()</code>方法，此时会释放对象锁，由<code>main()</code>方法获得锁，调用<code>LOCK.notify()</code>方法通知<code>LOCK</code>对象上等待的<code>waitThread</code>线程，将其置为阻塞状态，并将变量<code>flag</code>置为<code>true</code>，当<code>waitThread</code>线程再次获取对象锁之后继续执行余下代码</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 20:00
 * @description: wait/notify
 */
public class WaitNotifyTest {

    private static Object LOCK = new Object();
    private static Boolean FLAG = Boolean.TRUE;


    public static void main(String[] args) throws InterruptedException{
        Runnable r = new WaitThread();
        new Thread(r,&quot;waitThread&quot;).start();
        TimeUnit.SECONDS.sleep(1L);
        synchronized (LOCK){
            System.out.println(Thread.currentThread().getName()+&quot;唤醒waitThread线程：&quot;+LocalTime.now());
            /**
             * 线程状态由等待状态变为阻塞状态
             */
            LOCK.notify();
            /**
             * 只有当前线程释放对象锁，waitThread获取到LOCK对象的锁之后才会从wait()方法中返回
             */
            TimeUnit.SECONDS.sleep(2L);
            FLAG = Boolean.FALSE;
        }
    }

    public static class WaitThread implements Runnable {
        @Override
        public void run() {
            /**
             * 加锁
             */
            synchronized (LOCK){
                while (FLAG){
                    try {
                        System.out.println(Thread.currentThread().getName()+&quot;运行中：&quot;+LocalTime.now());
                        /**
                         * 线程状态变为等待状态
                         */
                        LOCK.wait();
                        /**
                         * 再次获得对象锁之后，才会执行
                         */
                        System.out.println(Thread.currentThread().getName()+&quot;被唤醒：&quot;+LocalTime.now());
                    }catch (InterruptedException e){
                        System.err.println(e.getMessage());
                    }
                }
            }
            System.out.println(Thread.currentThread().getName()+&quot;即将停止：&quot;+LocalTime.now());
        }
    }
}</code></pre>
<p>输出</p>
<p><img src="concurrent-thread/wait%EF%BC%8Cnotify.png" alt=""></p>
<p>可以看到在<code>mian</code>线程调用<code>LOCK.notify()</code>方法后，沉睡了2s才释放对象锁，<code>waitThread</code>线程在获得对象锁之后执行余下代码</p>
<h5 id="安全的线程停止操作-中断标识"><a href="#安全的线程停止操作-中断标识" class="headerlink" title="安全的线程停止操作(中断标识)"></a>安全的线程停止操作(中断标识)</h5><p>线程的安全停止操作是利用线程的中断标识来实现，线程的中断属性表示一个运行中的线程是否被其他线程进行了中断操作，其他线程通过调用该线程的<code>interrupt()</code>方法对其进行中断操作，而该线程通过检查自身是否被中断来进行响应，当一个线程被中断可以使用<code>Thread.interrupted()</code>方法对当前线程的中断标识位进行复位</p>
<p>例：新建一个线程，<code>run</code>方法中使用<code>Thread.currentThread().isInterrupted()</code>是否中断作为判断条件，在主线程中使用<code>thread.interrupt()</code>方法对子线程进行中断操作，用来达到终止线程的操作，这种方式会让子线程可以去清理资源或一些别的操作，而使用<code>stop()</code>方法则会会直接终止线程</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 20:47
 * @description: 中断
 */
public class InterruptTest {

    public static void main(String[] args) throws InterruptedException {
        Runnable r = new StopThread();
        Thread thread = new Thread(r,&quot;stopThread&quot;);
        thread.start();
        TimeUnit.SECONDS.sleep(1L);
        System.out.println(Thread.currentThread().getName()+&quot;对stopThread线程进行中断：&quot;+LocalTime.now());
        thread.interrupt();
    }

    public static class StopThread implements Runnable {
        @Override
        public void run() {
            while (!Thread.currentThread().isInterrupted()){
                System.out.println(Thread.currentThread().getName()+&quot;运行中：&quot;+LocalTime.now());
            }
            System.out.println(Thread.currentThread().getName()+&quot;停止：&quot;+LocalTime.now());
        }
    }
}</code></pre>
<h5 id="Thread-join"><a href="#Thread-join" class="headerlink" title="Thread.join()"></a>Thread.join()</h5><p><code>Thread.join()</code>作用是等待该线程终止</p>
<p>比如在主线程中新建一个子线程，调用子线程的<code>join()</code>方法，那么在子线程未执行完时，主线程的状态是阻塞状态，只有当子线程执行结束，主线程才会继续往下执行</p>
<table>
<thead>
<tr>
<th>方法名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>join()</td>
<td>调用A线程的<code>join()</code>方法后，那么当前线程需要等待A线程终止，才可以继续执行</td>
</tr>
<tr>
<td>join(long)</td>
<td>在<code>join()</code>方法的基础上增加了时间限制（毫秒），超出时间后，无论A线程是否执行完，当前线程都进入就绪状态，重新等待cpu调用</td>
</tr>
<tr>
<td>join(long,int)</td>
<td>在<code>join(long)</code>方法基础上，时间控制上更加严谨，时间细粒度为纳秒（Long毫秒+int纳秒）</td>
</tr>
</tbody></table>
<p>例：循环创建子线程，在<code>main</code>线程中调用子线程的<code>join()</code>方法，在子线程中输出了一句日志</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/9 20:53
 * @description: thread.join();
 */
public class JoinThreadTest {

    public static void main(String[] args) throws InterruptedException{

        IntStream.range(0, 5).forEach(i -&gt; {
            try {
                Runnable runnable = new JoinThread();
                Thread thread = new Thread(runnable,&quot;joinThread&quot;);
                thread.start();
                thread.join();
                System.out.println(Thread.currentThread().getName() + &quot;运行中: &quot; + LocalTime.now());
            } catch (InterruptedException e) {
                System.err.println(e.getMessage());
            }
            System.out.println(&quot;------- 分隔符 ------- &quot;);
        });
    }

    public static class JoinThread implements Runnable {
        @Override
        public void run() {
            try {
                TimeUnit.SECONDS.sleep(1L);
                System.out.println(Thread.currentThread().getName() + &quot;运行中: &quot; + LocalTime.now());
            } catch (InterruptedException e) {
                System.err.println(e.getMessage());
            }
        }
    }
}</code></pre>
<p>输出</p>
<p><img src="concurrent-thread/join.png" alt=""></p>
<p>每次循环都是主线程等待子线程终止，在子线程执行完之后主线程才会继续执行</p>
<p><strong>thread.join()源码</strong></p>
<p>调用方线程（调用join方法的线程）执行等待操作，直到被调用的线程（join方法所属的线程）结束，再被唤醒</p>
<pre><code class="java">public final void join() throws InterruptedException {
    join(0);
}</code></pre>
<p><code>join(0)</code>方法</p>
<pre><code class="java">public final synchronized void join(long millis)
throws InterruptedException {
    long base = System.currentTimeMillis();
    long now = 0;

    if (millis &lt; 0) {
        throw new IllegalArgumentException(&quot;timeout value is negative&quot;);
    }

    if (millis == 0) {
        while (isAlive()) {
            wait(0);
        }
    } else {
        while (isAlive()) {
            long delay = millis - now;
            if (delay &lt;= 0) {
                break;
            }
            wait(delay);
            now = System.currentTimeMillis() - base;
        }
    }
}</code></pre>
<p><code>join()</code>方法实现等待其实是调用了<code>wait()</code>方法，<code>isAlive()</code>方法的作用是监测子线程是否终止，如果终止或者超过了指定时间，代码就继续往下执行，否则就继续等待，知道条件满足</p>
<h5 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h5><p><code>ThreadLocal</code>，叫线程变量，是一个以<code>ThreadLocal</code>对象为键，任意对象为值的存储结构，<code>ThreadLocal</code>类型的变量在每个线程中是独立的，在多线程环境下不会相互影响</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/10 17:56
 * @description: ThreadLocal
 */
public class ThreadLocalTest {

    private static String STATE;
    private static ThreadLocal&lt;String&gt; STRING_THREAD_LOCAL = new InheritableThreadLocal&lt;&gt;();


    public static void main(String[] args) throws InterruptedException{

        STATE = &quot;未重置&quot;;
        STRING_THREAD_LOCAL.set(&quot;未重置&quot;);

        Thread thread = new Thread(() -&gt;
        {
            STATE = &quot;已重置&quot;;
            STRING_THREAD_LOCAL.set(&quot;已重置&quot;);
            System.out.println(Thread.currentThread().getName() + &quot; : 变量已重置&quot;);
        });
        thread.start();
        thread.join();

        System.out.println(Thread.currentThread().getName() + &quot;STATE : &quot; + STATE);
        System.out.println(Thread.currentThread().getName() + &quot;STRING_THREAD_LOCAL : &quot; + STRING_THREAD_LOCAL.get());
    }
}</code></pre>
<p>输出</p>
<p><img src="concurrent-thread/threadLocal.png" alt=""></p>
<p><code>ThreadLocal&lt;String&gt;</code>类型的变量<code>STRING_THREAD_LOCAL</code>未被子线程修改</p>
<p>使用<code>ThreadLocal</code>变量，必须要注意回收自定义的<code>ThreadLocal</code>变量，尤其在线程池场景下，线程经常会被复用，如果不清理自定义的<code>ThreadLocal</code>变量，可能会影响后续业务逻辑和造成内存泄露等问题，尽量使用<code>try-finally</code>块进行回收，回收方式是调用<code>threadLocal.remove()</code>;方法</p>
<p><strong>参考：java并发编程的艺术</strong></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/concurrent-thread/" data-id="ckdn6w7wb0002aktwblgu5sev" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E7%A8%8B/" rel="tag">线程</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-concurrent-threadpool" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/concurrent-threadpool/" class="article-date">
  <time datetime="2019-07-06T07:03:18.000Z" itemprop="datePublished">2019-07-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/concurrent-threadpool/">java并发编程 | 线程池详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>线程池用来处理异步任务或者并发执行的任务</p>
<p>优点：</p>
<ol>
<li>重复利用已创建的线程，减少创建和销毁线程造成的资源消耗</li>
<li>直接使用线程池中的线程，提高响应速度</li>
<li>提高线程的可管理性，由线程池同一管理</li>
</ol>
<h4 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h4><p><code>java</code>中线程池使用<code>ThreadPoolExecutor</code>实现</p>
<h5 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h5><p><code>ThreadPoolExecutor</code>提供了四个构造函数，其他三个构造函数最终调用的都是下面这个构造函数</p>
<pre><code class="java">public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue&lt;Runnable&gt; workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize &lt; 0 ||
            maximumPoolSize &lt;= 0 ||
            maximumPoolSize &lt; corePoolSize ||
            keepAliveTime &lt; 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.acc = System.getSecurityManager() == null ?
                null :
                AccessController.getContext();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }</code></pre>
<p><strong>入参：</strong></p>
<ol>
<li><p><code>corePoolSize</code>：线程池的核心线程数量</p>
<p>线程池维护的核心线程数量，当线程池初始化后，线程池中的工作线程数量为零，当有任务来到的时候才会创建线程去执行任务，当线程池中的工作线程数量等于核心线程数量时，新到的任务就会放到缓存队列中</p>
</li>
<li><p><code>maximumPoolSize</code>：线程池允许创建的最大线程数量</p>
<p>当阻塞队列满了的时候，并且线程池中创建的线程数量小于<code>maximumPoolSize</code>，此时会创建新的线程执行任务</p>
</li>
<li><p><code>keepAliveTime</code>：线程活动保持时间</p>
<p>只有当线程池数量大于核心线程数量时，<code>keepAliveTime</code>才会有效，如果当前线程数量大于核心线程数量时，并且线程的空闲时间达到<code>keepAliveTime</code>，当前线程终止，直到线程池数量等于核心线程数</p>
</li>
<li><p><code>unit</code>：线程活动保持时间的单位</p>
<p><code>keepAliveTime</code>的单位，包括：<code>TimeUnit.DAYS</code>天，<code>TimeUnit.HOURS</code>小时，<code>TimeUnit.MINUTES</code>分钟，<code>TimeUnit.SECONDS</code>秒，<code>TimeUnit.MILLISECONDS</code>毫秒，<code>TimeUnit.MICROSECONDS</code>微秒，<code>TimeUnit.NANOSECONDS</code>纳秒</p>
</li>
<li><p><code>workQueue</code>：任务队列，用来保存等待执行任务的阻塞队列</p>
<p><code>ArrayBlockingQueue</code>：是一个基于数组结构的有界队列</p>
<p><code>LinkedBlockingQueue</code>：是一个基于链表结构的阻塞队列</p>
<p><code>SynchronousQueue</code>：不存储元素的阻塞队列，每一个插入操作必须等到下一个线程调用移除操作，否则插入操作一直阻塞</p>
<p><code>PriorityBlockingQueue</code>：一个具有优先级的无线阻塞队列</p>
</li>
<li><p><code>threadFactory</code>：用来创建线程的工厂</p>
</li>
<li><p><code>handler</code>：饱和策略，当线程池和队列都满了的时候，必须要采取一种策略处理新的任务，默认策略是<code>AbortPolicy</code>，根据自己需求选择合适的饱和策略</p>
<p><code>AbortPolicy</code>：直接抛出异常</p>
<p><code>CallerRunsPolicy</code>：用调用者所在的线程来运行当前任务</p>
<p><code>DiscardOldestPolicy</code>：丢弃队列里面最近的一个任务，并执行当前任务</p>
<p><code>DiscardPolicy</code>：不处理，丢弃掉</p>
<p>当然我们也可以通过实现<code>RejectedExecutionHandler</code>去自定义实现处理策略</p>
</li>
</ol>
<p>入参不同，线程池的运行机制也不同，了解每个入参的含义由于我们更透传的理解线程池的实现原理</p>
<h5 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h5><p>线程池处理提交任务流程如下</p>
<p><img src="concurrent-threadpool/%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt=""></p>
<p><strong>处理流程</strong>：</p>
<ol>
<li>如果核心线程数量未满，创建线程执行任务，否则添加到阻塞队列中</li>
<li>如果阻塞队列中未满，将任务存到队列里</li>
<li>如果阻塞队列满了，看线程池数量是否达到了线程池最大数量，如果没达到，创建线程执行任务</li>
<li>如果已经达到线程池最大数量，根据饱和策略进行处理</li>
</ol>
<p><code>ThreadPoolExecutor</code>使用<code>execute(Runnable command)</code>和<code>submit(Runnable task)</code>向线程池中提交任务，在<code>submit(Runnable task)</code>方法中调用了<code>execute(Runnable command)</code>，所以我们只要了解<code>execute(Runnable command)</code></p>
<pre><code class="java">public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    // 获取线程池状态，并且可以通过ctl获取到当前线程池数量及线程池状态
    int c = ctl.get();
    // 如果工作线程数小于核心线程数量，则创建一个新线程执行任务
    if (workerCountOf(c) &lt; corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 如果不符合上面条件，当前线程处于运行状态并且写入阻塞队列成功
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        // 双重检查，再次获取线程状态，如果当前线程状态变为非运行状态，则从队列中移除任务，执行拒绝策略
        if (! isRunning(recheck) &amp;&amp; remove(command))
            reject(command);
        // 检查工作线程数量是否为0
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    //创建线程执行任务，如果添加失败则执行拒绝策略
    else if (!addWorker(command, false))
        reject(command);
}</code></pre>
<p><code>execute(Runnable command)</code>方法中我们比较关心的就是如何创建新的线程执行任务，就<code>addWorker(command, true)</code>方法</p>
<p><code>workQueue.offer(command)</code>方法是用来向阻塞队列中添加任务的</p>
<p><code>reject(command)</code>方法会根据创建线程池时传入的饱和策略对任务进行处理，例如默认的<code>AbortPolicy</code>，查看源码后知道就是直接抛了个<code>RejectedExecutionException</code>异常，其他的饱和策略的源码也是特别简单</p>
<p>关于线程池状态与工作线程的数量是如何表示的</p>
<p>在<code>ThreadPoolExecutor</code>中使用一个<code>AtomicInteger</code>类型变量表示</p>
<pre><code class="java">/**
 * ctl表示两个信息，一个是线程池的状态（高3位表示），一个是当前线程池的数量（低29位表示），这个跟我们前面      * 说过的读写锁的state变量是一样的，以一个变量记录两个信息，都是以利用int的32个字节，高十六位表述读，低十     * 六位表示写锁
 */
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
//低29位保存线程池数量
private static final int COUNT_BITS = Integer.SIZE - 3;
//线程池最大容量
private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;

// 运行状态存储在高3位
// 运行状态
private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;
private static final int STOP       =  1 &lt;&lt; COUNT_BITS;
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</code></pre>
<p><code>addWorker(command, boolean)</code>创建工作线程，执行任务</p>
<pre><code class="java">private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        // 线程池状态
        int rs = runStateOf(c);
        // 判断线程池状态，以及阻塞队列是否为空
        if (rs &gt;= SHUTDOWN &amp;&amp;
            ! (rs == SHUTDOWN &amp;&amp;
               firstTask == null &amp;&amp;
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            // 获取线程工作线程数量
            int wc = workerCountOf(c);
            // 判断是否大于最大容量，以及根据传入的core判断是否大于核心线程数量还是最大线程数量
            if (wc &gt;= CAPACITY ||
                wc &gt;= (core ? corePoolSize : maximumPoolSize))
                return false;
            // 增加工作线程数量
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            //如果线程池状态改变，则重试
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 创建Worker,内部创建了一个新的线程
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());
                // 线程池状态判断
                if (rs &lt; SHUTDOWN ||
                    (rs == SHUTDOWN &amp;&amp; firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    // 将创建的线程添加到线程池
                    workers.add(w);
                    int s = workers.size();
                    if (s &gt; largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                //执行任务，首先会执行Worker对象的firstTask
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        //如果任务执行失败
        if (! workerStarted)
            //移除worker
            addWorkerFailed(w);
    }
    return workerStarted;
}</code></pre>
<h5 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h5><p><code>ThreadPoolExecutor</code>中关闭线程池使用<code>shutdown()</code>和<code>shutdownNow()</code>方法，原理都是通过遍历线程池中的线程，对线程进行中断</p>
<pre><code class="java">for (Worker w : workers) {
    Thread t = w.thread;
    if (!t.isInterrupted() &amp;&amp; w.tryLock()) {
        try {
            t.interrupt();
        } catch (SecurityException ignore) {
        } finally {
            w.unlock();
        }
    }
    if (onlyOne)
        break;
    }</code></pre>
<h5 id="Executor框架"><a href="#Executor框架" class="headerlink" title="Executor框架"></a>Executor框架</h5><p><code>Executor</code>框架将任务的提交与任务的执行进行分离</p>
<p><code>Executors</code>提供了一系列工厂方法用于创先线程池，返回的线程池都实现了 <code>ExecutorService</code> 接口</p>
<p>工厂方法：</p>
<ol>
<li><code>newFixedThreadPool</code>：用于创建固定数目线程的线程池</li>
<li><code>newCachedThreadPool</code>：用于创建一个可缓存的线程池，调用execute将重用以前构造的线程，如果现有线程没有可用的，则创建一个新线 程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程</li>
<li><code>newSingleThreadExecutor</code>：用于创建只有一个线程的线程池</li>
<li><code>newScheduledThreadPool</code>：用于创建一个支持定时及周期性的任务执行的线程池</li>
</ol>
<p>在阿里巴巴手册中强制要求禁止使用<code>Executors</code>提供的工厂方法创建线程池</p>
<p><img src="concurrent-threadpool/%E9%98%BF%E9%87%8C%E8%A7%84%E8%8C%83.png" alt=""></p>
<p>这个确实是一个很严重的问题，我们部门曾经就出现过使用<code>FixedThreadPool</code>线程池，导致OOM，这是因为线程执行任务的时候被阻塞或耗时很长时间，导致阻塞队列一直在添加任务，直到内存被打满，报OOM</p>
<p>所以我们在使用线程池的时候用该使用<code>ThreadPoolExecutor</code>的构造函数去创建线程池，根据自己的任务类型来确定核心线程数和最大线程数，选择适合阻塞队列和阻塞队列的长度</p>
<h5 id="合理配置线程池"><a href="#合理配置线程池" class="headerlink" title="合理配置线程池"></a>合理配置线程池</h5><p>合理的配置线程池需要分析一下任务的性质（使用<code>ThreadPoolExecutor</code>创建线程池）：</p>
<ol>
<li><p>CPU密集型任务应配置竟可能小的线程，比如 cpu数量+1</p>
</li>
<li><p>IO密集型任务并不是一直在执行任务，应该配置尽可能多的线程，比如 cpu数量x2</p>
<p>可通过<code>Runtime.getRuntime().availableProcessors()</code>获取cpu数量</p>
</li>
<li><p>执行的任务有调用外部接口比较费时的时候，这时cup空闲的时间就越长，可以将线程池数量设置大一些，这样cup空闲的时间就可以去执行别的任务</p>
</li>
<li><p>建议使用有界队列，可根据需要将长度设置大一些，防止OOM</p>
</li>
</ol>
<p><strong>参考：java并发编程的艺术</strong></p>
<p><strong>推荐阅读</strong>：</p>
<p>​    <a href="https://chenmingyu.top/concurrent-thread/">java并发编程 | 线程详解</a></p>
<p>​    <a href="https://chenmingyu.top/concurrent-lock/">java并发编程 | 锁详解：AQS，Lock，ReentrantLock，ReentrantReadWriteLock</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/concurrent-threadpool/" data-id="ckdn6w7xm000maktw86vwg829" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/" rel="tag">线程池</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-data-structure-array" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/data-structure-array/" class="article-date">
  <time datetime="2019-07-05T10:07:08.000Z" itemprop="datePublished">2019-07-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/data-structure-array/">【数据结构】| 数组详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p><strong>数组是用于储存多个相同类型数据的集合，使用一段连续的内存空间存储数据</strong></p>
<p>数组作为最基本的数据结构，想必大家一定已经足够了解，数组的增删操作时间复杂度是O(n)，而查询的时间复杂度是O(1)，这里的查询指的是按下标进行查找，如果是比对数据进行查询时间复杂度还是O(n)</p>
<p><strong>前提:</strong></p>
<p>假设数组的长度是n</p>
<p><strong>新增操作</strong>：</p>
<p>我们新增一条数据到数组中时，当新增的数据在末尾的时候时间复杂度是O(1)，而当新增的数据插入到数组的第x个位置时，由于数组使用的是连续的内存，所以x之后的数据都需要往后移动一位，把第x位置腾出来，才可以将新增的数据插入到第x个位置，如果按最坏的情况考虑，是将数据插入到数据的首位，这时数组里所有的数据都需要往后移一位，这时的时间复杂度就是O(n)，所以平均的时间复杂度就是O(n)</p>
<p><strong>删除操作:</strong></p>
<p>当我们从数组中删除一条数据的时候，假设删除的数据位于数组的第x位置，也是由于数组使用的是连续的内存，当我们把x位置的数据删除之后，为了保证数组的内存是连续的，x位置之后的数据都需要往前移动一位，假设当删除的是数组首位的数据，这时首位之后的所有数据都需要往前移动一位，时间复杂度是O(n)，当删除的数据是数组尾部的数据时，不会发生数据移动，时间复杂度是O(1)</p>
<p><strong>查询操作:</strong></p>
<p>关于查询，要说的点还是，由于数组的内存是连续的，这就提供了我们随机访问的能力，随机访问的意思就是指我们可以按照数组的下标进行查询，这时的时间复杂度是O(1)，而遍历所有数组匹配查询的时候时间复杂度是O(n)</p>
<p>我们看一下数组在内存中的存储结构</p>
<pre><code class="java">//实例化一个数组，
int[] m = new int[]{0,5,10,15,20};</code></pre>
<p><img src="data-structure-array/array.png" alt=""></p>
<p><strong>随机访问:</strong>由于数组内的地址是连续的，想要获取m[3]位置数据的时候我们只要根据寻址公式计算出m[3]的内存地址就可以直接获取到数据，这时假设数组的首地址是k，一个int类型占4个字节，m[3]的内存地址就是k+3*4</p>
<p><strong>匹配查询:</strong>这时候由于需要遍历数组，如果在第一个m[0]的位置就匹配上，则时间复杂度是O(1)，在数组尾位匹配上就是O(n)，所以平均的时间复杂度就是O(n)</p>
<p>由于数组的容量是实例化的时候就固定的，所以没有办法进行动态扩容，而<code>java</code>中的容器类则弥补了这一缺陷，比如<code>ArrayList</code>，<code>ArrayList</code>将底层操作数组的细节封装，通过提供api供开发人员使用，<code>ArrayList</code>当我们调用<code>add</code>方法的时候不需要关心底层数组的容量够不够使用也不用关心扩容的逻辑是什么，当需要的扩容的时候<code>ArrayList</code>会自己进行扩容：</p>
<pre><code class="java">int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);</code></pre>
<p><code>oldCapacity</code>是数组的旧的容量大小，而<em>newCapacity</em>新的数组容量大小是原来的1.5倍（<code>oldCapacity &gt;&gt; 1</code>右移一位相当于<code>oldCapacity/2</code>）</p>
<p>扩容的原理就是计算出新的数组大小，然后申请内存，将原来的数组复制到新申请的数组中，这一过程是比较低效的，所以一般在实例化集合的时候都会指定集合的大小比如<code>new ArrayList(16)</code>;</p>
<p><strong>集合与数组对比：</strong>因为集合使用起来更方便，但数组也不是绝对不用，Java中的集合不支持基本类型，而这时候使用如果使用集合的话必然会进行装箱，拆箱的操作，造成不必要的性能消耗，所以当数据的容量是固定的，且数据类型是基本类型的时候，就可以考虑使用数组</p>
<p><strong>总结:</strong></p>
<p>由于数组存储的是相同类型的数据，并且内存的地址是连续的，就导致可以使用寻址公式计算出数组中某个元素的内存地址，所以数组的随机访问是高效的，但是要新增和删除数据的时候，为了保持数组的内存连续性，必然会导致数据的移动，所以数组的新增和删除是低效的</p>
<p><em>注意:使用数组需要警惕别造成数组越界</em></p>
<h3 id="算法题"><a href="#算法题" class="headerlink" title="算法题"></a>算法题</h3><p>算法题来自<a href="[https://leetcode-cn.com](https://leetcode-cn.com/)">leetcode</a></p>
<h4 id="两数之和"><a href="#两数之和" class="headerlink" title="两数之和"></a>两数之和</h4><p>链接：<a href="https://leetcode-cn.com/problems/two-sum/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/two-sum/</a></p>
<p><strong>难度:</strong>简单</p>
<p>给定一个整数数组 <code>nums</code> 和一个目标值 <em>target</em>，请你在该数组中找出和为目标值的那 <strong>两个</strong> 整数，并返回他们的数组下标。</p>
<p>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。</p>
<p><strong>示例:</strong></p>
<pre><code class="java">给定 nums = [2, 7, 11, 15], target = 9

因为 nums[0] + nums[1] = 2 + 7 = 9
所以返回 [0, 1]</code></pre>
<p><strong>思路:</strong></p>
<p><code>nums[i]=target-nums[j]</code></p>
<p><strong>题解:</strong></p>
<pre><code class="java">class Solution {
    public int[] twoSum(int[] nums, int target) {
        Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(16);
        for(int i=0;i&lt;nums.length;i++){
            int n = target-nums[i];
            if(map.containsKey(target-nums[i])){
                return new int[]{i,map.get(target-nums[i])};
            }
            map.put(nums[i],i);
        }
        return null;
    }
}</code></pre>
<h4 id="盛最多水的容器"><a href="#盛最多水的容器" class="headerlink" title="盛最多水的容器"></a>盛最多水的容器</h4><p>链接：<a href="https://leetcode-cn.com/problems/container-with-most-water" target="_blank" rel="noopener">https://leetcode-cn.com/problems/container-with-most-water</a></p>
<p><strong>难度：</strong>中等</p>
<p>给定 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。</p>
<p><strong>说明：</strong>你不能倾斜容器，且 n 的值至少为 2。</p>
<p> <img src="data-structure-array/question_11.jpg" alt=""></p>
<p>图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49</p>
<p><strong>示例：</strong></p>
<pre><code class="java">输入: [1,8,6,2,5,4,8,3,7]
输出: 49</code></pre>
<p><strong>思路：</strong></p>
<p>官方题解：双指针法</p>
<p>面积=长度(x)*高度(y)</p>
<p>假设left为x轴左起点，right为x轴右起点，left对应的y轴高度为a[left]，right对应的y轴高度为a[right]，计算面积中的高度只能取a[left]和a[right]中小的那个，而长度的计算方式是right-left</p>
<p>，当a[left]&gt;a[right]时，对应的x轴right就往前移动一位，反之left就往后移动一位</p>
<p><strong>题解：</strong></p>
<pre><code class="java">class Solution {
    public int maxArea(int[] height) {
        //x轴左起始位置
        int left=0;
        //x轴右起始位置
        int right= height.length-1;
        int maxarea = 0;
        while(left&lt;right){
            //每次都需要计算面积，将面积更大的赋值给maxarea
            maxarea = Math.max(maxarea,Math.min(height[left],height[right])*(right-left));
            //如果左面的垂直线大于右面的垂直线
            if(height[left]&gt;height[right]){
                //右面的往前移动一位
                right--;
            }else{
                //左面的往后移动一位
                left++;
            }
        }
        return maxarea;
    }
}</code></pre>
<h4 id="接雨水"><a href="#接雨水" class="headerlink" title="接雨水"></a>接雨水</h4><p>链接：<a href="https://leetcode-cn.com/problems/trapping-rain-water" target="_blank" rel="noopener">https://leetcode-cn.com/problems/trapping-rain-water</a></p>
<p><strong>难度：</strong>困难</p>
<p>给定 <em>n</em> 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。</p>
<p><img src="data-structure-array/rainwatertrap.png" alt=""></p>
<p>上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 感谢 Marcos 贡献此图。</p>
<p><strong>示例:</strong></p>
<pre><code class="java">输入: [0,1,0,2,1,0,1,3,2,1,2,1]
输出: 6</code></pre>
<p><strong>思路：</strong></p>
<p>解题思路也是使用双指针，没有思路的可详细看下官方题解双指针方法的那个动图</p>
<p><strong>题解：</strong></p>
<pre><code class="java">class Solution {
    public int trap(int[] height) {
        int left=0;
        int right=height.length-1;
        int maxLeft=0;
        int maxRight=0;
        int area =0;
        while(left&lt;right){
            if(height[left]&lt;height[right]){
                if(height[left]&gt;=maxLeft){
                    maxLeft = height[left];
                }else{
                    area += maxLeft-height[left];
                }
                ++left;
            }else{
                if(height[right]&gt;=maxRight){
                    maxRight = height[right];
                }else{
                    area += maxRight-height[right];
                }
                --right;
            }
        }
        return area; 
    }
}</code></pre>
<p><strong>参考:</strong></p>
<p>极客时间:数据结构与算法之美</p>
<p>leetCode官网:<a href="https://leetcode-cn.com/problemset/all/" target="_blank" rel="noopener">https://leetcode-cn.com/problemset/all/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/data-structure-array/" data-id="ckdn6w7wn0006aktw3ilc4ta9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-mysql-optimize" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/mysql-optimize/" class="article-date">
  <time datetime="2019-06-29T10:05:40.000Z" itemprop="datePublished">2019-06-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/mysql/">mysql</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/mysql-optimize/">mysql优化 | 存储引擎，建表，索引，sql的优化建议</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h4><p>mysql中查看支持的引擎的sql：</p>
<pre><code class="sql">show engines; </code></pre>
<p><img src="mysql-optimize/engines.png" alt=""></p>
<p>日常工作中使用较多的存储引擎对比：InnoDB，MyISAM</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">InnoDB</th>
<th align="center">MyISAM</th>
</tr>
</thead>
<tbody><tr>
<td align="center">存储限制</td>
<td align="center">64T</td>
<td align="center">256T</td>
</tr>
<tr>
<td align="center">支持事务</td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">支持索引</td>
<td align="center">yes</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">支持全文索引</td>
<td align="center">no</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">支持数据缓存</td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">支持外键</td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">支持Hash索引</td>
<td align="center">no</td>
<td align="center">no</td>
</tr>
</tbody></table>
<h5 id="innodb"><a href="#innodb" class="headerlink" title="innodb"></a>innodb</h5><p>支持提交、回滚和崩溃恢复能力的事物安全（ACID），支持行锁，支持外键完整性约束</p>
<p>适合场景</p>
<ul>
<li>需要事务处理</li>
<li>表数据量大，高并发操作</li>
</ul>
<h5 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h5><p>MyISAM存储引擎提供了高速检索和存储的能力，支持全文索引</p>
<p>适合场景</p>
<ul>
<li>很多count计算的</li>
<li>查询非常频繁的</li>
</ul>
<p>其余几种存储引擎</p>
<h5 id="MEMORY引擎"><a href="#MEMORY引擎" class="headerlink" title="MEMORY引擎"></a>MEMORY引擎</h5><p>数据只保存在内存中，因为是在内存中，拥有极高的插入，更新，查询的效率，但是重启后数据都会丢失，表级锁，并发性能低。</p>
<h5 id="MERGE引擎"><a href="#MERGE引擎" class="headerlink" title="MERGE引擎"></a>MERGE引擎</h5><p>merge表是一组MyISAM表的组合，所以merge表是没有数据的，对这个表的操作实际上是操作内部的MyISAM表，将多个MyISAM表合并适合做一些报表之类的操作。</p>
<h5 id="ARCHIVE引擎"><a href="#ARCHIVE引擎" class="headerlink" title="ARCHIVE引擎"></a>ARCHIVE引擎</h5><p>仅支持插入和查询，使用zlib压缩库，在记录被请求的时候实时压缩，不支持事务，支持行级锁，适合存储大量的日志数据。</p>
<p>个人是推荐Innodb引擎的，公司部门里也是规定新建表的时候必须使用Innodb引擎，Innodb引擎较MyISAM引擎可以提供更多的功能，不是很实时的查询场景可以使用缓存，近实时的查询可以使用es，当然了这只是个人看法，针对不同的场景选择不同的存储引擎还是很有必要滴。所以在知道不同存储引擎的特性之后，才可以根据不同业务需求选择合适的存储引擎。</p>
<h4 id="建表原则"><a href="#建表原则" class="headerlink" title="建表原则"></a>建表原则</h4><h5 id="在建表的时候尽量遵循以下原则"><a href="#在建表的时候尽量遵循以下原则" class="headerlink" title="在建表的时候尽量遵循以下原则"></a>在建表的时候尽量遵循以下原则</h5><ol>
<li><p>尽量选择小的数据类型，数据类型选择上尽量tinyint(1字节)&gt;smallint(2字节)&gt;int(4字节)&gt;bigint(8字节)，比如逻辑删除yn字段上（1代表可用，0代表）就可以选择tinyint（1字节）类型</p>
</li>
<li><p>尽量保证字段数据类型长度固定</p>
</li>
<li><p>尽量避免使用null，使用null的字段查询很难优化，影响索引，可以使用0或’’代替</p>
</li>
<li><p>避免宽表，能拆分就拆分，一个表往往跟一个实体域对应，就像设计对象的时候一样，保持单一原则</p>
</li>
<li><p>尽量避免使用text和blob，如果非使用不可，将类型为text和blob的字段在独立成一张新表，然后使用主键对应原表</p>
</li>
<li><p>禁止使用float或double类型，这个坑超大，float或double存在精度问题，在进行比较或者加减操作的时候会丢失精度导致数据异常，凡是使用float或double类型的时候考虑下可不可使用int或bigint代替。比如金额，以元为单位使用float或double类型的时候，可以考虑以分为单位使用int，bigint类型代替，然后由业务代码进行单位的转换。</p>
</li>
<li><p>每张表都加上createUser,createTime.updateUser,updateTime字段</p>
</li>
<li><p>起名字要规范，包括：库名，表名，字段名，索引名</p>
</li>
<li><p>查询频繁使用的字段记得加索引</p>
</li>
<li><p>尽量避免使用外键，不用外键约束，性能更高，然后数据的完整性有程序进行管理</p>
</li>
<li><p>如果表的数量可以预测到非常大，最好在建表的时候，就进行分表，不至于一时间数据量非常大导致效率问题</p>
<p>未完待补充，，，</p>
</li>
</ol>
<h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p>索引是为来加速对表中数据行中的检索而创建的一种分散的数据结果,是针对表而建立的，它是由数据页面以外的索引页面组成,每个索引页中的行都含有逻辑指针,以便加速检索物理数据，创建索引的目的在于提高查询效率，innodb的索引都是基于b tree实现的</p>
<h5 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h5><p>普通索引：最基本的索引，无限制</p>
<pre><code class="sql">#方式1
CREATE INDEX idx_username ON sys_user(user_name(32)); 
#方式2
ALTER table sys_user ADD INDEX idx_username(user_name(32))</code></pre>
<p>主键索引：一个表只能有一个主键索引，且不能为空</p>
<p>一般建表时同时创建了主键索引</p>
<pre><code class="sql">CREATE TABLE `sys_user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_name` varchar(32) DEFAULT NULL,
  `pass_word` varchar(32) DEFAULT NULL,
  `token` varchar(32) DEFAULT NULL,
  `token_expire` int(11) DEFAULT NULL,
  `yn` smallint(6) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=348007 DEFAULT CHARSET=utf8;</code></pre>
<p>唯一索引：与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一</p>
<pre><code class="sql">CREATE UNIQUE INDEX idx_token ON sys_user(token_expire)</code></pre>
<p>组合索引：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合</p>
<pre><code class="sql">ALTER TABLE sys_user ADD INDEX idx_un_te (user_name(32),token_expire); </code></pre>
<p>全文索引：用来查找文本中的关键字，而不是直接与索引中的值相比较。只有char、varchar，text 列上可以创建全文索引</p>
<pre><code class="sql">CREATE FULLTEXT INDEX idx_ ON sys_user(pass_word)</code></pre>
<h5 id="创建使用索引的原则"><a href="#创建使用索引的原则" class="headerlink" title="创建使用索引的原则"></a>创建使用索引的原则</h5><ol>
<li><p>索引的字段尽量要小，根据索引查询数据的快慢取决于b tree的高度，当数据量恒定的时候，字节越少，存的索引的数量就越多，树的高度就越会越低</p>
<p>比如：设置varchar(10)，则这个索引建立的时候只会存字段前10个字节，字段设置的字节数比较小可能会导致索引查出来的数据多，进而进行回表，导致性能下降，所以字段设置为多少还是要自己斟酌一下</p>
</li>
<li><p>遵循索引的最左匹配原则</p>
</li>
<li><p>注意使用like的时候尽量不要使用“%a%”，这样的不走索引，可以使用“a%”，走索引</p>
</li>
<li><p>不要在索引的列上进行计算，比如 select * from sys_user where token_expire+1 = 10000，这样的语句 不会走有索引</p>
</li>
<li><p>什么样的字段建索引，就是那种频繁在where，group by，order by中出现的列，最好加上索引</p>
</li>
<li><p>使用联合索引的时候尽量考虑到索引下推优化</p>
</li>
<li><p>对于使用or的条件，需要or左右的条件都是索引才会走索引，否则走全表扫描，可以考虑使用union代替</p>
</li>
<li><p>避免使用select *，对于只需要查询主键或者where 条件中只有索引的字段， 这时会走覆盖索引建少回表次数</p>
</li>
<li><p>sql语句中避免隐式转换，在MySQL 中，字符串和数字做比较的话，是将字符串转换成数字，如字段是varchar类型，但是入参是int类型，即便字段有索引也不会走，因为这里会进行一次隐式转换</p>
</li>
</ol>
<p><strong>总之使用索引的时候，需要考虑的地方比较多，但是归根结底就是查询尽量走索引，走索引尽量避免回表或减少回表次数</strong></p>
<h5 id="索引的缺点"><a href="#索引的缺点" class="headerlink" title="索引的缺点"></a>索引的缺点</h5><p>虽然索引的可以提高查询的效率，但是在进行insert，update，和delete的时候会降低效率，因为在保存数据的同时也会去保存索引。</p>
<p>不要在一个表里建过多的索引，问题跟上面一样，在操作数据的时候效率降低，而且数据量少的表要看情况建索引，如果建索引跟没建索引的效果差不多少的情况下就不要建索引了，如果是数据量大的表，就需要建索引去优化查询效率。</p>
<h5 id="explain分析sql"><a href="#explain分析sql" class="headerlink" title="explain分析sql"></a>explain分析sql</h5><p>可以使用explain去分析sql的执行情况，比如</p>
<pre><code class="sql">explain select * from sys_user where token_expire = 10000; </code></pre>
<p><img src="mysql-optimize/explan.png" alt=""></p>
<p>在阿里的开发手册中提到过，sql性能优化的标准：至少要达到range，要求ref级别，如果可以是consts最好</p>
<p>说明一下，这里的级别指的就是上图的type字段：</p>
<ul>
<li><p>consts 是指单表中最多只有一个匹配行（主键或唯一索引）</p>
</li>
<li><p>ref 指的是使用普通索引</p>
</li>
<li><p>range 是指对索引进行范围查询</p>
</li>
</ul>
<h4 id="sql优化"><a href="#sql优化" class="headerlink" title="sql优化"></a>sql优化</h4><p>关于sql语句的优化主要是两方面，一个是在建sql的时候需要注意的问题，另一个就是在发现有慢sql的时候可以根据不同情况进行分析，然后优化sql</p>
<h5 id="优化的建议"><a href="#优化的建议" class="headerlink" title="优化的建议"></a>优化的建议</h5><ol>
<li><p>查询的时候一定要记得使用limit进行限制</p>
</li>
<li><p>对于结果只需要一条数据的查询用limit 1进行限制</p>
</li>
<li><p>使用<code>count(*)</code>或count(1)来统计行数来查询，使用count(列)的时候，需要在查看列中这个是否为null,不会统计此列为null的情况，而且mysql已经<code>对count(*)</code>做了优化</p>
</li>
<li><p>不要使用select * 来查数据，使用select 需要的列名，这样的方式去查询</p>
</li>
<li><p>使用join链接代替子查询</p>
</li>
<li><p>不要使用外键，外键的约束可以放在程序里解决</p>
</li>
<li><p>控制一下in操作的集合数量，不要太大了</p>
</li>
<li><p>针对慢查询使用explain去分析原因，然后优化sql，让其尽量走索引</p>
</li>
</ol>
<p>上面说的四个方面就是我目前对于sql优化各个方面的注意事项，希望可以给大家提供一个参考，有问题的可以指出来，交流交流</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/mysql-optimize/" data-id="ckdn6w80n003yaktw3xfv7ten" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mysql/" rel="tag">mysql</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-crawler-htmlunit" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/crawler-htmlunit/" class="article-date">
  <time datetime="2019-06-11T08:42:12.000Z" itemprop="datePublished">2019-06-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/crawler-htmlunit/">一个可配置的爬虫采集系统的方案实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>记录写的一个采集系统，包括需求，分析，设计，实现，遇到的问题及系统的成效，系统最主要功能就是可以通过对每个网站进行不同的采集规则配置对每个网站爬取数据，两年前已爬取的数据量大概在千万级左右，每天采集的数据增量在一万左右，配置采集的网站1200多个，现记录一下系统实现，在提供一些简单的爬虫demo供大家学习下如何爬数据</p>
</blockquote>
<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>数据采集系统：一个可以通过配置规则采集不同网站的系统<br>主要实现目标：</p>
<ol>
<li>针对不同的网站通过配置不同的采集规则实现网页数据的爬取</li>
<li>针对每篇内容可以实现对特征数据的提取</li>
<li>定时去爬取所有网站的数据</li>
<li>采集配置规则可维护</li>
<li>采集入库数据可维护</li>
</ol>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p>数据采集系统架构图</p>
<p><img src="crawler-htmlunit/%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt=""></p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>第一步当然要先分析需求，所以在抽取一下系统的主要需求：</p>
<ol>
<li>针对不同的网站可以通过不同的采集规则实现数据的爬取 </li>
<li>针对每篇内容可以实现对特征数据的提取，特征数据就是指标题，作者，发布时间这种信息</li>
<li>定时任务关联任务或者任务组去爬取网站的数据</li>
</ol>
<p>再分析一下网站的结构，无非就是两种；</p>
<ol>
<li>一个是列表页，这里的列表页代表的就是那种需要在当前页面获取到更多别的详情页的网页链接，像一般的查询列表，可以通过列表获取到更多的详情页链接。</li>
<li>一个是详情页，这种就比较好理解，这种页面不需要在这个页面再去获得别的网页链接了，直接在当前页面就可以提取数据。</li>
</ol>
<p>基本所有爬取的网站都可以抽象成这样</p>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><p>针对分析的结果设计实现：</p>
<ol>
<li><p>任务表</p>
<p>每个网站可以当做一个任务，去执行采集  </p>
</li>
<li><p>两张规则表</p>
<p>每个网站对应自己的采集规则，根据上面分析的网站结构，采集规则又可以细分为两个表，一个是包含网站链接，获取详情页列表的列表采集规则表，一个针对是网站详情页的特征数据采集的规则表 详情采集规则表 </p>
</li>
<li><p>url表</p>
<p>负责记录采集目标网站详情页的url </p>
</li>
<li><p>定时任务表</p>
<p>根据定时任务去定时执行某些任务 （可以采用定时任务和多个任务进行关联，也可以考虑新增一个任务组表，定时任务跟任务组关联，任务组跟任务关联）</p>
</li>
<li><p>数据存储表 </p>
<p>这个由于我们采集的数据主要是招标和中标两种数据，分别建了两张表进行数据存储，中标信息表，招标信息表</p>
</li>
</ol>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h3><p>基础架构就是：ssm+redis+htmlunit+jsoup+es+mq+quartz<br>java中可以实现爬虫的框架有很多，htmlunit，WebMagic，jsoup等等还有很多优秀的开源框架，当然httpclient也可以实现。</p>
<p>为什么用htmlunit？<br>        htmlunit 是一款开源的java 页面分析工具，读取页面后，可以有效的使用htmlunit分析页面上的内容。项目可以模拟浏览器运行，被誉为java浏览器的开源实现</p>
<p>简单说下我对htmlunit的理解：</p>
<ol>
<li>一个是htmlunit提供了通过xpath去定位页面元素的功能，利用xpath就可以实现对页面特征数据进行提取；</li>
<li>第二个就在于对js的支持，支持js意味着你真的可以把它当做一个浏览器，你可以用它模拟点击，输入，登录等操作，而且对于采集而言，支持js就可以解决页面使用ajax获取数据的问题</li>
<li>当然除此之外，htmlunit还支持代理ip，https，通过配置可以实现模拟谷歌，火狐等浏览器，Referer，user-agent，是否加载js，css，是否支持ajax等。</li>
</ol>
<p><em>XPath语法即为XML路径语言（XML Path Language），它是一种用来确定XML文档中某部分位置的语言。</em></p>
<p>jsoup相较于htmlunit，就在于它提供了一种类似于jquery选择器的定位页面元素的功能，两者可以互补使用。</p>
<h3 id="采集"><a href="#采集" class="headerlink" title="采集"></a>采集</h3><p>采集数据逻辑分为两个部分：url采集器，详情页采集器</p>
<p>url采集器：</p>
<ul>
<li>只负责采集目标网站的详情页url</li>
</ul>
<p>详情页采集器：</p>
<ul>
<li><p>根据url去采集目标url的详情页数据</p>
</li>
<li><p>使用htmlunit的xpath，jsoup的select语法，和正则表达式进行特征数据的采集。</p>
<p>  这样设计目的主要是将url采集和详情页的采集流程分开，后续如果需要拆分服务的话就可以将url采集和详情页的采集分成两个服务。</p>
<p>  url采集器与详情页采集器之间使用mq进行交互，url采集器采集到url做完处理之后把消息冷到mq队列，详情页采集器去获取数据进行详情页数据的采集。</p>
</li>
</ul>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><h4 id="数据去重："><a href="#数据去重：" class="headerlink" title="数据去重："></a>数据去重：</h4><ol>
<li>在采集url的时候进行去重</li>
<li>同过url进行去重，通过在redis存储key为url，缓存时间为3天，这种方式是为了防止对同一个url进行重复采集。</li>
<li>通过标题进行去重，通过在redis中存储key为采集到的标题 ，缓存时间为3天，这种方式就是为了防止一篇文章被不同网站发布，重复采集情况的发生。</li>
</ol>
<h4 id="数据质量："><a href="#数据质量：" class="headerlink" title="数据质量："></a>数据质量：</h4><p>​    由于每个网站的页面都不一样，尤其是有的同一个网站的详情页结构也不一样，这样就给特征数据的提取增加了难度，所以使用了htmlunit+jsoup+正则三种方式结合使用去采集特征数据。</p>
<h4 id="采集效率："><a href="#采集效率：" class="headerlink" title="采集效率："></a>采集效率：</h4><p>​    由于采集的网站较多，假设每个任务的执行都打开一个列表页，十个详情页，那一千个任务一次执行就需要采集11000个页面，所以采用url与详情页分开采集，通过mq实现异步操作，url和详情页的采集通过多线程实现。</p>
<h4 id="被封ip："><a href="#被封ip：" class="headerlink" title="被封ip："></a>被封ip：</h4><p>​    对于一个网站，假设每半小时执行一次，那每天就会对网站进行48次的扫描，也是假设一次采集会打开11个页面，一天也是528次，所以被封是一个很常见的问题。解决办法，htmlunit提供了代理ip的实现，使用代理ip就可以解决被封ip的问题，代理ip的来源：一个是现在网上有很多卖代理ip的网站，可以直接去买他们的代理ip，另一种就是爬，这些卖代理ip的网站都提供了一些免费的代理ip，可以将这些ip都爬回来，然后使用httpclient或者别的方式去验证一下代理ip的可用性，如果可以就直接入库，构建一个自己的代理ip库，由于代理ip具有时效性，所以可以建个定时任务去刷这个ip库，将无效ip剔除。</p>
<h4 id="网站失效："><a href="#网站失效：" class="headerlink" title="网站失效："></a>网站失效：</h4><p>​    网站失效也有两种，一种是网站该域名了，原网址直接打不开，第二种就是网站改版，原来配置的所有规则都失效了，无法采集到有效数据。针对这个问题的解决办法就是每天发送采集数据和日志的邮件提醒，将那些没采到数据和没打开网页的数据汇总，以邮件的方式发送给相关人员。</p>
<h4 id="验证码："><a href="#验证码：" class="headerlink" title="验证码："></a>验证码：</h4><p>​    当时对一个网站采集历史数据采集，方式也是先通过他们的列表页去采集详情页，采集了几十万的数据之后发现，这个网站采不到数据了，看页面之后发现在列表页加了一个验证码,这个验证码还是属于比较简单的就数字加字母，当时就想列表页加验证码？，然后想解决办法吧，搜到了一个开源的orc文字识别项目tess4j（怎么使用可以看这），用了一下还可以，识别率在百分之二十左右，因为htmlunit可以模拟在浏览器的操作，所以在代码中的操作就是先通过htmlunit的xpath获取到验证码元素，获取到验证码图片，然后利用tess4j进行验证码识别，之后将识别的验证码在填入到验证码的输入框，点击翻页，如果验证码通过就翻页进行后续采集，如果失败就重复上述识别验证码操作，知道成功为止，将验证码输入到输入框和点击翻页都可用htmlunit去实现</p>
<h4 id="ajax加载数据："><a href="#ajax加载数据：" class="headerlink" title="ajax加载数据："></a>ajax加载数据：</h4><p>​    有些网站使用的是ajax加载数据，这种网站在使用htmlunit采集的时候需要在获取到HtmlPage对象之后给页面一个加载ajax的时间，之后就可以通过HtmlPage拿到ajax加载之后的数据。</p>
<p>代码：webClient.waitForBackgroundJavaScript(time); 可以看后面提供的demo</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>一个简略爬虫的代码实现：</p>
<pre><code class="java">@GetMapping(&quot;/getData&quot;)
    public List&lt;String&gt; article_(String url,String xpath){
        WebClient webClient = WebClientUtils.getWebClientLoadJs();
        List&lt;String&gt; datas = new ArrayList&lt;&gt;();
        try {
            HtmlPage page = webClient.getPage(url);
            if(page!=null){
                List&lt;?&gt; lists = page.getByXPath(xpath);
                lists.stream().forEach(i-&gt;{
                    DomNode domNode = (DomNode)i;
                    datas.add(domNode.asText());
                });
            }
        }catch (Exception e){
            e.printStackTrace();
        }finally {
            webClient.close();
        }
        return datas;
    }</code></pre>
<p>上面的代码就实现了采集一个列表页</p>
<ul>
<li>url就是目标网址</li>
<li>xpath就要采集的数据的xpath了</li>
</ul>
<h4 id="爬一下博客园"><a href="#爬一下博客园" class="headerlink" title="爬一下博客园"></a>爬一下博客园</h4><p>请求这个url：<a href="http://localhost:9001/getData?url=https://www.cnblogs.com/&amp;xpath=//*[@id=&quot;post_list&quot;]/div/div[2]/h3/a" target="_blank" rel="noopener">http://localhost:9001/getData?url=https://www.cnblogs.com/&amp;xpath=//*[@id=&quot;post_list&quot;]/div/div[2]/h3/a</a></p>
<ul>
<li>url：传的是博客园首页的地址；</li>
<li>xpath：传的是获取博客园首页的博客列表的标题</li>
</ul>
<p>网页页面：<br><img src="crawler-htmlunit/1.jpg" alt=""><br>采集回的数据：<br><img src="crawler-htmlunit/2.jpg" alt=""></p>
<h4 id="再爬一下csdn"><a href="#再爬一下csdn" class="headerlink" title="再爬一下csdn"></a>再爬一下csdn</h4><p>再次请求：<a href="http://localhost:9001/getData?url=https://blog.csdn.net/&amp;xpath=//*[@id=&quot;feedlist_id&quot;]/li/div/div[1]/h2/a" target="_blank" rel="noopener">http://localhost:9001/getData?url=https://blog.csdn.net/&amp;xpath=//*[@id=&quot;feedlist_id&quot;]/li/div/div[1]/h2/a</a></p>
<ul>
<li>url：这次传是csdn的首页；</li>
<li>xpath：传的是获取csdn首页的博客列表的标题</li>
</ul>
<p>网页页面：<br><img src="crawler-htmlunit/3.jpg" alt=""><br>采集回的数据：<br><img src="crawler-htmlunit/4.jpg" alt=""></p>
<h4 id="采集步骤"><a href="#采集步骤" class="headerlink" title="采集步骤"></a>采集步骤</h4><pre><code>通过一个方法去采集两个网站，通过不同url和xpath规则去采集不同的网站，这个demo展示的就是htmlunit采集数据的过程。
每个采集任务都是执行相同的步骤
- 获取client -&gt; 打开页面 -&gt; 提取特征数据（或详情页链接） -&gt; 关闭cline
不同的地方就在于提取特征数据</code></pre><p>优化：利用模板方法设计模式，将功能部分抽取出来</p>
<p>上述代码可以抽取为：一个采集执行者，一个自定义采集数据的实现</p>
<pre><code class="java">/**
 * @Description: 执行者 man
 * @author: chenmingyu
 * @date: 2018/6/24 17:29
 */
public class Crawler {

    private Gatherer gatherer;

    public Object execute(String url,Long time){
        // 获取 webClient对象
        WebClient webClient = WebClientUtils.getWebClientLoadJs();
        try {
            HtmlPage page = webClient.getPage(url);
            if(null != time){
                webClient.waitForBackgroundJavaScript(time);
            }
            return gatherer.crawl(page);
        }catch (Exception e){

            e.printStackTrace();
        }finally {
            webClient.close();
        }
        return null;
    }

   public Crawler(Gatherer gatherer) {
        this.gatherer = gatherer;
    }
}</code></pre>
<p>在Crawler 中注入一个接口，这个接口只有一个方法crawl（），不同的实现类去实现这个接口,然后自定义取特征数据的实现</p>
<pre><code class="java">/**
 * @Description: 自定义实现
 * @author: chenmingyu
 * @date: 2018/6/24 17:36
 */
public interface Gatherer {

    Object crawl(HtmlPage page) throws Exception;
}
</code></pre>
<p>优化后的代码:</p>
<pre><code class="java">    @GetMapping(&quot;/getData&quot;)
    public List&lt;String&gt; article_(String url,String xpath){

        Gatherer gatherer = (page)-&gt;{
            List&lt;String&gt; datas = new ArrayList&lt;&gt;();
            List&lt;?&gt; lists = page.getByXPath(xpath);
            lists.stream().forEach(i-&gt;{
                DomNode domNode = (DomNode)i;
                datas.add(domNode.asText());
            });
            return datas;
        };

        Crawler crawler = new Crawler(gatherer);
        List&lt;String&gt; datas = (List&lt;String&gt;)crawler.execute(url,null);
        return datas;
    }</code></pre>
<p>不同的实现，只需要去修改接口实现的这部分就可以了</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>最后看一下利用采集系统采集的数据。</p>
<h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>效果还是不错的，最主要是系统运行稳定：</p>
<ol>
<li>采集的历史数据在600-700万量级之间</li>
<li>每天新采集的数据增量在一万左右</li>
<li>系统目前配置了大约1200多个任务（一次定时的实现会去采集这些网站）</li>
</ol>
<h3 id="数据-1"><a href="#数据-1" class="headerlink" title="数据"></a>数据</h3><p>系统配置采集的网站主要针对全国各省市县招投标网站（目前大约配置了1200多个采集站点）的标讯信息。<br>采集的数据主要做公司标讯的数据中心，为一个pc端网站和2微信个公众号提供数据</p>
<ul>
<li>网址：<a href="http://www.bid-data.com" target="_blank" rel="noopener">http://www.bid-data.com</a></li>
<li>公众号：爱招标，中标喽</li>
</ul>
<p>欢迎关注，掌握一手标讯信息</p>
<p>以pc端展示的一篇采集的中标的数据为例，看下采集效果：</p>
<ul>
<li><a href="http://www.bid-data.com/bid_MQKHG001TD6.html" target="_blank" rel="noopener">http://www.bid-data.com/bid_MQKHG001TD6.html</a><br>采集的详情：<br><img src="crawler-htmlunit/5.jpg" alt=""><br>特征数据的提取：<br><img src="crawler-htmlunit/6.jpg" alt=""></li>
</ul>
<blockquote>
<p>本文只是大概记录下这个采集系统从零到整的过程，当然其中还遇到了很多本文没提到的问题。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenmingyu.top/crawler-htmlunit/" data-id="ckdn6w7wi0005aktwfcjw99ww" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/htmlunit/" rel="tag">htmlunit</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&amp;laquo; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">下一页 &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/elasticsearch/">elasticsearch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/jvm/">jvm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/nosql/">nosql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tomcat/">tomcat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/zookeeper/">zookeeper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/">分布式事务</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/">网络协议</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Integer%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/" rel="tag">Integer缓存机制</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/aop/" rel="tag">aop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/effective/" rel="tag">effective</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/" rel="tag">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/email/" rel="tag">email</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/exception/" rel="tag">exception</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gc/" rel="tag">gc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/htmlunit/" rel="tag">htmlunit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/io/" rel="tag">io</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jvm%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/" rel="tag">jvm内存区域</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mybatis/" rel="tag">mybatis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nio/" rel="tag">nio</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rabbitmq/" rel="tag">rabbitmq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/" rel="tag">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/springboot/" rel="tag">springboot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring%E6%BA%90%E7%A0%81/" rel="tag">spring源码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/swagger2/" rel="tag">swagger2</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/thymeleaf/" rel="tag">thymeleaf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tomcat/" rel="tag">tomcat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/" rel="tag">zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/" rel="tag">中介者模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" rel="tag">二分查找</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" rel="tag">二叉树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/" rel="tag">享元模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/" rel="tag">代理模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/" rel="tag">分布式事务</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/" rel="tag">单例模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/" rel="tag">原型模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%8D%E5%B0%84/" rel="tag">反射</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/" rel="tag">命令模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/" rel="tag">垃圾收集器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/" rel="tag">备忘录模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/" rel="tag">外观模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/" rel="tag">定时任务</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/" rel="tag">工厂模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/" rel="tag">建造者模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8/" rel="tag">异常</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8/" rel="tag">异步调用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82/" rel="tag">抽象工厂</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/" rel="tag">日志管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/" rel="tag">桥接模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/" rel="tag">模板方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/" rel="tag">策略模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/" rel="tag">类加载机制</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B4%A2%E5%BC%95/" rel="tag">索引</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E7%A8%8B/" rel="tag">线程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/" rel="tag">线程池</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/" rel="tag">组合模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" rel="tag">网络协议</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/" rel="tag">装饰器模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/" rel="tag">观察者模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/" rel="tag">解释器模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" rel="tag">设计模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/" rel="tag">访问者模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/" rel="tag">责任链模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/" rel="tag">迭代器模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/" rel="tag">适配器模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/" rel="tag">配置文件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%94%81/" rel="tag">锁</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9B%86%E5%90%88/" rel="tag">集合</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Integer%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">Integer缓存机制</a> <a href="/tags/aop/" style="font-size: 10px;">aop</a> <a href="/tags/effective/" style="font-size: 10px;">effective</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/exception/" style="font-size: 10px;">exception</a> <a href="/tags/gc/" style="font-size: 10px;">gc</a> <a href="/tags/htmlunit/" style="font-size: 10px;">htmlunit</a> <a href="/tags/io/" style="font-size: 10px;">io</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/jvm%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/" style="font-size: 10px;">jvm内存区域</a> <a href="/tags/mybatis/" style="font-size: 12.5px;">mybatis</a> <a href="/tags/mysql/" style="font-size: 12.5px;">mysql</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/rabbitmq/" style="font-size: 10px;">rabbitmq</a> <a href="/tags/redis/" style="font-size: 17.5px;">redis</a> <a href="/tags/springboot/" style="font-size: 20px;">springboot</a> <a href="/tags/spring%E6%BA%90%E7%A0%81/" style="font-size: 10px;">spring源码</a> <a href="/tags/swagger2/" style="font-size: 10px;">swagger2</a> <a href="/tags/thymeleaf/" style="font-size: 10px;">thymeleaf</a> <a href="/tags/tomcat/" style="font-size: 10px;">tomcat</a> <a href="/tags/zookeeper/" style="font-size: 10px;">zookeeper</a> <a href="/tags/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">中介者模式</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" style="font-size: 10px;">二分查找</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 10px;">二叉树</a> <a href="/tags/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">享元模式</a> <a href="/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">代理模式</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/" style="font-size: 10px;">分布式事务</a> <a href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">单例模式</a> <a href="/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">原型模式</a> <a href="/tags/%E5%8F%8D%E5%B0%84/" style="font-size: 10px;">反射</a> <a href="/tags/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">命令模式</a> <a href="/tags/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/" style="font-size: 10px;">垃圾收集器</a> <a href="/tags/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/" style="font-size: 12.5px;">备忘录模式</a> <a href="/tags/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">外观模式</a> <a href="/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/" style="font-size: 10px;">定时任务</a> <a href="/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">工厂模式</a> <a href="/tags/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">建造者模式</a> <a href="/tags/%E5%BC%82%E5%B8%B8/" style="font-size: 10px;">异常</a> <a href="/tags/%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8/" style="font-size: 10px;">异步调用</a> <a href="/tags/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82/" style="font-size: 10px;">抽象工厂</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/" style="font-size: 10px;">日志管理</a> <a href="/tags/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">桥接模式</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/" style="font-size: 10px;">模板方法</a> <a href="/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">策略模式</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 12.5px;">算法</a> <a href="/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">类加载机制</a> <a href="/tags/%E7%B4%A2%E5%BC%95/" style="font-size: 10px;">索引</a> <a href="/tags/%E7%BA%BF%E7%A8%8B/" style="font-size: 10px;">线程</a> <a href="/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/" style="font-size: 10px;">线程池</a> <a href="/tags/%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">组合模式</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" style="font-size: 10px;">网络协议</a> <a href="/tags/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">装饰器模式</a> <a href="/tags/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">观察者模式</a> <a href="/tags/%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">解释器模式</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">设计模式</a> <a href="/tags/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">访问者模式</a> <a href="/tags/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">责任链模式</a> <a href="/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">迭代器模式</a> <a href="/tags/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">适配器模式</a> <a href="/tags/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/" style="font-size: 10px;">配置文件</a> <a href="/tags/%E9%94%81/" style="font-size: 10px;">锁</a> <a href="/tags/%E9%9B%86%E5%90%88/" style="font-size: 10px;">集合</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/mysql-create-index/">这道面试题你确定不看看吗：一条sql语句，有多个查询条件，你会选择哪个字段作为索引，为什么？</a>
          </li>
        
          <li>
            <a href="/zookeeper/">zookeeper命令详解</a>
          </li>
        
          <li>
            <a href="/data-structure-binary-search/">【数据结构】| 二分查找</a>
          </li>
        
          <li>
            <a href="/jvm-class-loader/">【jvm】类加载机制</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 陈明羽<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>