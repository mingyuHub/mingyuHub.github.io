

<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="renderer" content="webkit">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black">
	<meta name="description" content="但行好事 莫问前程">

	
		
			<link rel="stylesheet" href="/bower_components/fancybox/source/jquery.fancybox.css">
		
		<link rel="stylesheet" href="/bower_components/font-awesome/css/font-awesome.min.css">
		<link rel="stylesheet" href="/css/style.css">
	

	<title>但行好事 莫问前程 - 明羽</title>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
<header id="header">
	<div class="center">
		<div class="wrap">
			<div id="site">
				<h1>
					<a href="/">但行好事 莫问前程</a>
					
						<a class="github" href="https://github.com/dnxbf321" target="_blank" rel="noopener">
	  					<svg aria-hidden="true" class="octicon octicon-mark-github" height="28" role="img" version="1.1" viewBox="0 0 16 16" width="28"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59 0.4 0.07 0.55-0.17 0.55-0.38 0-0.19-0.01-0.82-0.01-1.49-2.01 0.37-2.53-0.49-2.69-0.94-0.09-0.23-0.48-0.94-0.82-1.13-0.28-0.15-0.68-0.52-0.01-0.53 0.63-0.01 1.08 0.58 1.23 0.82 0.72 1.21 1.87 0.87 2.33 0.66 0.07-0.52 0.28-0.87 0.51-1.07-1.78-0.2-3.64-0.89-3.64-3.95 0-0.87 0.31-1.59 0.82-2.15-0.08-0.2-0.36-1.02 0.08-2.12 0 0 0.67-0.21 2.2 0.82 0.64-0.18 1.32-0.27 2-0.27 0.68 0 1.36 0.09 2 0.27 1.53-1.04 2.2-0.82 2.2-0.82 0.44 1.1 0.16 1.92 0.08 2.12 0.51 0.56 0.82 1.27 0.82 2.15 0 3.07-1.87 3.75-3.65 3.95 0.29 0.25 0.54 0.73 0.54 1.48 0 1.07-0.01 1.93-0.01 2.2 0 0.21 0.15 0.46 0.55 0.38C13.71 14.53 16 11.53 16 8 16 3.58 12.42 0 8 0z"></path></svg>
						</a>
					
				</h1>
				
					<h2>
						<a href="/">明羽</a>
					</h2>
				
			</div>
			<nav id="menu">
				<ul>
					
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives/">归档</a></li>
					
				</ul>
			</nav>
		</div>
	</div>
</header>

<div id="content">
	<div class="center">
		<div class="main-col">
			

	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-07-10T02:11:03.000Z">2019-07-10</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/es-query/">Elasticsearch 查询语句详解</a></h1>
	

		</header>
		<div class="entry">
			
				<p>本文主要详细介绍es中常用的查询语句，以及使用的时候一些需要注意的事项</p>
<p>如对es不了解，建议先看 es基础: <a href="https://juejin.im/post/5cdc07446fb9a0322e73b5b5" target="_blank" rel="noopener">https://juejin.im/post/5cdc07446fb9a0322e73b5b5</a></p>
<h3 id="url参数搜索"><a href="#url参数搜索" class="headerlink" title="url参数搜索"></a>url参数搜索</h3><p>这种方式就是类似于get请求，将请求参数拼接到链接上，例<code>GET /school/student/_search?参数</code>，多个参数用&amp;分开</p>
<h4 id="查询所有"><a href="#查询所有" class="headerlink" title="查询所有"></a>查询所有</h4><p>命令：<code>GET /school/student/_search</code></p>
<p>返回：</p>
<pre><code class="json">{
  &quot;took&quot;: 7, //查询耗时，毫秒
  &quot;timed_out&quot;: false, //是否超时，timeout 不是停止执行查询，它仅仅是告知正在协调的节点返回到目前为止收集的结果并且关闭连接
  &quot;_shards&quot;: {
    &quot;total&quot;: 5, //请求的分片数量，索引拆成了5个分片，所以对于搜索请求，会打到所有的primary shard
    &quot;successful&quot;: 5,
    &quot;skipped&quot;: 0,
    &quot;failed&quot;: 0
  },
  &quot;hits&quot;: {
    &quot;total&quot;: 2, //符合条件的总条数，这里查的是所有
    &quot;max_score&quot;: 1, //匹配分数
    &quot;hits&quot;: [ //数据
      {
        &quot;_index&quot;: &quot;school&quot;,
        &quot;_type&quot;: &quot;student&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;name&quot;: &quot;houyi&quot;,
          &quot;age&quot;: 23,
          &quot;class&quot;: 2,
          &quot;gender&quot;: &quot;男&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;school&quot;,
        &quot;_type&quot;: &quot;student&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;name&quot;: &quot;吕布&quot;,
          &quot;age&quot;: 21,
          &quot;class&quot;: 2,
          &quot;gender&quot;: &quot;男&quot;
        }
      }
    ]
  }
}</code></pre>
<h4 id="多索引，多type搜索"><a href="#多索引，多type搜索" class="headerlink" title="多索引，多type搜索"></a>多索引，多type搜索</h4><p>在URL中指定特殊的索引和类型进行多索引，多type搜索</p>
<ol>
<li><code>/_search</code>：在所有的索引中搜索所有的类型</li>
<li><code>/school/_search</code>：在 <code>school</code> 索引中搜索所有的类型</li>
<li><code>/school,ad/_search</code>：在 <code>school</code> 和<code>ad</code>索引中搜索所有的类型</li>
<li><code>/s*,a*/_search</code>：在所有以<code>g</code>和<code>a</code>开头的索引中所有所有的类型</li>
<li><code>/school/student/_search</code>：在<code>school</code>索引中搜索<code>student</code>类型</li>
<li><code>/school,ad/student,phone/_search</code>：在<code>school</code>和<code>ad</code>索引上搜索<code>student</code>和<code>phone</code>类型</li>
<li><code>/_all/student,phone/_search</code>：在所有的索引中搜索<code>student</code>和<code>phone</code>类型</li>
</ol>
<h4 id="按条件查询"><a href="#按条件查询" class="headerlink" title="按条件查询"></a>按条件查询</h4><p>命令：<code>GET /school/student/_search?q=name:houyi</code></p>
<p>查询name是houyi的记录</p>
<p>更多查询参数：</p>
<p><img src="/es-query/my/myblog/source/_posts/es-basics/url%E6%90%9C%E7%B4%A2%E5%8F%82%E6%95%B0.png" alt></p>
<h3 id="查询DSL"><a href="#查询DSL" class="headerlink" title="查询DSL"></a>查询DSL</h3><p>elasticsearch提供了基于JSON的完整查询DSL来定义查询，DSL拥有一套查询组件，这些组件可以以无限组合的方式进行搭配，构建各种复杂的查询</p>
<h4 id="叶子语句"><a href="#叶子语句" class="headerlink" title="叶子语句"></a>叶子语句</h4><p>叶子语句：就像match语句，被用于将查询的字符串与一个字段或多个字段进行对比（单个条件）<br>比如：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;name&quot;: &quot;phone&quot;
       }
     }
   }</code></pre>
<h4 id="复合查询"><a href="#复合查询" class="headerlink" title="复合查询"></a>复合查询</h4><p>用户合并其他查询语句，比如一个<code>bool</code>语句，允许你在需要的时候组合其他语句，包括<code>must</code>，<code>must_not</code>，<code>should</code>和<code>filter</code>语句（多条件组合查询）<br>比如：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;must&quot;: [
           {&quot;match&quot;: {
             &quot;name&quot;: &quot;phone&quot;
           }}
         ]
         , &quot;must_not&quot;: [
           {&quot;match&quot;: {
             &quot;color&quot;: &quot;red&quot;
           }}
         ]
         , &quot;should&quot;: [
           {&quot;match&quot;: {
             &quot;price&quot;: 5000
           }}
         ]
         , &quot;filter&quot;: {
             &quot;term&quot;: {
               &quot;label&quot;: &quot;phone&quot;
             }
         }
       }
     }
   }</code></pre>
<p><code>must</code>：表示文档一定要包含查询的内容</p>
<p><code>must_not</code>：表示文档一定不要包含查询的内容</p>
<p><code>should</code>：表示如果文档匹配上可以增加文档相关性得分</p>
<p>事实上我们可以使用两种结构化语句： 结构化查询<code>query DSL</code>和结构化过滤<code>Filter DSL</code></p>
<ol>
<li><p>结构化查询<code>query DSL</code></p>
<p>用于检查内容与条件是否匹配，内容查询中使用的bool和match字句，用于计算每个文档的匹配得分，元字段_score表示匹配度，查询的结构中以query参数开始来执行内容查询</p>
</li>
<li><p>结构化过滤<code>Filter DSL</code></p>
<p>只是简单的决定文档是否匹配，内容过滤中使用的term和range字句，会过滤 调不匹配的文档，并且不影响计算文档匹配得分</p>
<p>使用过滤查询会被es自动缓存用来提高效率</p>
</li>
</ol>
<p>原则上来说，使用查询语句做全文本搜索或其他需要进行相关性评分的时候，剩下的全部用过滤语句</p>
<p><strong>新建一个稍微复杂的索引，添加三条文档</strong></p>
<pre><code class="json">PUT /ad/phone/1
{
  &quot;name&quot;:&quot;phone 8&quot;,
  &quot;price&quot;: 6000,
  &quot;color&quot;:&quot;white&quot;,
  &quot;ad&quot;:&quot;this is a white phone&quot;,
  &quot;label&quot;:[&quot;white&quot;,&quot;nice&quot;]
}

PUT /ad/phone/2
{
  &quot;name&quot;:&quot;xiaomi 8&quot;,
  &quot;price&quot;: 4000,
  &quot;color&quot;:&quot;red&quot;,
  &quot;ad&quot;:&quot;this is a red phone&quot;,
  &quot;label&quot;:[&quot;white&quot;,&quot;xiaomi&quot;]
}

PUT /ad/phone/3
{
  &quot;name&quot;:&quot;huawei p30&quot;,
  &quot;price&quot;: 5000,
  &quot;color&quot;:&quot;white&quot;,
  &quot;ad&quot;:&quot;this is a white phone&quot;,
  &quot;label&quot;:[&quot;white&quot;,&quot;huawei&quot;]
}
</code></pre>
<h3 id="查询示例"><a href="#查询示例" class="headerlink" title="查询示例"></a>查询示例</h3><h4 id="1-获取所有"><a href="#1-获取所有" class="headerlink" title="1. 获取所有"></a>1. 获取所有</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     }
   }</code></pre>
<p><code>match_all</code>匹配所有数据，返回的结果中元字段<code>_score</code>得分为1</p>
<h4 id="2-分页查询，从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题）"><a href="#2-分页查询，从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题）" class="headerlink" title="2. 分页查询，从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题）"></a>2. 分页查询，从第二条开始，查两条（不要使用<code>from</code>，<code>size</code>进行深度分页，会有性能问题）</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     },
     &quot;from&quot;: 1,
     &quot;size&quot;: 2
   }</code></pre>
<p>这种分页方式如果进行深度分页，比如到100页，每页十条数据，它会从每个分片都查询出100*10条数据，假设有五个分片，就是5000条数据，然后在内存中进行排序，然后返回拍过序之后的集合中的第1000-1010条数据</p>
<h4 id="3-指定查询出来的数据返回的字段"><a href="#3-指定查询出来的数据返回的字段" class="headerlink" title="3. 指定查询出来的数据返回的字段"></a>3. 指定查询出来的数据返回的字段</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     },
     &quot;_source&quot;: [&quot;name&quot;,&quot;price&quot;]
   }</code></pre>
<p>返回的数据中只返回<code>name</code>和<code>price</code>字段</p>
<h4 id="4-ad字段中包含单词white"><a href="#4-ad字段中包含单词white" class="headerlink" title="4. ad字段中包含单词white"></a>4. ad字段中包含单词white</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: &quot;white&quot;
       }
     }
   }</code></pre>
<p>返回的结果中元字段<code>_score</code>有评分，说明使用<code>query</code>会计算评分</p>
<h4 id="5-ad字段中包含单词white，并按照价格升序排列"><a href="#5-ad字段中包含单词white，并按照价格升序排列" class="headerlink" title="5. ad字段中包含单词white，并按照价格升序排列"></a>5. ad字段中包含单词white，并按照价格升序排列</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: &quot;white&quot;
       }
     }, 
     &quot;sort&quot;: [
       {
         &quot;price&quot;: {
           &quot;order&quot;: &quot;asc&quot;
         }
       }
     ]
   }</code></pre>
<h4 id="6-价格字段大于5000"><a href="#6-价格字段大于5000" class="headerlink" title="6. 价格字段大于5000"></a>6. 价格字段大于5000</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;filter&quot;: {
           &quot;range&quot;: {
             &quot;price&quot;: {
               &quot;gt&quot;: 5000
             }
           }
         }
       }
     }
   }</code></pre>
<p>返回的结果中元字段<code>_score</code>字段等于0，没评分，说明使用<code>filter</code>不会计算评分</p>
<h4 id="7-ad字段中包含单词white，价格字段大于5000"><a href="#7-ad字段中包含单词white，价格字段大于5000" class="headerlink" title="7. ad字段中包含单词white，价格字段大于5000"></a>7. ad字段中包含单词white，价格字段大于5000</h4><pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;must&quot;: [
           {
             &quot;match&quot;: {
               &quot;ad&quot;: &quot;white&quot;
             }
           }
         ], 
         &quot;filter&quot;: {
           &quot;range&quot;: {
             &quot;price&quot;: {
               &quot;gt&quot;: 5000
             }
           }
         }
       }
     }
   }</code></pre>
<h4 id="8-查询name字段包含单词phone的文档的数量"><a href="#8-查询name字段包含单词phone的文档的数量" class="headerlink" title="8. 查询name字段包含单词phone的文档的数量"></a>8. 查询<code>name</code>字段包含单词<code>phone</code>的文档的数量</h4><pre><code class="json">   GET /ad/phone/_count
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;name&quot;: &quot;phone&quot;
       }
     }
   }</code></pre>
<h3 id="关键词详解"><a href="#关键词详解" class="headerlink" title="关键词详解"></a>关键词详解</h3><h4 id="1-match-all查询"><a href="#1-match-all查询" class="headerlink" title="1. match_all查询"></a>1. <code>match_all</code>查询</h4><p>查询简单的匹配所有文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     }
   }</code></pre>
<h4 id="2-match查询"><a href="#2-match查询" class="headerlink" title="2. match查询"></a>2. <code>match</code>查询</h4><p>支持全文搜索和精确查询，取决于字段是否支持全文检索</p>
<p>全文检索：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: &quot;a red&quot;
       }
     }
   }</code></pre>
<p>全文检索会将查询的字符串先进行分词，<code>a red</code>会分成为<code>a</code>和<code>red</code>，然后在倒排索引中进行匹配，所以这条语句会将三条文档都查出来</p>
<p>精确查询：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;price&quot;: &quot;6000&quot;
       }
     }
   }</code></pre>
<p>对于精确值的查询，可以使用 filter 语句来取代 query，因为 filter 将会被缓存</p>
<p><code>operator</code>操作：</p>
<p><code>match</code> 查询还可以接受 <code>operator</code> 操作符作为输入参数，默认情况下该操作符是 <code>or</code> 。我们可以将它修改成 <code>and</code> 让所有指定词项都必须匹配</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: {
           &quot;query&quot;: &quot;a red&quot;,
           &quot;operator&quot;: &quot;and&quot;
         }
       }
     }
   }</code></pre>
<p>精确度匹配：</p>
<p><code>match</code> 查询支持 <code>minimum_should_match</code> 最小匹配参数， 可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字（指需要匹配倒排索引的词的数量），更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match&quot;: {
         &quot;ad&quot;: {
           &quot;query&quot;: &quot;a red&quot;,
           &quot;minimum_should_match&quot;: &quot;2&quot;
         }
       }
     }
   }</code></pre>
<p>   只会返回匹配上<code>a</code>和<code>red</code>两个词的文档返回，如果<code>minimum_should_match</code>是1，则只要匹配上其中一个词，文档就会返回</p>
<h4 id="3-multi-match查询"><a href="#3-multi-match查询" class="headerlink" title="3. multi_match查询"></a>3. <code>multi_match</code>查询</h4><p>多字段查询，比如查询<code>color</code>和<code>ad</code>字段包含单词<code>red</code>的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;multi_match&quot;: {
         &quot;query&quot;: &quot;red&quot;,
         &quot;fields&quot;: [&quot;color&quot;,&quot;ad&quot;]
       }
     }
   }</code></pre>
<h4 id="4-range查询"><a href="#4-range查询" class="headerlink" title="4. range查询"></a>4. <code>range</code>查询</h4><p>   范围查询，查询价格大于4000小于6000的文档</p>
<pre><code>   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;range&quot;: {
         &quot;price&quot;: {
           &quot;gt&quot;: 4000,
           &quot;lt&quot;: 6000
         }
       }
     }
   }</code></pre><p>   范围查询操作符：<code>gt</code> （大于），<code>gte</code>（大于等于），<code>lt</code>（小于），<code>lte</code>（小于等于)；</p>
<h4 id="5-term查询"><a href="#5-term查询" class="headerlink" title="5. term查询"></a>5. <code>term</code>查询</h4><p>   精确值查询</p>
<p>   查询<code>price</code>字段等于6000的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;term&quot;: {
         &quot;price&quot;: {
           &quot;value&quot;: &quot;6000&quot;
         }
       }
     }
   }</code></pre>
<p>   查询<code>name</code>字段等于<code>phone 8</code>的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;term&quot;: {
         &quot;name&quot;: {
           &quot;value&quot;: &quot;phone 8&quot;
         }
       }
     }
   }</code></pre>
<p>   返回值如下，没有查询到名称为<code>phone 8</code>的文档</p>
<pre><code class="json">   {
     &quot;took&quot;: 5,
     &quot;timed_out&quot;: false,
     &quot;_shards&quot;: {
       &quot;total&quot;: 5,
       &quot;successful&quot;: 5,
       &quot;skipped&quot;: 0,
       &quot;failed&quot;: 0
     },
     &quot;hits&quot;: {
       &quot;total&quot;: 0,
       &quot;max_score&quot;: null,
       &quot;hits&quot;: []
     }
   }</code></pre>
<p>   为什么没有查到<code>phone 8</code>的这个文档那，这里需要介绍一下<code>term</code>的查询原理</p>
<pre><code>   `term`查询会去倒排索引中寻找确切的`term`,它并不会走分词器，只会去配倒排索引 ，而`name`字段的`type`类型是`text`，会进行分词，将`phone 8 ` 分为`phone`和`8`，我们使用`term`查询`phone 8`时倒排索引中没有`phone 8`，所以没有查询到匹配的文档</code></pre><p>   <code>term</code>查询与<code>match</code>查询的区别</p>
<ul>
<li><p><code>term</code>查询时，不会分词，直接匹配倒排索引</p>
</li>
<li><p><code>match</code>查询时会进行分词，查询<code>phone 8</code>时，会先分词成<code>phone</code>和<code>8</code>，然后去匹配倒排索引，所以结果会将<code>phone 8</code>和<code>xiaomi 8</code>两个文档都查出来</p>
<p>还有一点需要注意，因为<code>term</code>查询不会走分词器，但是回去匹配倒排索引，所以查询的结构就跟分词器如何分词有关系，比如新增一个<code>/ad/phone</code>类型下的文档，<code>name</code>字段赋值为<code>Oppo</code>，这时使用<code>term</code>查询<code>Oppo</code>不会查询出文档，这时因为es默认是用的<code>standard</code>分词器，它在分词后会将单词转成小写输出，所以使用<code>oppo</code>查不出文档，使用小写<code>oppo</code>可以查出来</p>
</li>
</ul>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;term&quot;: {
         &quot;name&quot;: {
           &quot;value&quot;: &quot;Oppo&quot; //改成oppo可以查出新添加的文档
         }
       }
     }
   }</code></pre>
<p>   这里说的并不是想让你了解<code>standard</code>分词器，而是要get到所有像<code>term</code>这类的查询结果跟选择的分词器有关系，了解选择的分词器分词方式有助于我们编写查询语句</p>
<h4 id="6-terms查询"><a href="#6-terms查询" class="headerlink" title="6. terms查询"></a>6. <code>terms</code>查询</h4><p>   <code>terms</code>查询与<code>term</code>查询一样，但它允许你指定多直进行匹配，如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;terms&quot;: {
         &quot;ad&quot;: [&quot;red&quot;,&quot;blue&quot;]
       }
     }
   }</code></pre>
<h4 id="7-exists-查询和-missing-查询"><a href="#7-exists-查询和-missing-查询" class="headerlink" title="7. exists 查询和 missing 查询"></a>7. <code>exists</code> 查询和 <code>missing</code> 查询</h4><p>   用于查找那些指定字段中有值 (<code>exists</code>) 或无值 (<code>missing</code>) 的文档</p>
<p>   指定<code>name</code>字段有值：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;filter&quot;: {
           &quot;exists&quot;: {
             &quot;field&quot;: &quot;name&quot;
           }
         }
       }
     }
   }</code></pre>
<p>   指定<code>name</code>字段无值：</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;bool&quot;: {
         &quot;filter&quot;: {
           &quot;missing&quot;: {
             &quot;field&quot;: &quot;name&quot;
           }
         }
       }
     }
   }</code></pre>
<h4 id="8-match-phrase查询"><a href="#8-match-phrase查询" class="headerlink" title="8. match_phrase查询"></a>8. <code>match_phrase</code>查询</h4><p>   短语查询，精确匹配，查询<code>a red</code>会匹配<code>ad</code>字段包含<code>a red</code>短语的，而不会进行分词查询，也不会查询出包含<code>a 其他词 red</code>这样的文档</p>
<pre><code class="json">   GET /ad/phone/_search
   {
     &quot;query&quot;: {
       &quot;match_phrase&quot;: {
         &quot;ad&quot;: &quot;a red&quot;
       }
     }
   }</code></pre>
<h4 id="9-scroll查询"><a href="#9-scroll查询" class="headerlink" title="9. scroll查询"></a>9. <code>scroll</code>查询</h4><p>   类似于分页查询，不支持跳页查询，只能一页一页往下查询，<code>scroll</code>查询不是针对实时用户请求，而是针对处理大量数据，例如为了将一个索引的内容重新索引到具有不同配置的新索引中</p>
<pre><code class="json">   POST /ad/phone/_search?scroll=1m
   {
     &quot;query&quot;: {
       &quot;match_all&quot;: {}
     },
     &quot;size&quot;: 1,
     &quot;from&quot;: 0
   }</code></pre>
<p>   返回值包含一个  <code>&quot;_scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAAQFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAERZVek91amNjWlQwS0RubmV3YmdIRWFBAAAAAAAAABIWVXpPdWpjY1pUMEtEbm5ld2JnSEVhQQAAAAAAAAATFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAFBZVek91amNjWlQwS0RubmV3YmdIRWFB&quot;</code></p>
<p>   下次查询的时候使用<code>_scroll_id</code>就可以查询下一页的文档</p>
<pre><code class="json">   POST /_search/scroll 
   {
       &quot;scroll&quot; : &quot;1m&quot;, 
       &quot;scroll_id&quot; : &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAAYFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAGRZVek91amNjWlQwS0RubmV3YmdIRWFBAAAAAAAAABYWVXpPdWpjY1pUMEtEbm5ld2JnSEVhQQAAAAAAAAAXFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAFRZVek91amNjWlQwS0RubmV3YmdIRWFB&quot; 
   }</code></pre>
<h4 id="10-multi-get查询"><a href="#10-multi-get查询" class="headerlink" title="10. multi get查询"></a>10. <code>multi get</code>查询</h4><p>允许基于索引，类型（可选）和id（以及可能的路由）获取多个文档，如果某个文档获取失败则将错误信息包含在响应中</p>
<pre><code>​```json
GET /ad/phone/_mget
{
  &quot;ids&quot;: [&quot;1&quot;,&quot;8&quot;]
}
​```</code></pre><h4 id="11-bulk批量操作"><a href="#11-bulk批量操作" class="headerlink" title="11. bulk批量操作"></a>11. <code>bulk</code>批量操作</h4><p><code>bulk</code>批量操作可以在单次API调用中实现多个文档的<code>create</code>、<code>index</code>、<code>update</code>或<code>delete</code>。这可以大大提高索引速度</p>
<p><code>bulk</code>请求体如下</p>
<pre><code class="json">{ action: { metadata }}\n 
{ request body        }\n
{ action: { metadata }}\n
{ request body        }\n
...</code></pre>
<p><strong>action</strong>必须是以下几种：<br>| 行为   | 解释                     |<br>| —— | ———————— |<br>| create | 当文档不存在时创建       |<br>| index  | 创建新文档或替换已有文档 |<br>| update | 局部更新文档             |<br>| delete | 删除一个文档             |<br>在索引、创建、更新或删除时必须指定文档的<code>_index</code>、<code>_type</code>、<code>_id</code>这些元数据(<code>metadata</code>)</p>
<p>例：</p>
<pre><code class="json">    PUT _bulk
    { &quot;create&quot; : { &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;6&quot; }}
    { &quot;doc&quot; : {&quot;name&quot; : &quot;bulk&quot;}}
    { &quot;index&quot; : { &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;6&quot; }}
    { &quot;doc&quot; : {&quot;name&quot; : &quot;bulk&quot;}}
    { &quot;delete&quot;:{  &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;1&quot;}}
    { &quot;update&quot;:{  &quot;_index&quot; : &quot;ad&quot;, &quot;_type&quot; : &quot;phone&quot;, &quot;_id&quot; : &quot;3&quot;}}
    { &quot;doc&quot; : {&quot;name&quot; : &quot;huawei p20&quot;}}</code></pre>
<p>返回：</p>
<pre><code class="json">    {
      &quot;took&quot;: 137,
      &quot;errors&quot;: true, //如果任意一个文档出错，这里返回true,
      &quot;items&quot;: [ //items数组，它罗列了每一个请求的结果，结果的顺序与我们请求的顺序相同
        {
          //create这个文档已经存在，所以异常
          &quot;create&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;6&quot;,
            &quot;status&quot;: 409,
            &quot;error&quot;: {
              &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,
              &quot;reason&quot;: &quot;[phone][6]: version conflict, document already exists (current version [2])&quot;,
              &quot;index_uuid&quot;: &quot;9F5FHqgISYOra_P09HReVQ&quot;,
              &quot;shard&quot;: &quot;2&quot;,
              &quot;index&quot;: &quot;ad&quot;
            }
          }
        },
        {
          //index这个文档已经存在，会覆盖
          &quot;index&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;6&quot;,
            &quot;_version&quot;: 3,
            &quot;result&quot;: &quot;updated&quot;,
            &quot;_shards&quot;: {
              &quot;total&quot;: 2,
              &quot;successful&quot;: 1,
              &quot;failed&quot;: 0
            },
            &quot;_seq_no&quot;: 6,
            &quot;_primary_term&quot;: 5,
            &quot;status&quot;: 200
          }
        },
        {
          //删除  
          &quot;delete&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;1&quot;,
            &quot;_version&quot;: 1,
            &quot;result&quot;: &quot;not_found&quot;,
            &quot;_shards&quot;: {
              &quot;total&quot;: 2,
              &quot;successful&quot;: 1,
              &quot;failed&quot;: 0
            },
            &quot;_seq_no&quot;: 4,
            &quot;_primary_term&quot;: 5,
            &quot;status&quot;: 404
          }
        },
        {
          //修改  
          &quot;update&quot;: { 
            &quot;_index&quot;: &quot;ad&quot;,
            &quot;_type&quot;: &quot;phone&quot;,
            &quot;_id&quot;: &quot;3&quot;,
            &quot;_version&quot;: 3,
            &quot;result&quot;: &quot;noop&quot;,
            &quot;_shards&quot;: {
              &quot;total&quot;: 2,
              &quot;successful&quot;: 1,
              &quot;failed&quot;: 0
            },
            &quot;status&quot;: 200
          }
        }
      ]
    }</code></pre>
<p><code>bulk</code>请求不是原子操作，它们不能实现事务。每个请求操作时分开的，所以每个请求的成功与否不干扰其它操作</p>
<h4 id="12-fuzzy查询"><a href="#12-fuzzy查询" class="headerlink" title="12. fuzzy查询"></a>12. <code>fuzzy</code>查询</h4><p>模糊查询，<code>fuzzy</code> 查询会计算与关键词的拼写相似程度</p>
<pre><code class="json">    GET /ad/phone/_search
    {
      &quot;query&quot;: {
        &quot;fuzzy&quot;: {
          &quot;color&quot;:{
            &quot;value&quot;: &quot;res&quot;
            , &quot;fuzziness&quot;: 2,
            &quot;prefix_length&quot;: 1
          }
        }
      }
    }</code></pre>
<p>参数设置：</p>
<p><code>fuzziness</code>：最大编辑距离，默认为<code>AUTO</code></p>
<p><code>prefix_length</code>：不会“模糊化”的初始字符数。这有助于减少必须检查的术语数量，默认为<code>0</code></p>
<p><code>max_expansions</code>：<code>fuzzy</code>查询将扩展到 的最大术语数。默认为<code>50</code>，设置小，有助于优化查询</p>
<p><code>transpositions</code>：是否支持模糊转置（<code>ab</code>→ <code>ba</code>），默认是<code>false</code></p>
<h4 id="13-wildcard查询"><a href="#13-wildcard查询" class="headerlink" title="13. wildcard查询"></a>13. <code>wildcard</code>查询</h4><p>支持通配符的模糊查询，？匹配单个字符，*匹配任何字符</p>
<p>为了防止极其缓慢通配符查询，<code>*</code>或<code>?</code>通配符项不应该放在通配符的开始</p>
<pre><code class="json">    GET /ad/phone/_search
    {
      &quot;query&quot;: {
        &quot;wildcard&quot;: {
          &quot;color&quot;: &quot;r?d&quot;
        }
      }
    }</code></pre>
<p>未完待续…</p>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/es-query/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/elasticsearch/">elasticsearch</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/elasticsearch/">#elasticsearch</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-07-09T06:58:39.000Z">2019-07-09</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/mysql-one/">mysql系列</a></h1>
	

		</header>
		<div class="entry">
			
				<blockquote>
<p>本文内容为：极客时间《mysql45讲》的内容</p>
</blockquote>
<h3 id="1-基础架构：一条SQL查询语句是如何执行的"><a href="#1-基础架构：一条SQL查询语句是如何执行的" class="headerlink" title="1.基础架构：一条SQL查询语句是如何执行的 ?"></a>1.基础架构：一条SQL查询语句是如何执行的 ?</h3><p>执行下面这个查询语句时 ,在 MySQL 内部的执行过程 </p>
<pre><code class="sql">select * from T where id = 10;</code></pre>
<p><img src="/mysql-one/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.png" alt></p>
<p>大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。</p>
<p>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服<br>务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都<br>在这一层实现，比如存储过程、触发器、视图等。</p>
<p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、<br>Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成<br>为了默认存储引擎 </p>
<p><strong>连接器：</strong></p>
<p>链接客户端，校验权限</p>
<p><strong>缓存：</strong></p>
<p>MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过<br>的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，<br>value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直<br>接返回给客户端 </p>
<p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存<br>中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结<br>果，这个效率会很高。 </p>
<p>但是很少使用缓存，因为只要更新表，表对应的缓存就全部失效</p>
<p>你可以将参数 query_cache_type 设置成<br>DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语<br>句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：</p>
<p>需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没</p>
<pre><code class="sql">select SQL_CACHE * from T where ID=10 ;</code></pre>
<p><strong>分析器：</strong></p>
<p>分析sql语句，是否满足 MySQL 语法</p>
<p>如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒 </p>
<p><strong>优化器：</strong></p>
<p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）<br>的时候，决定各个表的连接顺序 </p>
<p><strong>执行器：</strong></p>
<p>开始执行语句 </p>
<p>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没<br>有权限的错误 </p>
<pre><code class="sql">ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39; </code></pre>
<p>如果有权限，就打开表继续执行。打开表的时候，优化器就会根据表的引擎定义，去使用这个引<br>擎提供的接口 </p>
<h3 id="2-日志系统：一条SQL更新语句是如何执行的？"><a href="#2-日志系统：一条SQL更新语句是如何执行的？" class="headerlink" title="2.日志系统：一条SQL更新语句是如何执行的？"></a>2.日志系统：一条SQL更新语句是如何执行的？</h3><p>流程和查询相似，一条update语句会对应表的所有删除缓存</p>
<p><strong>redo log</strong></p>
<p>InnoDB 引擎特有的日志</p>
<p>在MySQL 中，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了redo log（重做日志） 来提升更新效率 </p>
<p>关键点就是先写日志，再写磁盘 ，mysql会先把记录写到redo log里面，并更新到内存，这个时候就算完成更新了，innoDB引擎会在适当的时候将这个操作记录更新到磁盘里</p>
<p><img src="/mysql-one/2.png" alt></p>
<p>wirte pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。<br>checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据<br>文件 </p>
<p>有了redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，<br>这个能力称为crash-safe </p>
<p><strong>WAL</strong>的全称是<strong>Write-Ahead Logging</strong>，它的关键点就是先写日志，再写磁盘</p>
<p><strong>binlog</strong></p>
<p>binlog（归档日志） 是server层实现的，可用于恢复数据库，主从之间同步数据</p>
<p><img src="/mysql-one/3.png" alt></p>
<p>Redo log是记录这个页 “做了什么改动”。<br>Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，<br>更新前和更新后都有</p>
<p>update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的</p>
<p><img src="/mysql-one/4.png" alt></p>
<p><strong>两阶段提交</strong> </p>
<p>redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致 </p>
<p>更多详细阅读：<a href="https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html" target="_blank" rel="noopener">https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html</a></p>
<h3 id="3-事务隔离：为什么你改了我还看不见？"><a href="#3-事务隔离：为什么你改了我还看不见？" class="headerlink" title="3.事务隔离：为什么你改了我还看不见？"></a>3.事务隔离：为什么你改了我还看不见？</h3><p>SQL 标准的事务隔离级别包括：</p>
<ol>
<li><p>读未提交（readuncommitted）</p>
<p>一个事务还没提交时，它做的变更就能被别的事务看到</p>
</li>
<li><p>读提交（read committed）</p>
<p>一个事务提交之后，它做的变更才会被其他事务看到 </p>
</li>
<li><p>可重复读（repeatable read）</p>
<p>一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的 </p>
</li>
<li><p>串行化（serializable ） </p>
<p>顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行 </p>
</li>
</ol>
<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>
<ol>
<li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</li>
<li>在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。</li>
<li>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念</li>
<li>“串行化”隔离级别下直接用加锁的方式来避免并行访问 </li>
</ol>
<p>设置mysql事务隔离级别</p>
<p>将transaction-isolation 的值设置成 READ-COMMITTED </p>
<p>show variables like ‘transaction_isolation’; 查看当前事务隔离级别</p>
<p>oracle默认事务隔离级别为读提交</p>
<p>mysql默认事务隔离级别为可重复读</p>
<h3 id="4-深入浅出索引"><a href="#4-深入浅出索引" class="headerlink" title="4.深入浅出索引"></a>4.深入浅出索引</h3><p>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样 </p>
<p><strong>索引的常见模型</strong> </p>
<p>介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树 </p>
<p>哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。 </p>
<p>哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。</p>
<p> 如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 </p>
<p>所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据 </p>
<p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子 </p>
<p><strong>索引类型</strong></p>
<p>分为主键索引和非主键索引 </p>
<p>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。 </p>
<p>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引 </p>
<p>根据上面的索引结构说明，我们来讨论一个问题：<strong>基于主键索引和普通索引的查询有什么区别？</strong></p>
<ul>
<li>如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+树；</li>
<li>如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。</li>
</ul>
<p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 </p>
<p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。<br>显然，<strong>主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong> </p>
<p><strong>回到主键索引树搜索的过程，我们称为回表</strong> </p>
<p><strong>覆盖索引</strong><br>如果执行的语句是 <code>select ID from T where k between 3 and 5</code>，这时只需要查 ID 的值，而ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p>
<p><strong>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</strong> </p>
<p>如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。</p>
<p>当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作 （不建议这么做）</p>
<p><strong>最左前缀原则</strong> </p>
<p><strong>B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong> </p>
<p>在建立联合索引的时候，如何安排索引内的字段顺序？<br>这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，<strong>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</strong> </p>
<p>如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。<br>这时候，我们要<strong>考虑的原则就是空间</strong>了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引 </p>
<p><strong>索引下推</strong> </p>
<p>以联合索引（name, age）为例 。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： </p>
<pre><code class="sql">select * from tuser where name like &#39;张 %&#39; and age=10 and ismale=1;</code></pre>
<p>在 <strong>MySQL 5.6</strong> 之前 ，只能用 “张”，找到第一个满足条件的记录 ID3 ，从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 </p>
<p><strong>在联合索引中，匹配name后会进行回表，然后从主键索引上找出数据行，在数据上进行age字段比对</strong></p>
<p><img src="/mysql-one/5.png" alt></p>
<p>而 <strong>MySQL 5.6</strong> 引入的<strong>索引下推</strong>优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 </p>
<p><img src="/mysql-one/6.png" alt></p>
<p>在<strong>索引下推</strong>优化下，<strong>在联合索引中，先匹配name，在不回表的情况下，接着比对age字段，不满足条件的记录直接过滤，只有满足条件的的才会进行回表，减少回表次数</strong></p>
<h3 id="5-全局锁和表锁-：给表加个字段怎么有这么多阻碍"><a href="#5-全局锁和表锁-：给表加个字段怎么有这么多阻碍" class="headerlink" title="5.全局锁和表锁 ：给表加个字段怎么有这么多阻碍"></a>5.全局锁和表锁 ：给表加个字段怎么有这么多阻碍</h3><p>根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类 </p>
<p><strong>全局锁</strong> </p>
<p>全局锁就是对整个数据库实例加锁 </p>
<p>MySQL 提供了一个加全局读锁的方法，命令是<code>Flush tables with read lock (FTWRL)</code>。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句 </p>
<p><strong>全局锁的典型使用场景是，做全库逻辑备份</strong> </p>
<p>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数<code>–single-transaction</code> 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。 （前提是引擎要支持这个隔离级别 ）</p>
<p><strong>single-transaction 方法只适用于所有的表使用事务引擎的库 （innodb）</strong></p>
<p><strong>表级锁</strong> </p>
<p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 </p>
<p>表锁的语法是 <code>lock tables … read/write</code> </p>
<p>与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象 </p>
<p><strong>另一类表级的锁是 MDL（metadata lock)</strong> </p>
<p>MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。 </p>
<p>在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。</p>
<ol>
<li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li>
<li>读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 </li>
</ol>
<p>MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。 </p>
<p><img src="/mysql-one/7.png" alt></p>
<p>我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。<br>之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要MDL 写锁，因此只能被阻塞。<br>如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。<br>如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session再请求的话，这个库的线程很快就会爆满。<br>你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放 </p>
<h3 id="6-行锁功过：怎么减少行锁对性能的影响？"><a href="#6-行锁功过：怎么减少行锁对性能的影响？" class="headerlink" title="6.行锁功过：怎么减少行锁对性能的影响？"></a>6.行锁功过：怎么减少行锁对性能的影响？</h3><p><strong>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议</strong> </p>
<p><img src="/mysql-one/8.png" alt></p>
<p>实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。 </p>
<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、<strong>最可能影响并发度的锁尽量往后放</strong> </p>
<p><strong>死锁和死锁检测</strong> </p>
<p><img src="/mysql-one/9.png" alt></p>
<p>事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p>
<ul>
<li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。</li>
<li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事<br>务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑 </li>
</ul>
<p>在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的 </p>
<p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的 </p>
<h3 id="7-事务到底是隔离的还是不隔离的？"><a href="#7-事务到底是隔离的还是不隔离的？" class="headerlink" title="7.事务到底是隔离的还是不隔离的？"></a>7.事务到底是隔离的还是不隔离的？</h3><p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的up_limit_id。普通查询语句是一致性读，一致性读会根据 row trx_id 和 up_limit_id 的大小决定数据版本的可见性。</p>
<ul>
<li>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；</li>
<li>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</li>
</ul>
<p>而当前读，总是读取已经提交完成的最新版本 </p>
<p><img src="/mysql-one/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB.png" alt></p>
<p>语句 Q1 返回的 k 的值是 3，而语句 Q2 返回的 k 的值是 1 </p>
<p><strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读（current read） “</strong></p>
<p><strong>InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。版本号就是事务Id</strong> </p>
<h3 id="8-普通索引和唯一索引，应该怎么选择？"><a href="#8-普通索引和唯一索引，应该怎么选择？" class="headerlink" title="8.普通索引和唯一索引，应该怎么选择？"></a>8.普通索引和唯一索引，应该怎么选择？</h3><p>对于查询过程来说：<br>a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，知道第一个不满足条件的记录<br>b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索</p>
<p>但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。</p>
<p>对于更新过程来说：</p>
<p>概念：<strong>change buffer</strong></p>
<p>当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中的与这个页有关的操作。</p>
<p>change buffer是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上</p>
<p>purge:将change buffer中的操作应用到原数据页上，得到最新结果的过程，成为purge访问这个数据页会触发purge，系统有后台线程定期purge，在数据库正常关闭的过程中，也会执行purge</p>
<p><strong>唯一索引的更新不能使用change buffer</strong><br>change buffer用的是buffer pool里的内存，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。<br>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。<br>change buffer使用场景<br>在一个数据页做purge之前，change buffer记录的变更越多，收益就越大。对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer,但之后由于马上要访问这个数据页，会立即触发purge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。</p>
<p><strong>索引的选择和实践：</strong><br>尽可能使用普通索引。<br>redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是<br>随机读磁盘的IO消耗。 </p>
<p><strong>命令：</strong></p>
<p><strong>参数</strong>：innodb_buffer_pool_size</p>
<p><strong>介绍</strong>：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。</p>
<p><strong>参数</strong>：innodb_old_blocks_pct</p>
<p><strong>介绍</strong>：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。</p>
<p><em>画外音：如果把这个参数设为100，就退化为普通LRU了。</em></p>
<p><strong>参数</strong>：innodb_old_blocks_time</p>
<p><strong>介绍</strong>：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。</p>
<p><strong>总结</strong></p>
<p>（1）<strong>缓冲池(buffer pool)</strong>是一种<strong>常见的降低磁盘访问的机制；</strong></p>
<p>（2）缓冲池通常<strong>以页(page)为单位缓存数据；</strong></p>
<p>（3）缓冲池的<strong>常见管理算法是LRU</strong>，memcache，OS，InnoDB都使用了这种算法；</p>
<p>（4）InnoDB对普通LRU进行了优化：</p>
<ul>
<li>将缓冲池分为<strong>老生代和新生代</strong>，入缓冲池的页，优先进入老生代，页被访问，才进入新生代，以解决预读失效的问题</li>
<li>页被访问，且在老生代<strong>停留时间超过配置阈值</strong>的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题</li>
</ul>
<h3 id="9-MySQL为什么有时候会选错索引？"><a href="#9-MySQL为什么有时候会选错索引？" class="headerlink" title="9.MySQL为什么有时候会选错索引？"></a>9.MySQL为什么有时候会选错索引？</h3><p><strong>优化器的逻辑</strong> </p>
<p>优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 </p>
<p>MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。<br>这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好 </p>
<p><strong>使用  show index 方法，看到一个索引的基数</strong> </p>
<p><img src="/mysql-one/cardinality.png" alt></p>
<p>从图中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。<br>其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行 </p>
<p><img src="/mysql-one/explain.png" alt></p>
<p>rows 这个字段表示的是预计扫描行数 </p>
<p>rows 统计信息不对，那就修正。<strong>analyze table t</strong> 命令，可以用来重新统计索引信息 </p>
<p><strong>索引选择异常和处理</strong></p>
<p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？ </p>
<p><strong>第一种方法是，采用 force index 强行选择一个索引</strong> </p>
<p>不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容 </p>
<p><strong>第二种方法是，可以考虑修改语句，引导 MySQL 使用我们期望的索引</strong> </p>
<p>比如，在这个例子里，显然把“order by b limit 1”改成 “order by b,a limit 1” ，语义的逻辑是相同的 </p>
<p>![](mysql-one/force index.png)</p>
<p>之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。 </p>
<p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引</strong> </p>
<h3 id="10-怎么给字符串字段加索引？"><a href="#10-怎么给字符串字段加索引？" class="headerlink" title="10.怎么给字符串字段加索引？"></a>10.怎么给字符串字段加索引？</h3><p>比如，这两个在 email 字段上创建索引的语句： </p>
<pre><code class="sql">mysql&gt; alter table SUser add index index1(email);
或
mysql&gt; alter table SUser add index index2(email(6)); </code></pre>
<p>第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的index2 索引里面，对于每个记录都是只取前 6 个字节 <strong>(前缀索引)</strong></p>
<p>由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（如：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势 </p>
<p><strong>使用前缀索引后，可能会导致查询语句读数据的次数变多</strong> </p>
<p><strong>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本</strong> </p>
<p>实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀 </p>
<pre><code class="sql">mysql&gt; select count(distinct email) as L from SUser; </code></pre>
<p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句： </p>
<pre><code class="sql">mysql&gt; select
    count(distinct left(email,4)）as L4,
    count(distinct left(email,5)）as L5,
    count(distinct left(email,6)）as L6, 
    count(distinct left(email,7)）as L7
from SUser; </code></pre>
<p>当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6 </p>
<p><strong>前缀索引对覆盖索引的影响</strong> </p>
<p>使用前缀索引就<strong>用不上</strong>覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素 </p>
<p>如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值 </p>
<p><strong>小结</strong></p>
<p>字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：</p>
<ol>
<li>直接创建完整索引，这样可能比较占用空间；</li>
<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li>
<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li>
<li>创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不<br> 支持范围扫描 </li>
</ol>
<h3 id="11-为什么我的MySQL会“抖”一下？"><a href="#11-为什么我的MySQL会“抖”一下？" class="headerlink" title="11.为什么我的MySQL会“抖”一下？"></a>11.为什么我的MySQL会“抖”一下？</h3><p><strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</strong> </p>
<p>不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush） </p>
<p><strong>那么，什么情况会引发数据库的 flush 过程呢？</strong> </p>
<p><strong>第一种场景：</strong>对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把checkpoint 往前推进，redo log 留出空间可以继续写 </p>
<p><strong>第二种场景：</strong>系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘 </p>
<p><strong>第三种场景：</strong>当MySQL 认为系统“空闲” 时，会刷“脏页”</p>
<p><strong>第四种场景：</strong>MySQL 正常关闭的情况下会把内存中的脏页都flush到磁盘上</p>
<p><strong>分析一下上面四种场景对性能的影响</strong> </p>
<p>第三种属于系统空闲时间操作的没有什么压力，第四种是正常关闭也不会对性能有影响，所以我们主要分析前两种场景</p>
<p>第一种，“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0 </p>
<p>第二种，第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存</p>
<p>缓冲池中的内存页有三种状态： </p>
<ol>
<li>第一种是，还没有使用的；</li>
<li>第二种是，使用了并且是干净页； </li>
<li>第三种是，使用了并且是脏页。 </li>
</ol>
<p>InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。 而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。 </p>
<p><strong>刷脏页虽然是常态</strong>，但是出现以下这两种情况，都是会明显影响性能的 :</p>
<ol>
<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； </li>
<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； </li>
</ol>
<p>所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。 </p>
<p><strong>InnoDB 刷脏页的控制策略</strong> </p>
<p>设置innodb_io_capacity 参数，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS 。磁盘的 IOPS 可以通过 fio 这个工具来测试 </p>
<p>现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。  </p>
<p>要尽量避免这种情况，你就要合理地设置 <strong>innodb_io_capacity</strong> 的值 </p>
<p>一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷 </p>
<p>在 InnoDB 中，<strong>innodb_flush_neighbors</strong> 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。 </p>
<p>而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。<br>在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。</p>
<h3 id="12-count-这么慢，我该怎么办？"><a href="#12-count-这么慢，我该怎么办？" class="headerlink" title="12.count(*)这么慢，我该怎么办？"></a>12.count(*)这么慢，我该怎么办？</h3><p><code>count(*)</code> 的实现方式<br>你首先要明确的是，在不同的 MySQL 引擎中，<code>count(*)</code> 有不同的实现方式。</p>
<ol>
<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 <code>count(*)</code> 的时候会直接返回这个数，效率很高； </li>
<li>而 InnoDB 引擎就麻烦了，它执行 <code>count(*)</code> 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数 </li>
</ol>
<p>文章里讨论的是没有过滤条件的 <code>count(*)</code>，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的 </p>
<p><strong>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一</strong> </p>
<p>按照效率排序的话，<code>count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)</code>，所以我建议你，尽量使用 <code>count(*)</code> </p>
<h3 id="13-答疑文章（一）：日志和索引相关问题"><a href="#13-答疑文章（一）：日志和索引相关问题" class="headerlink" title="13.答疑文章（一）：日志和索引相关问题"></a>13.答疑文章（一）：日志和索引相关问题</h3><p>主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？ </p>
<p><strong>我们先来看一下崩溃恢复时的判断规则</strong> </p>
<ol>
<li>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；</li>
<li>如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完<br> 整：<br> a. 如果是，则提交事务；<br> b. 否则，回滚事务；</li>
</ol>
<p>这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交 </p>
<p><strong>追问 1： MySQL 怎么知道 binlog 是完整的?</strong> </p>
<p>回答：一个事务的 binlog 是有完整格式的：</p>
<ol>
<li>statement 格式的 binlog，最后会有 COMMIT；</li>
<li>row 格式的 binlog，最后会有一个 XID event；</li>
</ol>
<p>另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的 </p>
<p><strong>追问 2：redo log 和 binlog 是怎么关联起来的?</strong> </p>
<p>回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log： </p>
<ol>
<li>如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；</li>
<li>如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务；</li>
</ol>
<p><strong>追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?</strong> </p>
<p>回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。<br>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。 </p>
<p><strong>追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</strong> </p>
<p>回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。<br>两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。 </p>
<p><strong>追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？</strong> </p>
<p>回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么“的问题。实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况 </p>
<ol>
<li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。</li>
<li>在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态 </li>
</ol>
<p><strong>追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？</strong> </p>
<p>回答：这两个问题可以一起回答。<br>在一个事务的更新过程中，日志是要写多次的。比如下面这个事务： </p>
<pre><code class="sql">begin;
insert into t1 ...
insert into t2 ...
commit; </code></pre>
<p>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。</p>
<p>所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。</p>
<p>但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。</p>
<p>单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成 </p>
<h3 id="14-“order-by”是怎么工作的？"><a href="#14-“order-by”是怎么工作的？" class="headerlink" title="14.“order by”是怎么工作的？"></a>14.“order by”是怎么工作的？</h3><pre><code class="sql">select city,name,age from t where city=&#39;杭州&#39; order by name limit 1000 ; </code></pre>
<p><strong>全字段排序</strong> </p>
<p>通常情况下，这个语句执行流程如下所示 ：</p>
<ol>
<li>初始化 sort_buffer，确定放入 name、city、age 这三个字段；</li>
<li>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；</li>
<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li>
<li>从索引 city 取下一个记录的主键 id；</li>
<li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li>
<li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li>
<li>按照排序结果取前 1000 行返回给客户端 </li>
</ol>
<p><img src="/mysql-one/order.png" alt></p>
<p>图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size </p>
<p>sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序 </p>
<p><strong>rowid 排序</strong> </p>
<p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。 </p>
<pre><code class="sql">SET max_length_for_sort_data = 16; </code></pre>
<p><strong>max_length_for_sort_data</strong>，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法 </p>
<p>新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。</p>
<p>但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子： </p>
<ol>
<li><p>初始化 sort_buffer，确定放入两个字段，即 name 和 id；</p>
</li>
<li><p>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；</p>
</li>
<li><p>到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；</p>
</li>
<li><p>从索引 city 取下一个记录的主键 id；</p>
</li>
<li><p>重复步骤 3、4 直到不满足 city=’杭州’条件为止，也就是图中的 ID_Y；</p>
</li>
<li><p>对 sort_buffer 中的数据按照字段 name 进行排序； </p>
</li>
<li><p>遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字<br> 段返回给客户端 </p>
</li>
</ol>
<p>![](mysql-one/order rowid.png)</p>
<p><strong>使用rowId进行排序需要进行回表，在根据主键索引查询一遍数据</strong></p>
<p>max_length_for_sort_data 代表的是字节，如果查询的所有字段字节数大于设置的字节，则使用rowid排序，否则使用全字段排序</p>
<p><strong>全字段排序 VS rowid 排序</strong> </p>
<p>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次</p>
<p>可以排序更多行，但是需要再回到原表去取数据</p>
<p>如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就</p>
<p>会直接从内存里面返回查询结果了，不用再回到原表去取数据 </p>
<p><strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong> </p>
<p>对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择 </p>
<p><strong>覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。</strong> </p>
<ol>
<li><p>无条件查询如果只有order by create_time,即便create_time上有索引,也不会使用到。</p>
<p>因为优化器认为走二级索引再去回表成本比全表扫描排序更高</p>
<p>所以选择走全表扫描,然后根据老师讲的两种方式选择一种来排序</p>
</li>
<li><p>无条件查询但是是order by create_time limit m.如果m值较小,是可以走索引的.</p>
<p>因为优化器认为根据索引有序性去回表查数据,然后得到m条数据,就可以终止循环,那么成本比全表扫描小,则选择走二级索引</p>
</li>
</ol>
<h3 id="15-如何正确地显示随机消息？"><a href="#15-如何正确地显示随机消息？" class="headerlink" title="15.如何正确地显示随机消息？"></a>15.如何正确地显示随机消息？</h3><p><strong>内存临时表</strong> </p>
<p>首先，你会想到用 order by rand() 来实现这个逻辑。 </p>
<pre><code class="sql">mysql&gt; select word from words order by rand() limit 3; </code></pre>
<p>explain 命令来看看这个语句的执行情况 </p>
<p><img src="/mysql-one/rand.png" alt></p>
<p>Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。 </p>
<p>因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序 </p>
<p><strong>对于 InnoDB 表来说，对于内存表，</strong>回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不</p>
<p>会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所</p>
<p>以，MySQL 这时就会选择 <strong>rowid 排序</strong> </p>
<p>这条语句的执行流程是这样的： </p>
<ol>
<li><p>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。</p>
</li>
<li><p>从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。 </p>
</li>
<li><p>现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R排序。</p>
</li>
<li><p>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。</p>
</li>
<li><p>从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。</p>
</li>
<li><p>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</p>
</li>
<li><p>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003 </p>
</li>
</ol>
<p>应用的是归并排序算法 </p>
<p><strong>MySQL 的表是用什么方法来定位“一行数据”的</strong> </p>
<p>如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid </p>
<p>来作为主键，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。</p>
<ol>
<li>对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；</li>
<li>对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；</li>
<li>MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。 </li>
</ol>
<p><strong>order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。</strong> </p>
<p><strong>磁盘临时表</strong> </p>
<p><strong>tmp_table_size</strong> 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 <strong>tmp_table_size</strong>，那么内存临时表就会转成磁盘临时表。<br>磁盘临时表使用的引擎默认是 InnoDB，是由参数 <strong>internal_tmp_disk_storage_engine</strong> 控制的 </p>
<p><strong>优先队列算法</strong> </p>
<p>可以精确地只得到三个最小值，执行流程如下： </p>
<ol>
<li>对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆； </li>
<li>取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个(R,rowid) 从堆中去掉，换成 (R’,rowid’)； </li>
<li>重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。 </li>
</ol>
<p>如果需要维护的堆大小超过了我设置的 <strong>sort_buffer_size</strong> 大小，就只能使用归并排序算法。 </p>
<h3 id="16-为什么这些SQL语句逻辑相同，性能却差异巨大？"><a href="#16-为什么这些SQL语句逻辑相同，性能却差异巨大？" class="headerlink" title="16.为什么这些SQL语句逻辑相同，性能却差异巨大？"></a>16.为什么这些SQL语句逻辑相同，性能却差异巨大？</h3><pre><code class="sql">select count(*) from tradelog where month(t_modified)=7; </code></pre>
<p>因为对字段使用了month()函数，所以不会走索引</p>
<p><img src="/mysql-one/%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0%E4%B8%8D%E8%B5%B0%E7%B4%A2%E5%BC%95.png" alt></p>
<p>需要注意的是，优化器并不是要放弃使用这个索引。<br>在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified（走这个索引不应是查询，还有可能是遍历，这里选择的就是遍历索引 t_modified）</p>
<p><strong>一定要注意，优化器会选择代价更小的方案，而这个方案并不固定</strong></p>
<p><strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</strong></p>
<p>不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。 </p>
<p><strong>隐式类型转换</strong> </p>
<pre><code class="sql">select * from tradelog where tradeid=110717; </code></pre>
<p>交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换 </p>
<p>在MySQL 中，字符串和数字做比较的话，是将字符串转换成数字 </p>
<p>所以对于优化器来说，上面的语句相当于：</p>
<pre><code class="sql">select * from tradelog where CAST(tradid AS signed int) = 110717; </code></pre>
<p>也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。 </p>
<p><strong>隐式字符编码转换</strong> </p>
<p>两个表使用的字符集不一样，会导致函数操作，进而导致优化器放弃走树搜索功能</p>
<p><strong>连接过程中要求在被驱动表的索引字段上加函数操作</strong>，是直接导致对被驱动表做全表扫描的原因 </p>
<p>三个例子，其实是在说同一件事儿，即：<strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能</strong> </p>
<p><strong>索引字段不能进行函数操作，但是索引字段的参数可以玩函数</strong></p>
<h3 id="17-为什么我只查一行的语句，也执行这么慢？"><a href="#17-为什么我只查一行的语句，也执行这么慢？" class="headerlink" title="17.为什么我只查一行的语句，也执行这么慢？"></a>17.为什么我只查一行的语句，也执行这么慢？</h3><p><strong>第一类：查询长时间不返回</strong> </p>
<p>等 MDL 锁 ，导致查询阻塞</p>
<p>等 flush ，导致查询阻塞（不过一般不会有这个问题）</p>
<p>等行锁 ，导致查询阻塞</p>
<p><strong>第二类：查询慢</strong> </p>
<p><em>坏查询不一定是慢查询</em> </p>
<p><img src="/mysql-one/%E6%9F%A5%E8%AF%A2%E6%85%A2.png" alt></p>
<p>session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句 </p>
<p>ession B 更新完 100 万次，生成了 100 万个回滚日志 (undo log) </p>
<p>带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。 </p>
<h3 id="幻读是什么，幻读有什么问题？"><a href="#幻读是什么，幻读有什么问题？" class="headerlink" title="幻读是什么，幻读有什么问题？"></a>幻读是什么，幻读有什么问题？</h3><p><strong>幻读的定义</strong> </p>
<p><strong>幻读</strong>指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 </p>
<p><strong>如何解决幻读？</strong> </p>
<p><strong>间隙锁+行锁（间隙锁是在可重复读隔离级别下才会生效的）</strong> </p>
<p>现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。<br>顾名思义，<strong>间隙锁</strong>，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。 </p>
<p>*<em>间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。再加上 7 个间隙锁。这样就确保了无法再插入新的记录 *</em> </p>
<p>这里的七个间隙值是查询语句进行了全表扫描，所以锁住了整个表，不能进行增删改操作</p>
<p>间隙锁之间都不存在冲突关系</p>
<p><strong>间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间</strong> </p>
<p>使用行锁+间隙锁不会锁住表，只会锁住行锁和间隙锁之间的数据</p>
<h3 id="18-为什么我只改一行的语句，锁这么多？"><a href="#18-为什么我只改一行的语句，锁这么多？" class="headerlink" title="18.为什么我只改一行的语句，锁这么多？"></a>18.为什么我只改一行的语句，锁这么多？</h3><p>总结的加锁规则：</p>
<ol>
<li>原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区<br> 间。</li>
<li>原则 2：查找过程中访问到的对象才会加锁。</li>
<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>
<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key<br> lock 退化为间隙锁。</li>
<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 </li>
</ol>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/mysql-one/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/mysql/">mysql</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/mysql/">#mysql</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-07-08T03:10:54.000Z">2019-07-08</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/concurrent-thread/">java并发编程 | 线程详解</a></h1>
	

		</header>
		<div class="entry">
			
				<h3 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h3><p>进程：操作系统在运行一个程序的时候就会为其创建一个进程（比如一个java程序），进程是资源分配的最小单位，一个进程包含多个线程</p>
<p>线程：线程是cpu调度的最小单位，每个线程拥有各自的计数器，对战和局部变量等属性，并且能过访问共享的内存变量</p>
<h4 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h4><p>java线程的生命周期总共包括6个阶段：</p>
<ol>
<li>初始状态：线程被创建，但是还没有调用<code>start()</code>方法</li>
<li>运行状态：java中将就绪状态和运行状态统称为运行状态</li>
<li>阻塞状态：线程阻塞，线程等待进入<code>synchronized</code>修饰的代码块或方法</li>
<li>等待状态：线程进入等待状态，需要调用<code>notify()</code>或<code>notifyAll()</code>进行唤醒</li>
<li>超时等待状态：线程进入等待状态，在指定时间后自行返回</li>
<li>终止状态：线程执行完毕</li>
</ol>
<p>在某一时刻，线程只能处于其中的一个状态</p>
<p><img src="/concurrent-thread/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png" alt></p>
<p>线程初始化后，调用<code>start()</code>方法变为运行状态，调用<code>wait()</code>，<code>join()</code>等方法，线程由运行状态变为等待状态，调用<code>notify()</code>或<code>notifyAll()</code>等方法，线程由等待状态变成运行状态，超时等待状态就是在等待状态基础上加了时间限制，超过规定时间，自动更改为运行状态，当需要执行同步方法时，如果没有获得锁，这时线程状态就变为阻塞状态，直到获取到锁，变为运行状态，当执行完线程的<code>run()</code>方法后，线程变为终止状态</p>
<h5 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h5><p>创建线程有三种方式</p>
<ol>
<li>继承<code>Thread</code>类</li>
<li>实现<code>Runnable</code>接口</li>
<li>实现<code>Callable</code>接口</li>
</ol>
<p><strong>继承<code>Thread</code>类</strong></p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:13
 * @description: 继承Thread类
 */
public class ThreadTest extends Thread{

    @Override
    public void run() {
        IntStream.range(0,10).forEach(i-&gt;{
            System.out.println(this.getName()+&quot;:&quot;+i);
        });
    }

    public static void main(String[] args) {
        Thread thread = new ThreadTest();
        thread.start();
    }
}</code></pre>
<h5 id="实现Runnable接口"><a href="#实现Runnable接口" class="headerlink" title="实现Runnable接口"></a>实现<code>Runnable</code>接口</h5><pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:18
 * @description: 实现Runnable接口
 */
public class RunnableTest implements Runnable {

    @Override
    public void run() {
        IntStream.range(0,10).forEach(i-&gt;{
            System.out.println(Thread.currentThread().getName()+&quot;:&quot;+i);
        });
    }

    public static void main(String[] args) {
        Runnable runnable = new RunnableTest();
        new Thread(runnable,&quot;RunnableTest&quot;).start();
    }
}</code></pre>
<h5 id="实现Callable接口"><a href="#实现Callable接口" class="headerlink" title="实现Callable接口"></a>实现<code>Callable</code>接口</h5><pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:23
 * @description: 实现Callable接口
 */
public class CallableTest implements Callable&lt;Integer&gt; {

    @Override
    public Integer call() throws Exception {
        IntStream.range(0,10).forEach(i-&gt;{
            System.out.println(Thread.currentThread().getName()+&quot;:&quot;+i);
        });
        return -1;
    }

    public static void main(String[] args) throws Exception {
        Callable callable = new CallableTest();
        FutureTask futureTask = new FutureTask(callable);
        new Thread(futureTask,&quot;future&quot;).start();
        System.out.println(&quot;result:&quot;+futureTask.get());
    }
}</code></pre>
<h4 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h4><h5 id="不安全的线程暂停，恢复，停止操作"><a href="#不安全的线程暂停，恢复，停止操作" class="headerlink" title="不安全的线程暂停，恢复，停止操作"></a>不安全的线程暂停，恢复，停止操作</h5><p><code>Thread</code>提供的过期方法可以实现对线程进行暂停<code>suspend()</code>，恢复<code>resume()</code>，停止<code>stop()</code>的操作</p>
<p>例：创建一个线程，<code>run()</code>中循环输出当前时间，在<code>main()</code>方法中对新建线程进行暂停，恢复，停止的操作</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 15:51
 * @description: 线程的暂停，恢复，停止
 */
public class OperationThread implements Runnable{

    @Override
    public void run() {
        while (true){
            try {
                TimeUnit.SECONDS.sleep(1L);
                System.out.println(Thread.currentThread().getName()+&quot;运行中：&quot;+LocalTime.now());
            }catch (InterruptedException e){
                System.err.println(e.getMessage());
            }
        }
    }

    public static void main(String[] args) throws Exception{
        Runnable runnable = new OperationThread();
        Thread thread = new Thread(runnable,&quot;operationThread&quot;);
        /**
         * 启动，输出当前时间
         */
        thread.start();
        TimeUnit.SECONDS.sleep(3L);

        /**
         * 线程暂停，不在输出当前时间
         */
        System.out.println(&quot;此处暂停：&quot;+LocalTime.now());
        thread.suspend();
        TimeUnit.SECONDS.sleep(3L);

        /**
         * 线程恢复，继续输出当前时间
         */
        System.out.println(&quot;此处恢复：&quot;+LocalTime.now());
        thread.resume();
        TimeUnit.SECONDS.sleep(3L);

        /**
         * 线程停止，不在输出当前时间
         */
        thread.stop();
        System.out.println(&quot;此处停止：&quot;+LocalTime.now());
        TimeUnit.SECONDS.sleep(3L);
    }
}</code></pre>
<p>输出</p>
<p><img src="/concurrent-thread/%E7%BA%BF%E7%A8%8B%E6%9A%82%E5%81%9C%EF%BC%8C%E6%81%A2%E5%A4%8D%EF%BC%8C%E5%81%9C%E6%AD%A2%E6%93%8D%E4%BD%9C.png" alt></p>
<p>因为是过期方法，所以不推荐使用，使用<code>suspend()</code>方法后，线程不会释放已经占有的资源，就进入睡眠状态，容易引发死锁问题，而使用<code>stop()</code>方法终结一个线程是不会保证线程的资源正常释放的，可能会导致程序异常</p>
<h5 id="安全的线程暂停，恢复（等待-通知机制）"><a href="#安全的线程暂停，恢复（等待-通知机制）" class="headerlink" title="安全的线程暂停，恢复（等待/通知机制）"></a>安全的线程暂停，恢复（等待/通知机制）</h5><p>线程安全的暂停，恢复操作可以使用等待/通知机制代替</p>
<p>相关方法：</p>
<table>
<thead>
<tr>
<th align="left">方法名</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">notify()</td>
<td align="left">通知一个在对象上等待的线程，使其重wait()方法中返回，前提是该线程获得了对象的锁</td>
</tr>
<tr>
<td align="left">notifyAll()</td>
<td align="left">通知所有等待在该对象上的线程</td>
</tr>
<tr>
<td align="left">wait()</td>
<td align="left">调用该方法线程进入等待状态，只有等待另外线程的通知或被中断才会返回，调用该方法会释放对象的锁</td>
</tr>
<tr>
<td align="left">wait(long)</td>
<td align="left">超时等待一段时间（毫秒），如果超过时间就返回</td>
</tr>
<tr>
<td align="left">wait(long,int)</td>
<td align="left">对于超时时间细粒度的控制，可以达到纳秒</td>
</tr>
</tbody></table>
<p>例：创建一个名为<code>waitThread</code>的线程，在<code>run()</code>方法,使用中使用<code>synchronized</code>进行加锁，以变量<code>flag</code>为条件进行<code>while</code>循环，在循环中调用<code>LOCK.wait()</code>方法，此时会释放对象锁，由<code>main()</code>方法获得锁，调用<code>LOCK.notify()</code>方法通知<code>LOCK</code>对象上等待的<code>waitThread</code>线程，将其置为阻塞状态，并将变量<code>flag</code>置为<code>true</code>，当<code>waitThread</code>线程再次获取对象锁之后继续执行余下代码</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 20:00
 * @description: wait/notify
 */
public class WaitNotifyTest {

    private static Object LOCK = new Object();
    private static Boolean FLAG = Boolean.TRUE;


    public static void main(String[] args) throws InterruptedException{
        Runnable r = new WaitThread();
        new Thread(r,&quot;waitThread&quot;).start();
        TimeUnit.SECONDS.sleep(1L);
        synchronized (LOCK){
            System.out.println(Thread.currentThread().getName()+&quot;唤醒waitThread线程：&quot;+LocalTime.now());
            /**
             * 线程状态由等待状态变为阻塞状态
             */
            LOCK.notify();
            /**
             * 只有当前线程释放对象锁，waitThread获取到LOCK对象的锁之后才会从wait()方法中返回
             */
            TimeUnit.SECONDS.sleep(2L);
            FLAG = Boolean.FALSE;
        }
    }

    public static class WaitThread implements Runnable {
        @Override
        public void run() {
            /**
             * 加锁
             */
            synchronized (LOCK){
                while (FLAG){
                    try {
                        System.out.println(Thread.currentThread().getName()+&quot;运行中：&quot;+LocalTime.now());
                        /**
                         * 线程状态变为等待状态
                         */
                        LOCK.wait();
                        /**
                         * 再次获得对象锁之后，才会执行
                         */
                        System.out.println(Thread.currentThread().getName()+&quot;被唤醒：&quot;+LocalTime.now());
                    }catch (InterruptedException e){
                        System.err.println(e.getMessage());
                    }
                }
            }
            System.out.println(Thread.currentThread().getName()+&quot;即将停止：&quot;+LocalTime.now());
        }
    }
}</code></pre>
<p>输出</p>
<p><img src="/concurrent-thread/wait%EF%BC%8Cnotify.png" alt></p>
<p>可以看到在<code>mian</code>线程调用<code>LOCK.notify()</code>方法后，沉睡了2s才释放对象锁，<code>waitThread</code>线程在获得对象锁之后执行余下代码</p>
<h5 id="安全的线程停止操作-中断标识"><a href="#安全的线程停止操作-中断标识" class="headerlink" title="安全的线程停止操作(中断标识)"></a>安全的线程停止操作(中断标识)</h5><p>线程的安全停止操作是利用线程的中断标识来实现，线程的中断属性表示一个运行中的线程是否被其他线程进行了中断操作，其他线程通过调用该线程的<code>interrupt()</code>方法对其进行中断操作，而该线程通过检查自身是否被中断来进行响应，当一个线程被中断可以使用<code>Thread.interrupted()</code>方法对当前线程的中断标识位进行复位</p>
<p>例：新建一个线程，<code>run</code>方法中使用<code>Thread.currentThread().isInterrupted()</code>是否中断作为判断条件，在主线程中使用<code>thread.interrupt()</code>方法对子线程进行中断操作，用来达到终止线程的操作，这种方式会让子线程可以去清理资源或一些别的操作，而使用<code>stop()</code>方法则会会直接终止线程</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/8 20:47
 * @description: 中断
 */
public class InterruptTest {

    public static void main(String[] args) throws InterruptedException {
        Runnable r = new StopThread();
        Thread thread = new Thread(r,&quot;stopThread&quot;);
        thread.start();
        TimeUnit.SECONDS.sleep(1L);
        System.out.println(Thread.currentThread().getName()+&quot;对stopThread线程进行中断：&quot;+LocalTime.now());
        thread.interrupt();
    }

    public static class StopThread implements Runnable {
        @Override
        public void run() {
            while (!Thread.currentThread().isInterrupted()){
                System.out.println(Thread.currentThread().getName()+&quot;运行中：&quot;+LocalTime.now());
            }
            System.out.println(Thread.currentThread().getName()+&quot;停止：&quot;+LocalTime.now());
        }
    }
}</code></pre>
<h5 id="Thread-join"><a href="#Thread-join" class="headerlink" title="Thread.join()"></a>Thread.join()</h5><p><code>Thread.join()</code>作用是等待该线程终止</p>
<p>比如在主线程中新建一个子线程，调用子线程的<code>join()</code>方法，那么在子线程未执行完时，主线程的状态是阻塞状态，只有当子线程执行结束，主线程才会继续往下执行</p>
<table>
<thead>
<tr>
<th>方法名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>join()</td>
<td>调用A线程的<code>join()</code>方法后，那么当前线程需要等待A线程终止，才可以继续执行</td>
</tr>
<tr>
<td>join(long)</td>
<td>在<code>join()</code>方法的基础上增加了时间限制（毫秒），超出时间后，无论A线程是否执行完，当前线程都进入就绪状态，重新等待cpu调用</td>
</tr>
<tr>
<td>join(long,int)</td>
<td>在<code>join(long)</code>方法基础上，时间控制上更加严谨，时间细粒度为纳秒（Long毫秒+int纳秒）</td>
</tr>
</tbody></table>
<p>例：循环创建子线程，在<code>main</code>线程中调用子线程的<code>join()</code>方法，在子线程中输出了一句日志</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/9 20:53
 * @description: thread.join();
 */
public class JoinThreadTest {

    public static void main(String[] args) throws InterruptedException{

        IntStream.range(0, 5).forEach(i -&gt; {
            try {
                Runnable runnable = new JoinThread();
                Thread thread = new Thread(runnable,&quot;joinThread&quot;);
                thread.start();
                thread.join();
                System.out.println(Thread.currentThread().getName() + &quot;运行中: &quot; + LocalTime.now());
            } catch (InterruptedException e) {
                System.err.println(e.getMessage());
            }
            System.out.println(&quot;------- 分隔符 ------- &quot;);
        });
    }

    public static class JoinThread implements Runnable {
        @Override
        public void run() {
            try {
                TimeUnit.SECONDS.sleep(1L);
                System.out.println(Thread.currentThread().getName() + &quot;运行中: &quot; + LocalTime.now());
            } catch (InterruptedException e) {
                System.err.println(e.getMessage());
            }
        }
    }
}</code></pre>
<p>输出</p>
<p><img src="/concurrent-thread/join.png" alt></p>
<p>每次循环都是主线程等待子线程终止，在子线程执行完之后主线程才会继续执行</p>
<p><strong>thread.join()源码</strong></p>
<p>调用方线程（调用join方法的线程）执行等待操作，直到被调用的线程（join方法所属的线程）结束，再被唤醒</p>
<pre><code class="java">public final void join() throws InterruptedException {
    join(0);
}</code></pre>
<p><code>join(0)</code>方法</p>
<pre><code class="java">public final synchronized void join(long millis)
throws InterruptedException {
    long base = System.currentTimeMillis();
    long now = 0;

    if (millis &lt; 0) {
        throw new IllegalArgumentException(&quot;timeout value is negative&quot;);
    }

    if (millis == 0) {
        while (isAlive()) {
            wait(0);
        }
    } else {
        while (isAlive()) {
            long delay = millis - now;
            if (delay &lt;= 0) {
                break;
            }
            wait(delay);
            now = System.currentTimeMillis() - base;
        }
    }
}</code></pre>
<p><code>join()</code>方法实现等待其实是调用了<code>wait()</code>方法，<code>isAlive()</code>方法的作用是监测子线程是否终止，如果终止或者超过了指定时间，代码就继续往下执行，否则就继续等待，知道条件满足</p>
<h5 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h5><p><code>ThreadLocal</code>，叫线程变量，是一个以<code>ThreadLocal</code>对象为键，任意对象为值的存储结构，<code>ThreadLocal</code>类型的变量在每个线程中是独立的，在多线程环境下不会相互影响</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/4/10 17:56
 * @description: ThreadLocal
 */
public class ThreadLocalTest {

    private static String STATE;
    private static ThreadLocal&lt;String&gt; STRING_THREAD_LOCAL = new InheritableThreadLocal&lt;&gt;();


    public static void main(String[] args) throws InterruptedException{

        STATE = &quot;未重置&quot;;
        STRING_THREAD_LOCAL.set(&quot;未重置&quot;);

        Thread thread = new Thread(() -&gt;
        {
            STATE = &quot;已重置&quot;;
            STRING_THREAD_LOCAL.set(&quot;已重置&quot;);
            System.out.println(Thread.currentThread().getName() + &quot; : 变量已重置&quot;);
        });
        thread.start();
        thread.join();

        System.out.println(Thread.currentThread().getName() + &quot;STATE : &quot; + STATE);
        System.out.println(Thread.currentThread().getName() + &quot;STRING_THREAD_LOCAL : &quot; + STRING_THREAD_LOCAL.get());
    }
}</code></pre>
<p>输出</p>
<p><img src="/concurrent-thread/threadLocal.png" alt></p>
<p><code>ThreadLocal&lt;String&gt;</code>类型的变量<code>STRING_THREAD_LOCAL</code>未被子线程修改</p>
<p>使用<code>ThreadLocal</code>变量，必须要注意回收自定义的<code>ThreadLocal</code>变量，尤其在线程池场景下，线程经常会被复用，如果不清理自定义的<code>ThreadLocal</code>变量，可能会影响后续业务逻辑和造成内存泄露等问题，尽量使用<code>try-finally</code>块进行回收，回收方式是调用<code>threadLocal.remove()</code>;方法</p>
<p><strong>参考：java并发编程的艺术</strong></p>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/concurrent-thread/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/%E7%BA%BF%E7%A8%8B/">#线程</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-07-06T07:03:18.000Z">2019-07-06</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/concurrent-threadpool/">java并发编程 | 线程池详解</a></h1>
	

		</header>
		<div class="entry">
			
				<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>线程池用来处理异步任务或者并发执行的任务</p>
<p>优点：</p>
<ol>
<li>重复利用已创建的线程，减少创建和销毁线程造成的资源消耗</li>
<li>直接使用线程池中的线程，提高响应速度</li>
<li>提高线程的可管理性，由线程池同一管理</li>
</ol>
<h4 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h4><p><code>java</code>中线程池使用<code>ThreadPoolExecutor</code>实现</p>
<h5 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h5><p><code>ThreadPoolExecutor</code>提供了四个构造函数，其他三个构造函数最终调用的都是下面这个构造函数</p>
<pre><code class="java">public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue&lt;Runnable&gt; workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize &lt; 0 ||
            maximumPoolSize &lt;= 0 ||
            maximumPoolSize &lt; corePoolSize ||
            keepAliveTime &lt; 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.acc = System.getSecurityManager() == null ?
                null :
                AccessController.getContext();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }</code></pre>
<p><strong>入参：</strong></p>
<ol>
<li><p><code>corePoolSize</code>：线程池的核心线程数量</p>
<p>线程池维护的核心线程数量，当线程池初始化后，线程池中的工作线程数量为零，当有任务来到的时候才会创建线程去执行任务，当线程池中的工作线程数量等于核心线程数量时，新到的任务就会放到缓存队列中</p>
</li>
<li><p><code>maximumPoolSize</code>：线程池允许创建的最大线程数量</p>
<p>当阻塞队列满了的时候，并且线程池中创建的线程数量小于<code>maximumPoolSize</code>，此时会创建新的线程执行任务</p>
</li>
<li><p><code>keepAliveTime</code>：线程活动保持时间</p>
<p>只有当线程池数量大于核心线程数量时，<code>keepAliveTime</code>才会有效，如果当前线程数量大于核心线程数量时，并且线程的空闲时间达到<code>keepAliveTime</code>，当前线程终止，直到线程池数量等于核心线程数</p>
</li>
<li><p><code>unit</code>：线程活动保持时间的单位</p>
<p><code>keepAliveTime</code>的单位，包括：<code>TimeUnit.DAYS</code>天，<code>TimeUnit.HOURS</code>小时，<code>TimeUnit.MINUTES</code>分钟，<code>TimeUnit.SECONDS</code>秒，<code>TimeUnit.MILLISECONDS</code>毫秒，<code>TimeUnit.MICROSECONDS</code>微秒，<code>TimeUnit.NANOSECONDS</code>纳秒</p>
</li>
<li><p><code>workQueue</code>：任务队列，用来保存等待执行任务的阻塞队列</p>
<p><code>ArrayBlockingQueue</code>：是一个基于数组结构的有界队列</p>
<p><code>LinkedBlockingQueue</code>：是一个基于链表结构的阻塞队列</p>
<p><code>SynchronousQueue</code>：不存储元素的阻塞队列，每一个插入操作必须等到下一个线程调用移除操作，否则插入操作一直阻塞</p>
<p><code>PriorityBlockingQueue</code>：一个具有优先级的无线阻塞队列</p>
</li>
<li><p><code>threadFactory</code>：用来创建线程的工厂</p>
</li>
<li><p><code>handler</code>：饱和策略，当线程池和队列都满了的时候，必须要采取一种策略处理新的任务，默认策略是<code>AbortPolicy</code>，根据自己需求选择合适的饱和策略</p>
<p><code>AbortPolicy</code>：直接抛出异常</p>
<p><code>CallerRunsPolicy</code>：用调用者所在的线程来运行当前任务</p>
<p><code>DiscardOldestPolicy</code>：丢弃队列里面最近的一个任务，并执行当前任务</p>
<p><code>DiscardPolicy</code>：不处理，丢弃掉</p>
<p>当然我们也可以通过实现<code>RejectedExecutionHandler</code>去自定义实现处理策略</p>
</li>
</ol>
<p>入参不同，线程池的运行机制也不同，了解每个入参的含义由于我们更透传的理解线程池的实现原理</p>
<h5 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h5><p>线程池处理提交任务流程如下</p>
<p><img src="/concurrent-threadpool/%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt></p>
<p><strong>处理流程</strong>：</p>
<ol>
<li>如果核心线程数量未满，创建线程执行任务，否则添加到阻塞队列中</li>
<li>如果阻塞队列中未满，将任务存到队列里</li>
<li>如果阻塞队列满了，看线程池数量是否达到了线程池最大数量，如果没达到，创建线程执行任务</li>
<li>如果已经达到线程池最大数量，根据饱和策略进行处理</li>
</ol>
<p><code>ThreadPoolExecutor</code>使用<code>execute(Runnable command)</code>和<code>submit(Runnable task)</code>向线程池中提交任务，在<code>submit(Runnable task)</code>方法中调用了<code>execute(Runnable command)</code>，所以我们只要了解<code>execute(Runnable command)</code></p>
<pre><code class="java">public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    // 获取线程池状态，并且可以通过ctl获取到当前线程池数量及线程池状态
    int c = ctl.get();
    // 如果工作线程数小于核心线程数量，则创建一个新线程执行任务
    if (workerCountOf(c) &lt; corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 如果不符合上面条件，当前线程处于运行状态并且写入阻塞队列成功
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        // 双重检查，再次获取线程状态，如果当前线程状态变为非运行状态，则从队列中移除任务，执行拒绝策略
        if (! isRunning(recheck) &amp;&amp; remove(command))
            reject(command);
        // 检查工作线程数量是否为0
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    //创建线程执行任务，如果添加失败则执行拒绝策略
    else if (!addWorker(command, false))
        reject(command);
}</code></pre>
<p><code>execute(Runnable command)</code>方法中我们比较关心的就是如何创建新的线程执行任务，就<code>addWorker(command, true)</code>方法</p>
<p><code>workQueue.offer(command)</code>方法是用来向阻塞队列中添加任务的</p>
<p><code>reject(command)</code>方法会根据创建线程池时传入的饱和策略对任务进行处理，例如默认的<code>AbortPolicy</code>，查看源码后知道就是直接抛了个<code>RejectedExecutionException</code>异常，其他的饱和策略的源码也是特别简单</p>
<p>关于线程池状态与工作线程的数量是如何表示的</p>
<p>在<code>ThreadPoolExecutor</code>中使用一个<code>AtomicInteger</code>类型变量表示</p>
<pre><code class="java">/**
 * ctl表示两个信息，一个是线程池的状态（高3位表示），一个是当前线程池的数量（低29位表示），这个跟我们前面      * 说过的读写锁的state变量是一样的，以一个变量记录两个信息，都是以利用int的32个字节，高十六位表述读，低十     * 六位表示写锁
 */
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
//低29位保存线程池数量
private static final int COUNT_BITS = Integer.SIZE - 3;
//线程池最大容量
private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;

// 运行状态存储在高3位
// 运行状态
private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;
private static final int STOP       =  1 &lt;&lt; COUNT_BITS;
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</code></pre>
<p><code>addWorker(command, boolean)</code>创建工作线程，执行任务</p>
<pre><code class="java">private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        // 线程池状态
        int rs = runStateOf(c);
        // 判断线程池状态，以及阻塞队列是否为空
        if (rs &gt;= SHUTDOWN &amp;&amp;
            ! (rs == SHUTDOWN &amp;&amp;
               firstTask == null &amp;&amp;
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            // 获取线程工作线程数量
            int wc = workerCountOf(c);
            // 判断是否大于最大容量，以及根据传入的core判断是否大于核心线程数量还是最大线程数量
            if (wc &gt;= CAPACITY ||
                wc &gt;= (core ? corePoolSize : maximumPoolSize))
                return false;
            // 增加工作线程数量
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            //如果线程池状态改变，则重试
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 创建Worker,内部创建了一个新的线程
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());
                // 线程池状态判断
                if (rs &lt; SHUTDOWN ||
                    (rs == SHUTDOWN &amp;&amp; firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    // 将创建的线程添加到线程池
                    workers.add(w);
                    int s = workers.size();
                    if (s &gt; largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                //执行任务，首先会执行Worker对象的firstTask
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        //如果任务执行失败
        if (! workerStarted)
            //移除worker
            addWorkerFailed(w);
    }
    return workerStarted;
}</code></pre>
<h5 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h5><p><code>ThreadPoolExecutor</code>中关闭线程池使用<code>shutdown()</code>和<code>shutdownNow()</code>方法，原理都是通过遍历线程池中的线程，对线程进行中断</p>
<pre><code class="java">for (Worker w : workers) {
    Thread t = w.thread;
    if (!t.isInterrupted() &amp;&amp; w.tryLock()) {
        try {
            t.interrupt();
        } catch (SecurityException ignore) {
        } finally {
            w.unlock();
        }
    }
    if (onlyOne)
        break;
    }</code></pre>
<h5 id="Executor框架"><a href="#Executor框架" class="headerlink" title="Executor框架"></a>Executor框架</h5><p><code>Executor</code>框架将任务的提交与任务的执行进行分离</p>
<p><code>Executors</code>提供了一系列工厂方法用于创先线程池，返回的线程池都实现了 <code>ExecutorService</code> 接口</p>
<p>工厂方法：</p>
<ol>
<li><code>newFixedThreadPool</code>：用于创建固定数目线程的线程池</li>
<li><code>newCachedThreadPool</code>：用于创建一个可缓存的线程池，调用execute将重用以前构造的线程，如果现有线程没有可用的，则创建一个新线 程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程</li>
<li><code>newSingleThreadExecutor</code>：用于创建只有一个线程的线程池</li>
<li><code>newScheduledThreadPool</code>：用于创建一个支持定时及周期性的任务执行的线程池</li>
</ol>
<p>在阿里巴巴手册中强制要求禁止使用<code>Executors</code>提供的工厂方法创建线程池</p>
<p><img src="/concurrent-threadpool/%E9%98%BF%E9%87%8C%E8%A7%84%E8%8C%83.png" alt></p>
<p>这个确实是一个很严重的问题，我们部门曾经就出现过使用<code>FixedThreadPool</code>线程池，导致OOM，这是因为线程执行任务的时候被阻塞或耗时很长时间，导致阻塞队列一直在添加任务，直到内存被打满，报OOM</p>
<p>所以我们在使用线程池的时候用该使用<code>ThreadPoolExecutor</code>的构造函数去创建线程池，根据自己的任务类型来确定核心线程数和最大线程数，选择适合阻塞队列和阻塞队列的长度</p>
<h5 id="合理配置线程池"><a href="#合理配置线程池" class="headerlink" title="合理配置线程池"></a>合理配置线程池</h5><p>合理的配置线程池需要分析一下任务的性质（使用<code>ThreadPoolExecutor</code>创建线程池）：</p>
<ol>
<li><p>CPU密集型任务应配置竟可能小的线程，比如 cpu数量+1</p>
</li>
<li><p>IO密集型任务并不是一直在执行任务，应该配置尽可能多的线程，比如 cpu数量x2</p>
<p>可通过<code>Runtime.getRuntime().availableProcessors()</code>获取cpu数量</p>
</li>
<li><p>执行的任务有调用外部接口比较费时的时候，这时cup空闲的时间就越长，可以将线程池数量设置大一些，这样cup空闲的时间就可以去执行别的任务</p>
</li>
<li><p>建议使用有界队列，可根据需要将长度设置大一些，防止OOM</p>
</li>
</ol>
<p><strong>参考：java并发编程的艺术</strong></p>
<p><strong>推荐阅读</strong>：</p>
<p>​    <a href="https://chenmingyu.top/concurrent-thread/">java并发编程 | 线程详解</a></p>
<p>​    <a href="https://chenmingyu.top/concurrent-lock/">java并发编程 | 锁详解：AQS，Lock，ReentrantLock，ReentrantReadWriteLock</a></p>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/concurrent-threadpool/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/">#线程池</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-07-05T10:07:08.000Z">2019-07-05</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/data-structure-array/">【数据结构】| 数组详解</a></h1>
	

		</header>
		<div class="entry">
			
				<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p><strong>数组是用于储存多个相同类型数据的集合，使用一段连续的内存空间存储数据</strong></p>
<p>数组作为最基本的数据结构，想必大家一定已经足够了解，数组的增删操作时间复杂度是O(n)，而查询的时间复杂度是O(1)，这里的查询指的是按下标进行查找，如果是比对数据进行查询时间复杂度还是O(n)</p>
<p><strong>前提:</strong></p>
<p>假设数组的长度是n</p>
<p><strong>新增操作</strong>：</p>
<p>我们新增一条数据到数组中时，当新增的数据在末尾的时候时间复杂度是O(1)，而当新增的数据插入到数组的第x个位置时，由于数组使用的是连续的内存，所以x之后的数据都需要往后移动一位，把第x位置腾出来，才可以将新增的数据插入到第x个位置，如果按最坏的情况考虑，是将数据插入到数据的首位，这时数组里所有的数据都需要往后移一位，这时的时间复杂度就是O(n)，所以平均的时间复杂度就是O(n)</p>
<p><strong>删除操作:</strong></p>
<p>当我们从数组中删除一条数据的时候，假设删除的数据位于数组的第x位置，也是由于数组使用的是连续的内存，当我们把x位置的数据删除之后，为了保证数组的内存是连续的，x位置之后的数据都需要往前移动一位，假设当删除的是数组首位的数据，这时首位之后的所有数据都需要往前移动一位，时间复杂度是O(n)，当删除的数据是数组尾部的数据时，不会发生数据移动，时间复杂度是O(1)</p>
<p><strong>查询操作:</strong></p>
<p>关于查询，要说的点还是，由于数组的内存是连续的，这就提供了我们随机访问的能力，随机访问的意思就是指我们可以按照数组的下标进行查询，这时的时间复杂度是O(1)，而遍历所有数组匹配查询的时候时间复杂度是O(n)</p>
<p>我们看一下数组在内存中的存储结构</p>
<pre><code class="java">//实例化一个数组，
int[] m = new int[]{0,5,10,15,20};</code></pre>
<p><img src="/data-structure-array/array.png" alt></p>
<p><strong>随机访问:</strong>由于数组内的地址是连续的，想要获取m[3]位置数据的时候我们只要根据寻址公式计算出m[3]的内存地址就可以直接获取到数据，这时假设数组的首地址是k，一个int类型占4个字节，m[3]的内存地址就是k+3*4</p>
<p><strong>匹配查询:</strong>这时候由于需要遍历数组，如果在第一个m[0]的位置就匹配上，则时间复杂度是O(1)，在数组尾位匹配上就是O(n)，所以平均的时间复杂度就是O(n)</p>
<p>由于数组的容量是实例化的时候就固定的，所以没有办法进行动态扩容，而<code>java</code>中的容器类则弥补了这一缺陷，比如<code>ArrayList</code>，<code>ArrayList</code>将底层操作数组的细节封装，通过提供api供开发人员使用，<code>ArrayList</code>当我们调用<code>add</code>方法的时候不需要关心底层数组的容量够不够使用也不用关心扩容的逻辑是什么，当需要的扩容的时候<code>ArrayList</code>会自己进行扩容：</p>
<pre><code class="java">int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);</code></pre>
<p><code>oldCapacity</code>是数组的旧的容量大小，而<em>newCapacity</em>新的数组容量大小是原来的1.5倍（<code>oldCapacity &gt;&gt; 1</code>右移一位相当于<code>oldCapacity/2</code>）</p>
<p>扩容的原理就是计算出新的数组大小，然后申请内存，将原来的数组复制到新申请的数组中，这一过程是比较低效的，所以一般在实例化集合的时候都会指定集合的大小比如<code>new ArrayList(16)</code>;</p>
<p><strong>集合与数组对比：</strong>因为集合使用起来更方便，但数组也不是绝对不用，Java中的集合不支持基本类型，而这时候使用如果使用集合的话必然会进行装箱，拆箱的操作，造成不必要的性能消耗，所以当数据的容量是固定的，且数据类型是基本类型的时候，就可以考虑使用数组</p>
<p><strong>总结:</strong></p>
<p>由于数组存储的是相同类型的数据，并且内存的地址是连续的，就导致可以使用寻址公式计算出数组中某个元素的内存地址，所以数组的随机访问是高效的，但是要新增和删除数据的时候，为了保持数组的内存连续性，必然会导致数据的移动，所以数组的新增和删除是低效的</p>
<p><em>注意:使用数组需要警惕别造成数组越界</em></p>
<h3 id="算法题"><a href="#算法题" class="headerlink" title="算法题"></a>算法题</h3><p>算法题来自<a href="[https://leetcode-cn.com](https://leetcode-cn.com/)">leetcode</a></p>
<h4 id="两数之和"><a href="#两数之和" class="headerlink" title="两数之和"></a>两数之和</h4><p>链接：<a href="https://leetcode-cn.com/problems/two-sum/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/two-sum/</a></p>
<p><strong>难度:</strong>简单</p>
<p>给定一个整数数组 <code>nums</code> 和一个目标值 <em>target</em>，请你在该数组中找出和为目标值的那 <strong>两个</strong> 整数，并返回他们的数组下标。</p>
<p>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。</p>
<p><strong>示例:</strong></p>
<pre><code class="java">给定 nums = [2, 7, 11, 15], target = 9

因为 nums[0] + nums[1] = 2 + 7 = 9
所以返回 [0, 1]</code></pre>
<p><strong>思路:</strong></p>
<p><code>nums[i]=target-nums[j]</code></p>
<p><strong>题解:</strong></p>
<pre><code class="java">class Solution {
    public int[] twoSum(int[] nums, int target) {
        Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(16);
        for(int i=0;i&lt;nums.length;i++){
            int n = target-nums[i];
            if(map.containsKey(target-nums[i])){
                return new int[]{i,map.get(target-nums[i])};
            }
            map.put(nums[i],i);
        }
        return null;
    }
}</code></pre>
<h4 id="盛最多水的容器"><a href="#盛最多水的容器" class="headerlink" title="盛最多水的容器"></a>盛最多水的容器</h4><p>链接：<a href="https://leetcode-cn.com/problems/container-with-most-water" target="_blank" rel="noopener">https://leetcode-cn.com/problems/container-with-most-water</a></p>
<p><strong>难度：</strong>中等</p>
<p>给定 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。</p>
<p><strong>说明：</strong>你不能倾斜容器，且 n 的值至少为 2。</p>
<p> <img src="/data-structure-array/question_11.jpg" alt></p>
<p>图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49</p>
<p><strong>示例：</strong></p>
<pre><code class="java">输入: [1,8,6,2,5,4,8,3,7]
输出: 49</code></pre>
<p><strong>思路：</strong></p>
<p>官方题解：双指针法</p>
<p>面积=长度(x)*高度(y)</p>
<p>假设left为x轴左起点，right为x轴右起点，left对应的y轴高度为a[left]，right对应的y轴高度为a[right]，计算面积中的高度只能取a[left]和a[right]中小的那个，而长度的计算方式是right-left</p>
<p>，当a[left]&gt;a[right]时，对应的x轴right就往前移动一位，反之left就往后移动一位</p>
<p><strong>题解：</strong></p>
<pre><code class="java">class Solution {
    public int maxArea(int[] height) {
        //x轴左起始位置
        int left=0;
        //x轴右起始位置
        int right= height.length-1;
        int maxarea = 0;
        while(left&lt;right){
            //每次都需要计算面积，将面积更大的赋值给maxarea
            maxarea = Math.max(maxarea,Math.min(height[left],height[right])*(right-left));
            //如果左面的垂直线大于右面的垂直线
            if(height[left]&gt;height[right]){
                //右面的往前移动一位
                right--;
            }else{
                //左面的往后移动一位
                left++;
            }
        }
        return maxarea;
    }
}</code></pre>
<h4 id="接雨水"><a href="#接雨水" class="headerlink" title="接雨水"></a>接雨水</h4><p>链接：<a href="https://leetcode-cn.com/problems/trapping-rain-water" target="_blank" rel="noopener">https://leetcode-cn.com/problems/trapping-rain-water</a></p>
<p><strong>难度：</strong>困难</p>
<p>给定 <em>n</em> 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。</p>
<p><img src="/data-structure-array/rainwatertrap.png" alt></p>
<p>上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 感谢 Marcos 贡献此图。</p>
<p><strong>示例:</strong></p>
<pre><code class="java">输入: [0,1,0,2,1,0,1,3,2,1,2,1]
输出: 6</code></pre>
<p><strong>思路：</strong></p>
<p>解题思路也是使用双指针，没有思路的可详细看下官方题解双指针方法的那个动图</p>
<p><strong>题解：</strong></p>
<pre><code class="java">class Solution {
    public int trap(int[] height) {
        int left=0;
        int right=height.length-1;
        int maxLeft=0;
        int maxRight=0;
        int area =0;
        while(left&lt;right){
            if(height[left]&lt;height[right]){
                if(height[left]&gt;=maxLeft){
                    maxLeft = height[left];
                }else{
                    area += maxLeft-height[left];
                }
                ++left;
            }else{
                if(height[right]&gt;=maxRight){
                    maxRight = height[right];
                }else{
                    area += maxRight-height[right];
                }
                --right;
            }
        }
        return area; 
    }
}</code></pre>
<p><strong>参考:</strong></p>
<p>极客时间:数据结构与算法之美</p>
<p>leetCode官网:<a href="https://leetcode-cn.com/problemset/all/" target="_blank" rel="noopener">https://leetcode-cn.com/problemset/all/</a></p>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/data-structure-array/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">#数据结构</a>
		
			<a href="/tags/%E7%AE%97%E6%B3%95/">#算法</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-06-29T10:05:40.000Z">2019-06-29</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/mysql-optimize/">mysql优化 | 存储引擎，建表，索引，sql的优化建议</a></h1>
	

		</header>
		<div class="entry">
			
				<h4 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h4><p>mysql中查看支持的引擎的sql：</p>
<pre><code class="sql">show engines; </code></pre>
<p><img src="/mysql-optimize/engines.png" alt></p>
<p>日常工作中使用较多的存储引擎对比：InnoDB，MyISAM</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">InnoDB</th>
<th align="center">MyISAM</th>
</tr>
</thead>
<tbody><tr>
<td align="center">存储限制</td>
<td align="center">64T</td>
<td align="center">256T</td>
</tr>
<tr>
<td align="center">支持事务</td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">支持索引</td>
<td align="center">yes</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">支持全文索引</td>
<td align="center">no</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">支持数据缓存</td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">支持外键</td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">支持Hash索引</td>
<td align="center">no</td>
<td align="center">no</td>
</tr>
</tbody></table>
<h5 id="innodb"><a href="#innodb" class="headerlink" title="innodb"></a>innodb</h5><p>支持提交、回滚和崩溃恢复能力的事物安全（ACID），支持行锁，支持外键完整性约束</p>
<p>适合场景</p>
<ul>
<li>需要事务处理</li>
<li>表数据量大，高并发操作</li>
</ul>
<h5 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h5><p>MyISAM存储引擎提供了高速检索和存储的能力，支持全文索引</p>
<p>适合场景</p>
<ul>
<li>很多count计算的</li>
<li>查询非常频繁的</li>
</ul>
<p>其余几种存储引擎</p>
<h5 id="MEMORY引擎"><a href="#MEMORY引擎" class="headerlink" title="MEMORY引擎"></a>MEMORY引擎</h5><p>数据只保存在内存中，因为是在内存中，拥有极高的插入，更新，查询的效率，但是重启后数据都会丢失，表级锁，并发性能低。</p>
<h5 id="MERGE引擎"><a href="#MERGE引擎" class="headerlink" title="MERGE引擎"></a>MERGE引擎</h5><p>merge表是一组MyISAM表的组合，所以merge表是没有数据的，对这个表的操作实际上是操作内部的MyISAM表，将多个MyISAM表合并适合做一些报表之类的操作。</p>
<h5 id="ARCHIVE引擎"><a href="#ARCHIVE引擎" class="headerlink" title="ARCHIVE引擎"></a>ARCHIVE引擎</h5><p>仅支持插入和查询，使用zlib压缩库，在记录被请求的时候实时压缩，不支持事务，支持行级锁，适合存储大量的日志数据。</p>
<p>个人是推荐Innodb引擎的，公司部门里也是规定新建表的时候必须使用Innodb引擎，Innodb引擎较MyISAM引擎可以提供更多的功能，不是很实时的查询场景可以使用缓存，近实时的查询可以使用es，当然了这只是个人看法，针对不同的场景选择不同的存储引擎还是很有必要滴。所以在知道不同存储引擎的特性之后，才可以根据不同业务需求选择合适的存储引擎。</p>
<h4 id="建表原则"><a href="#建表原则" class="headerlink" title="建表原则"></a>建表原则</h4><h5 id="在建表的时候尽量遵循以下原则"><a href="#在建表的时候尽量遵循以下原则" class="headerlink" title="在建表的时候尽量遵循以下原则"></a>在建表的时候尽量遵循以下原则</h5><ol>
<li><p>尽量选择小的数据类型，数据类型选择上尽量tinyint(1字节)&gt;smallint(2字节)&gt;int(4字节)&gt;bigint(8字节)，比如逻辑删除yn字段上（1代表可用，0代表）就可以选择tinyint（1字节）类型</p>
</li>
<li><p>尽量保证字段数据类型长度固定</p>
</li>
<li><p>尽量避免使用null，使用null的字段查询很难优化，影响索引，可以使用0或’’代替</p>
</li>
<li><p>避免宽表，能拆分就拆分，一个表往往跟一个实体域对应，就像设计对象的时候一样，保持单一原则</p>
</li>
<li><p>尽量避免使用text和blob，如果非使用不可，将类型为text和blob的字段在独立成一张新表，然后使用主键对应原表</p>
</li>
<li><p>禁止使用float或double类型，这个坑超大，float或double存在精度问题，在进行比较或者加减操作的时候会丢失精度导致数据异常，凡是使用float或double类型的时候考虑下可不可使用int或bigint代替。比如金额，以元为单位使用float或double类型的时候，可以考虑以分为单位使用int，bigint类型代替，然后由业务代码进行单位的转换。</p>
</li>
<li><p>每张表都加上createUser,createTime.updateUser,updateTime字段</p>
</li>
<li><p>起名字要规范，包括：库名，表名，字段名，索引名</p>
</li>
<li><p>查询频繁使用的字段记得加索引</p>
</li>
<li><p>尽量避免使用外键，不用外键约束，性能更高，然后数据的完整性有程序进行管理</p>
</li>
<li><p>如果表的数量可以预测到非常大，最好在建表的时候，就进行分表，不至于一时间数据量非常大导致效率问题</p>
<p>未完待补充，，，</p>
</li>
</ol>
<h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p>索引是为来加速对表中数据行中的检索而创建的一种分散的数据结果,是针对表而建立的，它是由数据页面以外的索引页面组成,每个索引页中的行都含有逻辑指针,以便加速检索物理数据，创建索引的目的在于提高查询效率，innodb的索引都是基于b tree实现的</p>
<h5 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h5><p>普通索引：最基本的索引，无限制</p>
<pre><code class="sql">#方式1
CREATE INDEX idx_username ON sys_user(user_name(32)); 
#方式2
ALTER table sys_user ADD INDEX idx_username(user_name(32))</code></pre>
<p>主键索引：一个表只能有一个主键索引，且不能为空</p>
<p>一般建表时同时创建了主键索引</p>
<pre><code class="sql">CREATE TABLE `sys_user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_name` varchar(32) DEFAULT NULL,
  `pass_word` varchar(32) DEFAULT NULL,
  `token` varchar(32) DEFAULT NULL,
  `token_expire` int(11) DEFAULT NULL,
  `yn` smallint(6) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=348007 DEFAULT CHARSET=utf8;</code></pre>
<p>唯一索引：与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一</p>
<pre><code class="sql">CREATE UNIQUE INDEX idx_token ON sys_user(token_expire)</code></pre>
<p>组合索引：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合</p>
<pre><code class="sql">ALTER TABLE sys_user ADD INDEX idx_un_te (user_name(32),token_expire); </code></pre>
<p>全文索引：用来查找文本中的关键字，而不是直接与索引中的值相比较。只有char、varchar，text 列上可以创建全文索引</p>
<pre><code class="sql">CREATE FULLTEXT INDEX idx_ ON sys_user(pass_word)</code></pre>
<h5 id="创建使用索引的原则"><a href="#创建使用索引的原则" class="headerlink" title="创建使用索引的原则"></a>创建使用索引的原则</h5><ol>
<li><p>索引的字段尽量要小，根据索引查询数据的快慢取决于b tree的高度，当数据量恒定的时候，字节越少，存的索引的数量就越多，树的高度就越会越低</p>
<p>比如：设置varchar(10)，则这个索引建立的时候只会存字段前10个字节，字段设置的字节数比较小可能会导致索引查出来的数据多，进而进行回表，导致性能下降，所以字段设置为多少还是要自己斟酌一下</p>
</li>
<li><p>遵循索引的最左匹配原则</p>
</li>
<li><p>注意使用like的时候尽量不要使用“%a%”，这样的不走索引，可以使用“a%”，走索引</p>
</li>
<li><p>不要在索引的列上进行计算，比如 select * from sys_user where token_expire+1 = 10000，这样的语句 不会走有索引</p>
</li>
<li><p>什么样的字段建索引，就是那种频繁在where，group by，order by中出现的列，最好加上索引</p>
</li>
<li><p>使用联合索引的时候尽量考虑到索引下推优化</p>
</li>
<li><p>对于使用or的条件，需要or左右的条件都是索引才会走索引，否则走全表扫描，可以考虑使用union代替</p>
</li>
<li><p>避免使用select *，对于只需要查询主键或者where 条件中只有索引的字段， 这时会走覆盖索引建少回表次数</p>
</li>
<li><p>sql语句中避免隐式转换，在MySQL 中，字符串和数字做比较的话，是将字符串转换成数字，如字段是varchar类型，但是入参是int类型，即便字段有索引也不会走，因为这里会进行一次隐式转换</p>
</li>
</ol>
<p><strong>总之使用索引的时候，需要考虑的地方比较多，但是归根结底就是查询尽量走索引，走索引尽量避免回表或减少回表次数</strong></p>
<h5 id="索引的缺点"><a href="#索引的缺点" class="headerlink" title="索引的缺点"></a>索引的缺点</h5><p>虽然索引的可以提高查询的效率，但是在进行insert，update，和delete的时候会降低效率，因为在保存数据的同时也会去保存索引。</p>
<p>不要在一个表里建过多的索引，问题跟上面一样，在操作数据的时候效率降低，而且数据量少的表要看情况建索引，如果建索引跟没建索引的效果差不多少的情况下就不要建索引了，如果是数据量大的表，就需要建索引去优化查询效率。</p>
<h5 id="explain分析sql"><a href="#explain分析sql" class="headerlink" title="explain分析sql"></a>explain分析sql</h5><p>可以使用explain去分析sql的执行情况，比如</p>
<pre><code class="sql">explain select * from sys_user where token_expire = 10000; </code></pre>
<p><img src="/mysql-optimize/explan.png" alt></p>
<p>在阿里的开发手册中提到过，sql性能优化的标准：至少要达到range，要求ref级别，如果可以是consts最好</p>
<p>说明一下，这里的级别指的就是上图的type字段：</p>
<ul>
<li><p>consts 是指单表中最多只有一个匹配行（主键或唯一索引）</p>
</li>
<li><p>ref 指的是使用普通索引</p>
</li>
<li><p>range 是指对索引进行范围查询</p>
</li>
</ul>
<h4 id="sql优化"><a href="#sql优化" class="headerlink" title="sql优化"></a>sql优化</h4><p>关于sql语句的优化主要是两方面，一个是在建sql的时候需要注意的问题，另一个就是在发现有慢sql的时候可以根据不同情况进行分析，然后优化sql</p>
<h5 id="优化的建议"><a href="#优化的建议" class="headerlink" title="优化的建议"></a>优化的建议</h5><ol>
<li><p>查询的时候一定要记得使用limit进行限制</p>
</li>
<li><p>对于结果只需要一条数据的查询用limit 1进行限制</p>
</li>
<li><p>使用<code>count(*)</code>或count(1)来统计行数来查询，使用count(列)的时候，需要在查看列中这个是否为null,不会统计此列为null的情况，而且mysql已经<code>对count(*)</code>做了优化</p>
</li>
<li><p>不要使用select * 来查数据，使用select 需要的列名，这样的方式去查询</p>
</li>
<li><p>使用join链接代替子查询</p>
</li>
<li><p>不要使用外键，外键的约束可以放在程序里解决</p>
</li>
<li><p>控制一下in操作的集合数量，不要太大了</p>
</li>
<li><p>针对慢查询使用explain去分析原因，然后优化sql，让其尽量走索引</p>
</li>
</ol>
<p>上面说的四个方面就是我目前对于sql优化各个方面的注意事项，希望可以给大家提供一个参考，有问题的可以指出来，交流交流</p>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/mysql-optimize/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/mysql/">mysql</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/mysql/">#mysql</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-06-11T08:42:12.000Z">2019-06-11</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/crawler-htmlunit/">一个可配置的爬虫采集系统的方案实现</a></h1>
	

		</header>
		<div class="entry">
			
				<blockquote>
<p>记录写的一个采集系统，包括需求，分析，设计，实现，遇到的问题及系统的成效，系统最主要功能就是可以通过对每个网站进行不同的采集规则配置对每个网站爬取数据，两年前已爬取的数据量大概在千万级左右，每天采集的数据增量在一万左右，配置采集的网站1200多个，现记录一下系统实现，在提供一些简单的爬虫demo供大家学习下如何爬数据</p>
</blockquote>
<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>数据采集系统：一个可以通过配置规则采集不同网站的系统<br>主要实现目标：</p>
<ol>
<li>针对不同的网站通过配置不同的采集规则实现网页数据的爬取</li>
<li>针对每篇内容可以实现对特征数据的提取</li>
<li>定时去爬取所有网站的数据</li>
<li>采集配置规则可维护</li>
<li>采集入库数据可维护</li>
</ol>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p>数据采集系统架构图</p>
<p><img src="/crawler-htmlunit/%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt></p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>第一步当然要先分析需求，所以在抽取一下系统的主要需求：</p>
<ol>
<li>针对不同的网站可以通过不同的采集规则实现数据的爬取 </li>
<li>针对每篇内容可以实现对特征数据的提取，特征数据就是指标题，作者，发布时间这种信息</li>
<li>定时任务关联任务或者任务组去爬取网站的数据</li>
</ol>
<p>再分析一下网站的结构，无非就是两种；</p>
<ol>
<li>一个是列表页，这里的列表页代表的就是那种需要在当前页面获取到更多别的详情页的网页链接，像一般的查询列表，可以通过列表获取到更多的详情页链接。</li>
<li>一个是详情页，这种就比较好理解，这种页面不需要在这个页面再去获得别的网页链接了，直接在当前页面就可以提取数据。</li>
</ol>
<p>基本所有爬取的网站都可以抽象成这样</p>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><p>针对分析的结果设计实现：</p>
<ol>
<li><p>任务表</p>
<p>每个网站可以当做一个任务，去执行采集  </p>
</li>
<li><p>两张规则表</p>
<p>每个网站对应自己的采集规则，根据上面分析的网站结构，采集规则又可以细分为两个表，一个是包含网站链接，获取详情页列表的列表采集规则表，一个针对是网站详情页的特征数据采集的规则表 详情采集规则表 </p>
</li>
<li><p>url表</p>
<p>负责记录采集目标网站详情页的url </p>
</li>
<li><p>定时任务表</p>
<p>根据定时任务去定时执行某些任务 （可以采用定时任务和多个任务进行关联，也可以考虑新增一个任务组表，定时任务跟任务组关联，任务组跟任务关联）</p>
</li>
<li><p>数据存储表 </p>
<p>这个由于我们采集的数据主要是招标和中标两种数据，分别建了两张表进行数据存储，中标信息表，招标信息表</p>
</li>
</ol>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h3><p>基础架构就是：ssm+redis+htmlunit+jsoup+es+mq+quartz<br>java中可以实现爬虫的框架有很多，htmlunit，WebMagic，jsoup等等还有很多优秀的开源框架，当然httpclient也可以实现。</p>
<p>为什么用htmlunit？<br>        htmlunit 是一款开源的java 页面分析工具，读取页面后，可以有效的使用htmlunit分析页面上的内容。项目可以模拟浏览器运行，被誉为java浏览器的开源实现</p>
<p>简单说下我对htmlunit的理解：</p>
<ol>
<li>一个是htmlunit提供了通过xpath去定位页面元素的功能，利用xpath就可以实现对页面特征数据进行提取；</li>
<li>第二个就在于对js的支持，支持js意味着你真的可以把它当做一个浏览器，你可以用它模拟点击，输入，登录等操作，而且对于采集而言，支持js就可以解决页面使用ajax获取数据的问题</li>
<li>当然除此之外，htmlunit还支持代理ip，https，通过配置可以实现模拟谷歌，火狐等浏览器，Referer，user-agent，是否加载js，css，是否支持ajax等。</li>
</ol>
<p><em>XPath语法即为XML路径语言（XML Path Language），它是一种用来确定XML文档中某部分位置的语言。</em></p>
<p>jsoup相较于htmlunit，就在于它提供了一种类似于jquery选择器的定位页面元素的功能，两者可以互补使用。</p>
<h3 id="采集"><a href="#采集" class="headerlink" title="采集"></a>采集</h3><p>采集数据逻辑分为两个部分：url采集器，详情页采集器</p>
<p>url采集器：</p>
<ul>
<li>只负责采集目标网站的详情页url</li>
</ul>
<p>详情页采集器：</p>
<ul>
<li><p>根据url去采集目标url的详情页数据</p>
</li>
<li><p>使用htmlunit的xpath，jsoup的select语法，和正则表达式进行特征数据的采集。</p>
<p>  这样设计目的主要是将url采集和详情页的采集流程分开，后续如果需要拆分服务的话就可以将url采集和详情页的采集分成两个服务。</p>
<p>  url采集器与详情页采集器之间使用mq进行交互，url采集器采集到url做完处理之后把消息冷到mq队列，详情页采集器去获取数据进行详情页数据的采集。</p>
</li>
</ul>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><h4 id="数据去重："><a href="#数据去重：" class="headerlink" title="数据去重："></a>数据去重：</h4><ol>
<li>在采集url的时候进行去重</li>
<li>同过url进行去重，通过在redis存储key为url，缓存时间为3天，这种方式是为了防止对同一个url进行重复采集。</li>
<li>通过标题进行去重，通过在redis中存储key为采集到的标题 ，缓存时间为3天，这种方式就是为了防止一篇文章被不同网站发布，重复采集情况的发生。</li>
</ol>
<h4 id="数据质量："><a href="#数据质量：" class="headerlink" title="数据质量："></a>数据质量：</h4><p>​    由于每个网站的页面都不一样，尤其是有的同一个网站的详情页结构也不一样，这样就给特征数据的提取增加了难度，所以使用了htmlunit+jsoup+正则三种方式结合使用去采集特征数据。</p>
<h4 id="采集效率："><a href="#采集效率：" class="headerlink" title="采集效率："></a>采集效率：</h4><p>​    由于采集的网站较多，假设每个任务的执行都打开一个列表页，十个详情页，那一千个任务一次执行就需要采集11000个页面，所以采用url与详情页分开采集，通过mq实现异步操作，url和详情页的采集通过多线程实现。</p>
<h4 id="被封ip："><a href="#被封ip：" class="headerlink" title="被封ip："></a>被封ip：</h4><p>​    对于一个网站，假设每半小时执行一次，那每天就会对网站进行48次的扫描，也是假设一次采集会打开11个页面，一天也是528次，所以被封是一个很常见的问题。解决办法，htmlunit提供了代理ip的实现，使用代理ip就可以解决被封ip的问题，代理ip的来源：一个是现在网上有很多卖代理ip的网站，可以直接去买他们的代理ip，另一种就是爬，这些卖代理ip的网站都提供了一些免费的代理ip，可以将这些ip都爬回来，然后使用httpclient或者别的方式去验证一下代理ip的可用性，如果可以就直接入库，构建一个自己的代理ip库，由于代理ip具有时效性，所以可以建个定时任务去刷这个ip库，将无效ip剔除。</p>
<h4 id="网站失效："><a href="#网站失效：" class="headerlink" title="网站失效："></a>网站失效：</h4><p>​    网站失效也有两种，一种是网站该域名了，原网址直接打不开，第二种就是网站改版，原来配置的所有规则都失效了，无法采集到有效数据。针对这个问题的解决办法就是每天发送采集数据和日志的邮件提醒，将那些没采到数据和没打开网页的数据汇总，以邮件的方式发送给相关人员。</p>
<h4 id="验证码："><a href="#验证码：" class="headerlink" title="验证码："></a>验证码：</h4><p>​    当时对一个网站采集历史数据采集，方式也是先通过他们的列表页去采集详情页，采集了几十万的数据之后发现，这个网站采不到数据了，看页面之后发现在列表页加了一个验证码,这个验证码还是属于比较简单的就数字加字母，当时就想列表页加验证码？，然后想解决办法吧，搜到了一个开源的orc文字识别项目tess4j（怎么使用可以看这），用了一下还可以，识别率在百分之二十左右，因为htmlunit可以模拟在浏览器的操作，所以在代码中的操作就是先通过htmlunit的xpath获取到验证码元素，获取到验证码图片，然后利用tess4j进行验证码识别，之后将识别的验证码在填入到验证码的输入框，点击翻页，如果验证码通过就翻页进行后续采集，如果失败就重复上述识别验证码操作，知道成功为止，将验证码输入到输入框和点击翻页都可用htmlunit去实现</p>
<h4 id="ajax加载数据："><a href="#ajax加载数据：" class="headerlink" title="ajax加载数据："></a>ajax加载数据：</h4><p>​    有些网站使用的是ajax加载数据，这种网站在使用htmlunit采集的时候需要在获取到HtmlPage对象之后给页面一个加载ajax的时间，之后就可以通过HtmlPage拿到ajax加载之后的数据。</p>
<p>代码：webClient.waitForBackgroundJavaScript(time); 可以看后面提供的demo</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>一个简略爬虫的代码实现：</p>
<pre><code class="java">@GetMapping(&quot;/getData&quot;)
    public List&lt;String&gt; article_(String url,String xpath){
        WebClient webClient = WebClientUtils.getWebClientLoadJs();
        List&lt;String&gt; datas = new ArrayList&lt;&gt;();
        try {
            HtmlPage page = webClient.getPage(url);
            if(page!=null){
                List&lt;?&gt; lists = page.getByXPath(xpath);
                lists.stream().forEach(i-&gt;{
                    DomNode domNode = (DomNode)i;
                    datas.add(domNode.asText());
                });
            }
        }catch (Exception e){
            e.printStackTrace();
        }finally {
            webClient.close();
        }
        return datas;
    }</code></pre>
<p>上面的代码就实现了采集一个列表页</p>
<ul>
<li>url就是目标网址</li>
<li>xpath就要采集的数据的xpath了</li>
</ul>
<h4 id="爬一下博客园"><a href="#爬一下博客园" class="headerlink" title="爬一下博客园"></a>爬一下博客园</h4><p>请求这个url：<a href="http://localhost:9001/getData?url=https://www.cnblogs.com/&amp;xpath=//*[@id=&quot;post_list&quot;]/div/div[2]/h3/a" target="_blank" rel="noopener">http://localhost:9001/getData?url=https://www.cnblogs.com/&amp;xpath=//*[@id=&quot;post_list&quot;]/div/div[2]/h3/a</a></p>
<ul>
<li>url：传的是博客园首页的地址；</li>
<li>xpath：传的是获取博客园首页的博客列表的标题</li>
</ul>
<p>网页页面：<br><img src="/crawler-htmlunit/1.jpg" alt><br>采集回的数据：<br><img src="/crawler-htmlunit/2.jpg" alt></p>
<h4 id="再爬一下csdn"><a href="#再爬一下csdn" class="headerlink" title="再爬一下csdn"></a>再爬一下csdn</h4><p>再次请求：<a href="http://localhost:9001/getData?url=https://blog.csdn.net/&amp;xpath=//*[@id=&quot;feedlist_id&quot;]/li/div/div[1]/h2/a" target="_blank" rel="noopener">http://localhost:9001/getData?url=https://blog.csdn.net/&amp;xpath=//*[@id=&quot;feedlist_id&quot;]/li/div/div[1]/h2/a</a></p>
<ul>
<li>url：这次传是csdn的首页；</li>
<li>xpath：传的是获取csdn首页的博客列表的标题</li>
</ul>
<p>网页页面：<br><img src="/crawler-htmlunit/3.jpg" alt><br>采集回的数据：<br><img src="/crawler-htmlunit/4.jpg" alt></p>
<h4 id="采集步骤"><a href="#采集步骤" class="headerlink" title="采集步骤"></a>采集步骤</h4><pre><code>通过一个方法去采集两个网站，通过不同url和xpath规则去采集不同的网站，这个demo展示的就是htmlunit采集数据的过程。
每个采集任务都是执行相同的步骤
- 获取client -&gt; 打开页面 -&gt; 提取特征数据（或详情页链接） -&gt; 关闭cline
不同的地方就在于提取特征数据</code></pre><p>优化：利用模板方法设计模式，将功能部分抽取出来</p>
<p>上述代码可以抽取为：一个采集执行者，一个自定义采集数据的实现</p>
<pre><code class="java">/**
 * @Description: 执行者 man
 * @author: chenmingyu
 * @date: 2018/6/24 17:29
 */
public class Crawler {

    private Gatherer gatherer;

    public Object execute(String url,Long time){
        // 获取 webClient对象
        WebClient webClient = WebClientUtils.getWebClientLoadJs();
        try {
            HtmlPage page = webClient.getPage(url);
            if(null != time){
                webClient.waitForBackgroundJavaScript(time);
            }
            return gatherer.crawl(page);
        }catch (Exception e){

            e.printStackTrace();
        }finally {
            webClient.close();
        }
        return null;
    }

   public Crawler(Gatherer gatherer) {
        this.gatherer = gatherer;
    }
}</code></pre>
<p>在Crawler 中注入一个接口，这个接口只有一个方法crawl（），不同的实现类去实现这个接口,然后自定义取特征数据的实现</p>
<pre><code class="java">/**
 * @Description: 自定义实现
 * @author: chenmingyu
 * @date: 2018/6/24 17:36
 */
public interface Gatherer {

    Object crawl(HtmlPage page) throws Exception;
}
</code></pre>
<p>优化后的代码:</p>
<pre><code class="java">    @GetMapping(&quot;/getData&quot;)
    public List&lt;String&gt; article_(String url,String xpath){

        Gatherer gatherer = (page)-&gt;{
            List&lt;String&gt; datas = new ArrayList&lt;&gt;();
            List&lt;?&gt; lists = page.getByXPath(xpath);
            lists.stream().forEach(i-&gt;{
                DomNode domNode = (DomNode)i;
                datas.add(domNode.asText());
            });
            return datas;
        };

        Crawler crawler = new Crawler(gatherer);
        List&lt;String&gt; datas = (List&lt;String&gt;)crawler.execute(url,null);
        return datas;
    }</code></pre>
<p>不同的实现，只需要去修改接口实现的这部分就可以了</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>最后看一下利用采集系统采集的数据。</p>
<h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>效果还是不错的，最主要是系统运行稳定：</p>
<ol>
<li>采集的历史数据在600-700万量级之间</li>
<li>每天新采集的数据增量在一万左右</li>
<li>系统目前配置了大约1200多个任务（一次定时的实现会去采集这些网站）</li>
</ol>
<h3 id="数据-1"><a href="#数据-1" class="headerlink" title="数据"></a>数据</h3><p>系统配置采集的网站主要针对全国各省市县招投标网站（目前大约配置了1200多个采集站点）的标讯信息。<br>采集的数据主要做公司标讯的数据中心，为一个pc端网站和2微信个公众号提供数据</p>
<ul>
<li>网址：<a href="http://www.bid-data.com" target="_blank" rel="noopener">http://www.bid-data.com</a></li>
<li>公众号：爱招标，中标喽</li>
</ul>
<p>欢迎关注，掌握一手标讯信息</p>
<p>以pc端展示的一篇采集的中标的数据为例，看下采集效果：</p>
<ul>
<li><a href="http://www.bid-data.com/bid_MQKHG001TD6.html" target="_blank" rel="noopener">http://www.bid-data.com/bid_MQKHG001TD6.html</a><br>采集的详情：<br><img src="/crawler-htmlunit/5.jpg" alt><br>特征数据的提取：<br><img src="/crawler-htmlunit/6.jpg" alt></li>
</ul>
<blockquote>
<p>本文只是大概记录下这个采集系统从零到整的过程，当然其中还遇到了很多本文没提到的问题。</p>
</blockquote>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/crawler-htmlunit/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/htmlunit/">#htmlunit</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-05-31T06:54:58.000Z">2019-05-31</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/spring-source-base/">spring实现原理 | 加载xml，注册BeanDefinition</a></h1>
	

		</header>
		<div class="entry">
			
				<p>本文首先提供了一个实现了spring aop的demo，通过demo进行源码分析</p>
<p>通过读源码我们可以学习到spring是<strong>如何解析xml的</strong>，如何<strong>加载bean</strong>的，如何<strong>创建bean</strong>的，又是如何<strong>实现aop</strong>操作的，及其中各种操作的细节是如何实现的</p>
<p>讲源码的时候我会进行一些取舍，根据上面的问题结合demo对主要流程进行讲解，争取能把上述的问题说明白</p>
<p><strong>源码地址：<a href="https://github.com/mingyuHub/spring-shared" target="_blank" rel="noopener">https://github.com/mingyuHub/spring-shared</a></strong></p>
<h3 id="Aop-demo"><a href="#Aop-demo" class="headerlink" title="Aop demo"></a>Aop demo</h3><p>代码：</p>
<ol>
<li>一个类<code>UserController</code>，提供一个方法<code>login</code></li>
<li>一个切面<code>UserAspect</code>，切入点为<code>login</code>方法</li>
<li>一个配置文件<code>spring-aop.xml</code>将类加载到spring容器中</li>
</ol>
<p>创建<code>UserController</code>类</p>
<pre><code class="java">public class UserController {

    public void login(){
        System.out.println(&quot;登录&quot;);
    }
}</code></pre>
<p>定义一个切面<code>UserAspect</code>，不了解aop概念的可以看一下：<a href="https://chenmingyu.top/springboot-aop/">https://chenmingyu.top/springboot-aop/</a></p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/3/19 18:29
 * @description:
 */
@Aspect
public class UserAspect {

    /**
     * 切入点
     */
    @Pointcut(&quot;execution(public * com.my.spring.*.*(..))&quot;)
    public void execute(){
    }

    /**
     * 前置通知
     * @param joinPoint
     */
    @Before(value =&quot;execute()&quot;)
    public void Before(JoinPoint joinPoint) {
        System.out.println(&quot;执行方法之前&quot;);
    }

    /**
     * 后置通知
     * @param joinPoint
     */
    @After(value =&quot;execute()&quot;)
    public void After(JoinPoint joinPoint) {
        System.out.println(&quot;执行方法之后&quot;);
    }
}</code></pre>
<p>自定义一个xml文件，名为<code>spring-aop.xml</code></p>
<pre><code class="java">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
           http://www.springframework.org/schema/aop
           http://www.springframework.org/schema/aop/spring-aop-3.1.xsd
           &quot;&gt;

    &lt;aop:aspectj-autoproxy    proxy-target-class=&quot;true&quot;/&gt;
    &lt;bean id=&quot;userController&quot; class=&quot;com.my.spring.UserController&quot;/&gt;
    &lt;bean id=&quot;userAspect&quot; class=&quot;com.my.spring.UserAspect&quot;/&gt;
&lt;/beans&gt;</code></pre>
<p>调试的代码已经准备好，首先写一个测试类测一下</p>
<pre><code class="java">@Test
public void test(){
    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring-aop.xml&quot;);
    UserController userController = (UserController) applicationContext.getBean(&quot;userController&quot;);
    userController.login();
}</code></pre>
<p>正常情况下的输出如下：</p>
<p><img src="/spring-source-base/1.png" alt></p>
<h3 id="核心类"><a href="#核心类" class="headerlink" title="核心类"></a>核心类</h3><p>开始学习spring的源码之前，有必要先了解一下spring中几个较为核心的类</p>
<p>先大概了解一下这些类是干什么的，不必深究，后续读源码的时候碰到会着重讲解一下</p>
<p>先看一个spring容器的类图：</p>
<p><img src="/spring-source-base/5.png" alt></p>
<ol>
<li><p><strong>BeanFactory</strong></p>
<p>工厂类的顶级接口，用于获取bean及bean的各种属性，提供了ioc容器最基本的形式，给具体的IOC容器的实现提供了规范</p>
<p>ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory是BeanFactory接口的子接口，最终的默认实现类是 DefaultListableBeanFactory，定义这多接口主要是为了区分在 Spring 内部在操作过程中对象的传递和转化过程中，对对象的数据访问所做的限制</p>
</li>
<li><p><strong>DefaultListableBeanFactory</strong></p>
<p>ioc容器的实现，DefaultListableBeanFactory作为一个可以独立使用的ioc容器，是整个Bean加载的核心部分，是spring注册及加载bean的默认实现</p>
</li>
<li><p><strong>xmlBeanFactory</strong></p>
<p>xmlBeanFactory继承DefaultListableBeanFactory，对其进行了扩展，增加了自定义的xml读取器<code>XmlBeanDefinitionReader</code>，实现了个性化的BeanDefinitionReader读取，主要作用就是将xml配置解析成BeanDefinition</p>
</li>
<li><p><strong>ApplicationContext</strong></p>
<p>ApplicationContext继承自BeanFactory，包含BeanFactory的所有功能，情况下都使用这个</p>
</li>
<li><p><strong>BeanDefinition</strong></p>
<p>Spring中用于包装Bean的数据结构</p>
</li>
<li><p><strong>BeanDefinitionRegistory</strong></p>
<p>定义对BeanDefinition的各种增删操作</p>
</li>
<li><p><strong>BeanDefinitionReader</strong></p>
<p>定义了读取BeanDefinition的接口，主要作用是从资源文件中读取Bean定义，XmlBeanDefinitionReader是其具体的实现类</p>
</li>
<li><p><strong>SingletonBeanRegistry</strong></p>
<p>定义对单例的注册及获取</p>
</li>
<li><p><strong>AliasRegistry</strong></p>
<p>定义对alias的简单增删改操作</p>
</li>
</ol>
<p>了解一些核心类之后我们就要开始读源码了</p>
<h3 id="读源码"><a href="#读源码" class="headerlink" title="读源码"></a>读源码</h3><p>我们的源码以测试类为入口开始分析</p>
<pre><code class="java">ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring-aop.xml&quot;);</code></pre>
<p><code>ApplicationContext</code>和<code>BeanFactory</code>都是用于加载Bean的，相比之下<code>ApplicationContext</code>提供了更多的扩展功能</p>
<p><code>ClassPathXmlApplicationContext</code>最终调用下面这个构造函数</p>
<pre><code class="java">public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent)
      throws BeansException {

   super(parent);
   //设置配置文件
   setConfigLocations(configLocations);
   if (refresh) {
      refresh();
   }
}</code></pre>
<p><code>refresh()</code>是<code>ApplicationContext</code>的核心方法，这个方法基本包含了<code>ApplicationContext</code>提供的全部功能</p>
<pre><code class="java">@Override
public void refresh() throws BeansException, IllegalStateException {
   synchronized (this.startupShutdownMonitor) {
      // 准备刷新此上下文，不重要.
      prepareRefresh();

      // 初始化bean工厂，加载xml，解析默认标签，解析自定义标签，注册BeanDefinitions
      ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

      // 设置bean工厂的属性，进行功能填充.
      prepareBeanFactory(beanFactory);

      try {
         // 子类覆盖方法做额外的处理.
         postProcessBeanFactory(beanFactory);

         // 激活bean处理器.
         invokeBeanFactoryPostProcessors(beanFactory);

         // 注册拦截bean创建的bean处理器，只是注册
         registerBeanPostProcessors(beanFactory);

         // 初始化message源.
         initMessageSource();

         // 初始化应用消息广播器
         initApplicationEventMulticaster();

         // 留给子类加载其他bean.
         onRefresh();

         // 注册Listeners bean，到消息广播器
         registerListeners();

         // 实例化所有剩余的（非lazy init）单例.
         finishBeanFactoryInitialization(beanFactory);

         // 刷新通知.
         finishRefresh();
      }

      catch (BeansException ex) {
         logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt&quot;, ex);

         // Destroy already created singletons to avoid dangling resources.
         destroyBeans();

         // Reset &#39;active&#39; flag.
         cancelRefresh(ex);

         // Propagate exception to caller.
         throw ex;
      }
   }
}</code></pre>
<h4 id="spring是如何加载解析xml，注册BeanDefinition的"><a href="#spring是如何加载解析xml，注册BeanDefinition的" class="headerlink" title="spring是如何加载解析xml，注册BeanDefinition的"></a>spring是如何加载解析xml，注册BeanDefinition的</h4><p>加载解析xml和注册BeanDefinition的逻辑都在<code>obtainFreshBeanFactory()</code>方法中，这个方法的作用是初始化bean工厂，加载xml，解析默认标签和自定义标签，将解析出来的<code>BeanDefinition</code>注册到容器中</p>
<pre><code class="java">protected ConfigurableListableBeanFactory obtainFreshBeanFactory() {
   // 核心逻辑：创建bean工厂，解析xml，注册BeanDefinition
   refreshBeanFactory();

   ConfigurableListableBeanFactory beanFactory = getBeanFactory();
   if (logger.isDebugEnabled()) {
      logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory);
   }
   return beanFactory;
}

------------------调用下面这个方法------------------

//调用AbstractRefreshableApplicationContext的refreshBeanFactory()
protected final void refreshBeanFactory() throws BeansException {
        if (hasBeanFactory()) {
            destroyBeans();
            closeBeanFactory();
        }
        try {
            //创建bean工厂，类型为DefaultListableBeanFactory
            DefaultListableBeanFactory beanFactory = createBeanFactory();
            beanFactory.setSerializationId(getId());
            customizeBeanFactory(beanFactory);
            //核心逻辑：加载BeanDefinitions，进入这个方法
            loadBeanDefinitions(beanFactory);
            synchronized (this.beanFactoryMonitor) {
                this.beanFactory = beanFactory;
            }
        }
        catch (IOException ex) {
            throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex);
        }
}    </code></pre>
<p><code>createBeanFactory()</code>方法逻辑特别简单，我们详细说一下<code>loadBeanDefinitions(beanFactory)</code>方法</p>
<p>在<code>loadBeanDefinitions()</code>这个方法实例化了一个<strong>XmlBeanDefinitionReader</strong>，介绍<code>XmlBeanDefinitionReader</code>之前需要介绍一下什么是<code>BeanDefinition</code></p>
<p><strong>BeanDefinition</strong>：Bean的定义主要由<code>BeanDefinition</code>来描述的。作为Spring中用于包装Bean的数据结构</p>
<p><code>BeanDefinition</code>作为顶级接口 ，拥有三种实现：<code>RootBeanDefinition</code>，<code>ChildBeanDefinition</code>，<code>GenericBeanDefinition</code>，三种<code>BeanDefinition</code>均继承了<code>AbstractBeanDefinition</code></p>
<p><img src="/spring-source-base/4.jpg" alt></p>
<p>spring通过<code>BeanDefinition</code>将配置文件中的<bean>标签转换为容器的内部表示，并将<code>BeanDefinition</code>注册到<code>BeandefinitionRegistry</code>中，spring中的容器主要以map的形式进行存储<code>BeanDefinition</code></bean></p>
<p>再介绍一下<strong>BeanDefinitionReader</strong>：</p>
<p><img src="/spring-source-base/2.png" alt></p>
<p><strong>BeanDefinitionReader</strong>解决的是从资源文件（xml,propert）解析到<code>BeanDefinition</code>的过程，所以<strong>XmlBeanDefinitionReader</strong>的作用就很明显了，将xml转为<code>BeanDefinition</code></p>
<pre><code class="java">protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException {
   // 根据beanFactory创建XmlBeanDefinitionReader
   XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);

   // 加载环境变量啥的
   beanDefinitionReader.setEnvironment(this.getEnvironment());
   beanDefinitionReader.setResourceLoader(this);
   beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this));

   // initBeanDefinitionReader
   initBeanDefinitionReader(beanDefinitionReader);
    //核心逻辑在这个方法里，加载beanDefinitions
   loadBeanDefinitions(beanDefinitionReader);
}</code></pre>
<p>在<code>loadBeanDefinitions(beanDefinitionReader);</code>方法中我们层层调用，发现最终解析xml调用的方法是<code>doLoadBeanDefinitions(InputSource inputSource, Resource resource)</code></p>
<pre><code class="java">protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource)
      throws BeanDefinitionStoreException {
   try {
      //将xml转成document对象 
      Document doc = doLoadDocument(inputSource, resource);
      //核心逻辑在这个方法里，解析Document，注册beanDefinition
      return registerBeanDefinitions(doc, resource);
   }
   catch (BeanDefinitionStoreException ex) {
      throw ex;
   }
   ......省略其他异常信息
}</code></pre>
<p><code>registerBeanDefinitions(doc, resource);</code>方法中最终调用<code>doRegisterBeanDefinitions(Element root)</code>将由<code>xml</code>转出来的<code>Document</code>（通过<code>doc.getDocumentElement()</code>取到Element 元素）解析成<code>beandefinition</code>并注册</p>
<pre><code class="java">protected void doRegisterBeanDefinitions(Element root) {

   BeanDefinitionParserDelegate parent = this.delegate;
   this.delegate = createDelegate(getReaderContext(), root, parent);

   if (this.delegate.isDefaultNamespace(root)) {
      String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);
      if (StringUtils.hasText(profileSpec)) {
         String[] specifiedProfiles = StringUtils.tokenizeToStringArray(
               profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);
         if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {
            return;
         }
      }
   }
   //解析前置操作，留给子类实现
   preProcessXml(root);
   // 核心逻辑：解析并注册BeanDefinition
   parseBeanDefinitions(root, this.delegate);
   //解析后置操作，留给子类实现
   postProcessXml(root);

   this.delegate = parent;
}</code></pre>
<p>经历层层调用我们终于找到了核心方法，解析<code>beanDefinition</code>，我们看看它是如何进行解析的</p>
<p>spring中的标签包括默认标签和自定义标签两种，但是两种标签的解析方式有很大的区别</p>
<pre><code class="java">protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {
   //根据root元素的namespace是否等于http://www.springframework.org/schema/beans
   //通过上面的判断，确定是否是属于spring的默认标签 
   if (delegate.isDefaultNamespace(root)) {
      NodeList nl = root.getChildNodes();
      for (int i = 0; i &lt; nl.getLength(); i++) {
         Node node = nl.item(i);
         if (node instanceof Element) {
            Element ele = (Element) node;
            if (delegate.isDefaultNamespace(ele)) {
               //默认标签解析
               parseDefaultElement(ele, delegate);
            }
            else {
               //自定义标签解析 
               delegate.parseCustomElement(ele);
            }
         }
      }
   }
   else {
      //自定义标签解析 
      delegate.parseCustomElement(root);
   }
}</code></pre>
<h4 id="默认标签解析"><a href="#默认标签解析" class="headerlink" title="默认标签解析"></a>默认标签解析</h4><p><code>parseDefaultElement()</code>方法提供了对import，alias，bean，beans标签的解析</p>
<pre><code class="java">private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {
   //解析&lt;import&gt;标签
   if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {
      importBeanDefinitionResource(ele);
   }
   //解析&lt;alias&gt;标签 
   else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {
      processAliasRegistration(ele);
   }
   //解析&lt;bean&gt;标签 
   else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {
      processBeanDefinition(ele, delegate);
   }
   //解析&lt;beans&gt;标签 
   else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {
      // recurse
      doRegisterBeanDefinitions(ele);
   }
}</code></pre>
<p>详细的讲解一下对<code>bean</code>标签的解析</p>
<pre><code class="java">protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {
   //步骤一，将Element解析成BeanDefinitionHolder. 
   BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);
   if (bdHolder != null) {
      // 对 bdHolder 进行装饰，针对自定义的属性进行解析，根据自定义标签找到对应的处理器，进行解析（自定义解析方式下面会细说）
      bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);
      try {
         //步骤二，注册解析出来的BeanDefinition.
         BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());
      }
      catch (BeanDefinitionStoreException ex) {
         getReaderContext().error(&quot;Failed to register bean definition with name &#39;&quot; +
               bdHolder.getBeanName() + &quot;&#39;&quot;, ele, ex);
      }
      // Send registration event.
      getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));
   }
}</code></pre>
<p><strong>步骤一</strong>：先介绍下<strong>BeanDefinitionHolder</strong>：这个类是一个工具类，作用是承载<strong>BeanDefinition</strong>数据的</p>
<pre><code class="java">public class BeanDefinitionHolder implements BeanMetadataElement {

   private final BeanDefinition beanDefinition;

   private final String beanName;

   private final String[] aliases;
   ...
}   </code></pre>
<p><code>delegate.parseBeanDefinitionElement(ele);</code>方法中将<code>Element</code>转化为<strong>BeanDefinitionHolder</strong>，并且识别出bean的beanName和aliases(别名)，得到<code>BeanDefinitionHolder</code>其实默认标签的解析就已经结束了</p>
<p>这个方法没有啥复杂逻辑，挺清晰的</p>
<pre><code class="java">public BeanDefinitionHolder parseBeanDefinitionElement(Element ele) {
   return parseBeanDefinitionElement(ele, null);
}

----------------------调用下面这个方法------------------------------

public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) {
        //获取id属性
        String id = ele.getAttribute(ID_ATTRIBUTE);
        //获取name属性
        String nameAttr = ele.getAttribute(NAME_ATTRIBUTE);

        List&lt;String&gt; aliases = new ArrayList&lt;String&gt;();
        //如果name属性配置的不为空
        if (StringUtils.hasLength(nameAttr)) {
            //按,; 分割成字符串数组
            String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS);
            //加到别名的集合里
            aliases.addAll(Arrays.asList(nameArr));
        }
        //把id属性赋值给beanName，如果id为空就在aliases别名的集合里取第一个
        String beanName = id;
        if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) {
            beanName = aliases.remove(0);
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;No XML &#39;id&#39; specified - using &#39;&quot; + beanName +
                        &quot;&#39; as bean name and &quot; + aliases + &quot; as aliases&quot;);
            }
        }

        if (containingBean == null) {
            //检查beanName和aliases是否已经使用，如果使用了就报异常，没使用就加到一个
            checkNameUniqueness(beanName, aliases, ele);
        }
        //创建了一个GenericBeanDefinition类型的BeanDefinition，并对个属性进行填充
        AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean);
        if (beanDefinition != null) {
            if (!StringUtils.hasText(beanName)) {
                try {
                    if (containingBean != null) {
                        beanName = BeanDefinitionReaderUtils.generateBeanName(
                                beanDefinition, this.readerContext.getRegistry(), true);
                    }
                    else {
                        beanName = this.readerContext.generateBeanName(beanDefinition);

                        String beanClassName = beanDefinition.getBeanClassName();
                        if (beanClassName != null &amp;&amp;
                                beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp;
                                !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) {
                            aliases.add(beanClassName);
                        }
                    }
                    if (logger.isDebugEnabled()) {
                        logger.debug(&quot;Neither XML &#39;id&#39; nor &#39;name&#39; specified - &quot; +
                                &quot;using generated bean name [&quot; + beanName + &quot;]&quot;);
                    }
                }
                catch (Exception ex) {
                    error(ex.getMessage(), ele);
                    return null;
                }
            }
            String[] aliasesArray = StringUtils.toStringArray(aliases);
            //创建一个BeanDefinitionHolder返回
            return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray);
        }
        return null;
    }    </code></pre>
<p>得到<code>BeanDefinitionHolder</code>后，剩下的就是注册<code>BeanDefinition</code>了</p>
<p><strong>步骤二</strong>，调用<code>BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry())</code>方法，注册<code>BeanDifinition</code></p>
<pre><code class="java">public static void registerBeanDefinition(
      BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)
      throws BeanDefinitionStoreException {

   // 使用beanName做唯一标识注册
   String beanName = definitionHolder.getBeanName();
   registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());

   // 使用所有别名进行注册
   String[] aliases = definitionHolder.getAliases();
   if (aliases != null) {
      for (String alias : aliases) {
         registry.registerAlias(beanName, alias);
      }
   }
}</code></pre>
<p>通过<strong>beanName</strong>进行注册：<code>definitionHolder.getBeanName()</code>，默认标签和自定义标签都使用这个方法进行<code>BeanDefinition</code>的注册</p>
<pre><code class="java">public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)
      throws BeanDefinitionStoreException {

   Assert.hasText(beanName, &quot;Bean name must not be empty&quot;);
   Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;);
   // beanDefinition是否属于AbstractBeanDefinition的实例
   if (beanDefinition instanceof AbstractBeanDefinition) {
      try {
         // 进行校验，主要是校验methodOverrides与工程方法是否存在以及methodOverrides对应的方法存不存在
         ((AbstractBeanDefinition) beanDefinition).validate();
      }
      catch (BeanDefinitionValidationException ex) {
         throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,
               &quot;Validation of bean definition failed&quot;, ex);
      }
   }

   BeanDefinition oldBeanDefinition;
   // 通过beanName获取BeanDefinition是否已经注册
   oldBeanDefinition = this.beanDefinitionMap.get(beanName);
   //如果已经注册并且不允许覆盖就抛出异常 
   if (oldBeanDefinition != null) {
      if (!isAllowBeanDefinitionOverriding()) {
         throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,
               &quot;Cannot register bean definition [&quot; + beanDefinition + &quot;] for bean &#39;&quot; + beanName +
               &quot;&#39;: There is already [&quot; + oldBeanDefinition + &quot;] bound.&quot;);
      }
      else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) {
         // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE
         if (this.logger.isWarnEnabled()) {
            this.logger.warn(&quot;Overriding user-defined bean definition for bean &#39;&quot; + beanName +
                  &quot;&#39; with a framework-generated bean definition: replacing [&quot; +
                  oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
         }
      }
      else {
         if (this.logger.isInfoEnabled()) {
            this.logger.info(&quot;Overriding bean definition for bean &#39;&quot; + beanName +
                  &quot;&#39;: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
         }
      }
   }
   else {
      //注册BeanDefinition
      this.beanDefinitionNames.add(beanName);
      this.manualSingletonNames.remove(beanName);
      this.frozenBeanDefinitionNames = null;
   }
   this.beanDefinitionMap.put(beanName, beanDefinition);
   // 如果oldBeanDefinition通过上述校验没抛出异常或者beanName是单例
   if (oldBeanDefinition != null || containsSingleton(beanName)) {
      //则更新对应的缓存
      resetBeanDefinition(beanName);
   }
}</code></pre>
<p>通过<code>this.beanDefinitionMap.put(beanName, beanDefinition)</code>这行代码我们就知道，spring使用一个叫<code>beanDefinitionMap</code> 的<strong>ConcurrentHashMap</strong>来存储解析出来的<code>beanDefinition</code></p>
<p><code>Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;(64);</code></p>
<p>通过别名注册的方式跟通过beanName注册的区别不大，仔细看下<code>registry.registerAlias(beanName, alias);</code>方法应该就能了解</p>
<p>spring默认标签的解析大致流程就是这样，细枝末节并没有特别详细的讲解，不过这并不会对我们理解spring的整体流程有阻碍，大家可自行看一下，代码逻辑也不是特别复杂</p>
<h4 id="自定义标签解析"><a href="#自定义标签解析" class="headerlink" title="自定义标签解析"></a>自定义标签解析</h4><p>自定义标签解析的时候会先根据从<code>Element</code>获取到的<code>namespaceUri</code>获取到对应的<code>NamespaceHandler</code>，根据<code>NamespaceHandler</code>进行自定义的解析，以aop为例，我们在配置文件中配置了<code>&lt;aop:aspectj-autoproxy    proxy-target-class=&quot;true&quot;/&gt;</code>，解析会根据<code>aspectj-autoproxy</code>找到对应的处理器，然后调用其<code>parse</code>方法创建</p>
<p><code>delegate.parseCustomElement(root);</code>定义了自定义标签解析的流程</p>
<pre><code class="java">public BeanDefinition parseCustomElement(Element ele) {
   return parseCustomElement(ele, null);
}
-----------------------调用下面这个方法-----------------------
public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) {
    //获取命名空间
    String namespaceUri = getNamespaceURI(ele);
    //步骤一，根据命名空间找到对应的NamespaceHandler
    NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri);
    if (handler == null) {
        error(&quot;Unable to locate Spring NamespaceHandler for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;, ele);
        return null;
    }
    //步骤二，根据自定义的NamespaceHandler进行解析
    return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));
}    </code></pre>
<p><strong>步骤一</strong>：有了<code>namespaceUri</code>我们就可以根据<code>this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri)</code>方法获取对应<code>NamespaceHandler</code>的实例</p>
<pre><code class="java">//DefaultNamespaceHandlerResolver.java

public NamespaceHandler resolve(String namespaceUri) {
   //1,获取到所有的解析器 
   Map&lt;String, Object&gt; handlerMappings = getHandlerMappings();
   //2,根据 namespaceUri 获取到对应的handle
   Object handlerOrClassName = handlerMappings.get(namespaceUri);
   if (handlerOrClassName == null) {
      return null;
   }
   else if (handlerOrClassName instanceof NamespaceHandler) {
      //3,强转返回 
      return (NamespaceHandler) handlerOrClassName;
   }
   else {
      //4,根据handlerOrClassName实例化NamespaceHandler
      String className = (String) handlerOrClassName;
      try {
         Class&lt;?&gt; handlerClass = ClassUtils.forName(className, this.classLoader);
         if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) {
            throw new FatalBeanException(&quot;Class [&quot; + className + &quot;] for namespace [&quot; + namespaceUri +
                  &quot;] does not implement the [&quot; + NamespaceHandler.class.getName() + &quot;] interface&quot;);
         }
         NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass);
         //调用自定义的NamespaceHandler的初始化方法
         namespaceHandler.init();
         //添加到缓存里 
         handlerMappings.put(namespaceUri, namespaceHandler);
         return namespaceHandler;
      }
      catch (ClassNotFoundException ex) {
         throw new FatalBeanException(&quot;NamespaceHandler class [&quot; + className + &quot;] for namespace [&quot; +
               namespaceUri + &quot;] not found&quot;, ex);
      }
      catch (LinkageError err) {
         throw new FatalBeanException(&quot;Invalid NamespaceHandler class [&quot; + className + &quot;] for namespace [&quot; +
               namespaceUri + &quot;]: problem with handler class file or dependent class&quot;, err);
      }
   }
}</code></pre>
<p>这个过程还是比较清晰的，debug一下：</p>
<p><img src="/spring-source-base/3.png" alt></p>
<p>这个<code>handlerMappings.get(namespaceUri)</code>取到是字符串:<code>org.springframework.aop.config.AopNamespaceHandler</code>，接下来按流程走调用<code>BeanUtils.instantiateClass(handlerClass)</code>就是实例化这个类，然后调用它的<code>init</code>方法，然后加到缓存里，然后返回这个<code>NamespaceHandler</code>的实例</p>
<pre><code class="java">public class AopNamespaceHandler extends NamespaceHandlerSupport {

   /**
    * Register the {@link BeanDefinitionParser BeanDefinitionParsers} for the
    * &#39;{@code config}&#39;, &#39;{@code spring-configured}&#39;, &#39;{@code aspectj-autoproxy}&#39;
    * and &#39;{@code scoped-proxy}&#39; tags.
    */
   @Override
   public void init() {
      // In 2.0 XSD as well as in 2.1 XSD.
      registerBeanDefinitionParser(&quot;config&quot;, new ConfigBeanDefinitionParser());
      registerBeanDefinitionParser(&quot;aspectj-autoproxy&quot;, new AspectJAutoProxyBeanDefinitionParser());
      registerBeanDefinitionDecorator(&quot;scoped-proxy&quot;, new ScopedProxyBeanDefinitionDecorator());

      // Only in 2.0 XSD: moved to context namespace as of 2.1
      registerBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser());
   }

}</code></pre>
<p>注册<code>BeanDefinitionParser</code>，就是放到一个叫<code>parsers</code>的<strong>HashMap</strong>里，总共4个<code>config</code>，<code>aspectj-autoproxy</code>，<code>scoped-proxy</code>，<code>spring-configured</code></p>
<pre><code class="java">protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) {
   this.parsers.put(elementName, parser);
}</code></pre>
<p><strong>步骤二</strong>：返回<code>NamespaceHandler</code>实例之后调用它的<code>parse</code>方法</p>
<p><code>handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));</code></p>
<p>我们的配置文件中只有一个自定义标签：<code>&lt;aop:aspectj-autoproxy    proxy-target-class=&quot;true&quot;/&gt;</code></p>
<p>所以<code>findParserForElement(element, parserContext)</code>这个方法根据标签<code>aspectj-autoproxy</code>取到的是取到的<code>BeanDefinition</code>是：<code>AspectJAutoProxyBeanDefinitionParser</code></p>
<pre><code class="java">//NamespaceHandlerSupport.java
//获取到对应解析器的BeanDefinition，调用其parse方法
//比如aspectj-autoproxy标签对应AspectJAutoProxyBeanDefinitionParser
public BeanDefinition parse(Element element, ParserContext parserContext) {
        return findParserForElement(element, parserContext).parse(element, parserContext);
}
--------------------调用下面这个方法-----------------------
private BeanDefinitionParser findParserForElement(Element element, ParserContext parserContext) {
        String localName = parserContext.getDelegate().getLocalName(element);
        BeanDefinitionParser parser = this.parsers.get(localName);
        if (parser == null) {
            parserContext.getReaderContext().fatal(
                    &quot;Cannot locate BeanDefinitionParser for element [&quot; + localName + &quot;]&quot;, element);
        }
        return parser;
}</code></pre>
<p><code>AspectJAutoProxyBeanDefinitionParser</code>实现<code>BeanDefinitionParser</code>接口</p>
<p><code>BeanDefinitionParser</code>接口中只定义了一个<code>parse</code>方法，所有自定义处理器都需要实现<code>BeanDefinitionParser</code>接口进行自定标签的解析</p>
<p>接下来我们看下<code>AspectJAutoProxyBeanDefinitionParser</code>类的<code>parse</code>方法</p>
<pre><code class="java">//AspectJAutoProxyBeanDefinitionParser.java

public BeanDefinition parse(Element element, ParserContext parserContext) {
   //注册 AspectJAnnotationAutoProxyCreator
   AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element);
   extendBeanDefinition(element, parserContext);
   return null;
}</code></pre>
<p>主要的逻辑就在注册<code>AspectJAnnotationAutoProxyCreator</code>这个方法上</p>
<pre><code class="java">public static void registerAspectJAnnotationAutoProxyCreatorIfNecessary(
      ParserContext parserContext, Element sourceElement) {
   //核心逻辑：注册或升级AutoProxyCreator定义beanName为org.springframework.aop.config.internalAutoProxyCreator的BeanDefinition
   BeanDefinition beanDefinition = AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(
         parserContext.getRegistry(), parserContext.extractSource(sourceElement));
   useClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement);
   registerComponentIfNecessary(beanDefinition, parserContext);
}</code></pre>
<p>这个方法调用了<code>registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source)</code>方法</p>
<p>调用的这个方法逻辑也特别清晰</p>
<pre><code class="java">public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, Object source) {
   return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);
}

-----------------------调用下面这个方法---------------------

private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, Object source) {
        Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;);
        //判断BeanDefinitionRegistry是否包含AUTO_PROXY_CREATOR_BEAN_NAME这个静态变量
        if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) {
            //包含说明就注册过，将这个BeanDefinition取出来，然后判断BeanClassName如果不相等，重新BeanClassName为cls.getName()
            BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME);
            if (!cls.getName().equals(apcDefinition.getBeanClassName())) {
                int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName());
                int requiredPriority = findPriorityForClass(cls);
                if (currentPriority &lt; requiredPriority) {
                    apcDefinition.setBeanClassName(cls.getName());
                }
            }
            return null;
        }
        //如果不包含就创建一个RootBeanDefinition，填充属性然后注册
        RootBeanDefinition beanDefinition = new RootBeanDefinition(cls);
        beanDefinition.setSource(source);
        beanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE);
        beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);
        //这个注册方法我们前面讲默认标签注册BeanDefinition的时候讲过，用的一个方法
        registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition);
        return beanDefinition;
}</code></pre>
<p>自定义标签解析注册<code>BeanDefinition</code>的过程我们也讲解完了</p>
<p>现在我们知道了spring是如果解析默认标签和自定义标签的了，整体流程还是比较清晰的</p>
<p>总结一下spring如何加载xml及注册BeanDefinition：</p>
<p>首先将xml文件转化为Element对象，获取命名空间，根据命名空间判断是spring的默认标签还是自定义标签</p>
<ol>
<li><p>默认标签：使用spring的流程进行处理，遇到默认标签首先判断是哪种标签，import，alias，bean，beans标签都有着不同的解析处理逻辑，解析成BeanDefinition之后进行注册，注册的过程就是放到一个<code>ConcurrentHashMap</code>里</p>
</li>
<li><p>自定义标签：使用自定义的命名空间处理器（实现了<code>NamespaceHandler</code>接口）进行解析注册处理</p>
<p>首先根据<code>namespaceUri</code>找到对应的<code>NamespaceHandler</code>处理器</p>
<p>然后调用它的init方法，注册对应自定义标签的解析器（比如<code>aspectj-autoproxy</code>对应<code>AspectJAutoProxyBeanDefinitionParser</code>）</p>
<p>调用<code>NamespaceHandler</code>的<code>parse</code>方法，在这个方法里根据自定义标签找到对应的解析器，调用对应的解析器的<code>parse</code>方法进行注册<code>BeanDefinition</code></p>
</li>
</ol>
<p>本想一篇文章把所有的问题都说明白，发现写完一个问题篇幅就比较长了</p>
<p>那关于spring是如何加载bean的，如何创建bean的，又是如何实现aop操作的，我们下篇分解</p>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/spring-source-base/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/java/">java</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/spring%E6%BA%90%E7%A0%81/">#spring源码</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-05-23T09:08:48.000Z">2019-05-23</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/springboot-rabbitmq/">spring Boot 2.x | 集成 rabbitmq</a></h1>
	

		</header>
		<div class="entry">
			
				<p><em><code>springboot</code>项目中增加入<code>rabbitmq</code>，<code>mq</code>是系统架构设计中的重要一环，<code>mq</code>具有系统间解耦，异步通信，流量削峰等优点，但是引入<code>mq</code>也意味着要增加系统架构的复杂度，需要考虑到<code>mq</code>服务的高可用等问题</em></p>
<h4 id="rabbitmq"><a href="#rabbitmq" class="headerlink" title="rabbitmq"></a>rabbitmq</h4><p><code>RabbitMQ</code>是一个开源的AMQP实现，服务器端用<code>Erlang</code>语言编写，支持多种客户端，如：<code>Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP</code>等，支持<code>AJAX</code>。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗</p>
<p><em><code>AMQP</code>，即 <code>Advanced Message Queuing Protocol</code>，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。<code>AMQP</code> 的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全</em></p>
<h4 id="集成-rabbitmq"><a href="#集成-rabbitmq" class="headerlink" title="集成 rabbitmq"></a>集成 rabbitmq</h4><ol>
<li><p>pom文件引入<code>rabbitmq</code>依赖</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</li>
<li><p><code>application.yml</code>配置文件中增加<code>rabbitmq</code>的相关配置</p>
<pre><code class="yml">spring:
  rabbitmq:
    host: 127.0.0.1
    port: 5672
    username: guest
    password: guest</code></pre>
</li>
<li><p>创建队列</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/5/23 17:29
 * @description: 队列配置类
 */
@Configuration
public class RabbitQueueConfig {

    /**
     * 测试队列名称
     */
    public static final String TEST_QUEUE = &quot;test&quot;;

    @Bean
    public Queue Queue() {
        return new Queue(TEST_QUEUE);
    }
}
</code></pre>
</li>
<li><p>生产者实现</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/5/23 17:32
 * @description: 生产者
 */
@Component
public class TestProduce {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    /**
     * 发送消息
     */
    public void send(){
        System.out.println(&quot;发送消息&quot;);
        rabbitTemplate.convertAndSend(RabbitQueueConfig.TEST_QUEUE,&quot;this is test&quot;);
    }
}</code></pre>
</li>
<li><p>消费者实现</p>
<pre><code class="java">/**
 * @author: chenmingyu
 * @date: 2019/5/23 17:31
 * @description: 消费者
 */
@Component
@RabbitListener(queues = RabbitQueueConfig.TEST_QUEUE)
public class TestConsumer {

    @RabbitHandler
    public void process(String msg) {
        System.out.println(&quot;消费消息  : &quot; + msg);
    }
}</code></pre>
</li>
<li><p>测试</p>
<pre><code class="java">@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringbootRabbitmqApplicationTests {

    @Autowired
    private TestProduce testProduce;

    @Test
    public void contextLoads() {
        testProduce.send();
    }

}</code></pre>
<p>输出</p>
<p><img src="/springboot-rabbitmq/1.png" alt></p>
</li>
</ol>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/springboot-rabbitmq/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/java/">java</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/java/">#java</a>
		
			<a href="/tags/rabbitmq/">#rabbitmq</a>
		
	</div>

		</footer>
	</div>
</article>
	
		
		<article class="post">
	<div class="post-content">
		<header>
			
				<div class="meta">
					<div class="icon">
						
							<i class="fa fa-file"></i>
						
					</div>
					<time datetime="2019-05-16T13:42:07.000Z">2019-05-16</time>
				</div>
			
			
	
		<h1 class="title" data-role="articleTitle"><a href="/springboot/">spring Boot 2.x 入门教程总序</a></h1>
	

		</header>
		<div class="entry">
			
				<p><em>spring Boot 是一个基于spring的轻量级框架，可用于快速构建容易配置的、生产级的、的Spring 应用程序</em></p>
<p><em>本教程为springboot入门教程，过一遍之后基本上<code>springboot</code>日常开发就没有大问题了</em></p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>spring Boot简化了spring的应用开发，采用约定大于配置的方式，提供了很多合理的默认值，即使少量的配置也是采用注解方式配置，省去了复杂的xml配置</p>
<p>spring Boot使用starter来简化依赖项的配置， starter 都使用以下命名约定：<code>spring-boot-starter-xxx</code>，xxx就代表想要引入的服务，如web，redis，mongodb等。系统中如果要提供web支持，只需要引入<code>spring-boot-starter-web</code>即可，<code>spring-boot-starter-web</code>自动提供了web需要的各种jar包及相应的版本。</p>
<h4 id="spring-Boot的优点："><a href="#spring-Boot的优点：" class="headerlink" title="spring Boot的优点："></a>spring Boot的优点：</h4><ol>
<li>约定大于配置，省去了繁琐的xml配置</li>
<li>内置容器，默认使用tomcat</li>
<li>自动装配bean，提供starter来提供对第三方服务的支持</li>
</ol>
<h4 id="本系列教程环境版本："><a href="#本系列教程环境版本：" class="headerlink" title="本系列教程环境版本："></a>本系列教程环境版本：</h4><ul>
<li>ide：idea</li>
<li>springboot：  2.x以上</li>
<li>jdk ： 1.8</li>
<li>maven： 3.53</li>
</ul>
<p>spring Boot 2.x版本需要jdk1.8或者更高版本支持，maven需要3以上；</p>
<h4 id="源码：https-github-com-mingyuHub-springboot"><a href="#源码：https-github-com-mingyuHub-springboot" class="headerlink" title="源码：https://github.com/mingyuHub/springboot"></a>源码：<strong><a href="https://github.com/mingyuHub/springboot" target="_blank" rel="noopener">https://github.com/mingyuHub/springboot</a></strong></h4><h4 id="教程："><a href="#教程：" class="headerlink" title="教程："></a>教程：</h4><ol>
<li><a href="https://chenmingyu.top/springboot-web/"><strong>spring Boot 2.x（一）：第一个web应用 hello world</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-properties/"><strong>spring Boot 2.x（二）：配置文件，自定义配置，多环境配置</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-exception/"><strong>spring Boot 2.x（三）：自定义异常 统一返回值 全局异常处理</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-log/"><strong>spring Boot 2.x（四）：日志管理</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-swagger/"><strong>spring Boot 2.x（五）：swagger2构建api文档</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-thymeleaf/"><strong>spring Boot 2.x（六）：模板引擎 thymeleaf</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-mail/"><strong>spring Boot 2.x（七）：发送文本邮件，HTML邮件，模板邮件</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-async/"><strong>spring Boot 2.x（八）：异步调用，定时任务</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-aop/"><strong>spring Boot 2.x（九）：实现 aop</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-mybatis-annotation/"><strong>spring Boot 2.x（十）：mybatis-注解方式</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-mybatis-xml/"><strong>spring Boot 2.x（十一）：mybatis-xml方式</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-redis/"><strong>spring Boot 2.x（十二）：加入 redis</strong></a></li>
<li><a href="https://chenmingyu.top/springboot-rabbitmq/"><strong>spring Boot 2.x（十三）：加入rabbitmq</strong></a></li>
<li>未完待续…</li>
</ol>

			
		</div>
		<footer class="clearfix">
			
				
				
					<div class="disqus-comment">
						<i class="fa fa-comment"></i><a href="https://chenmingyu.top/springboot/#disqus_thread" class="comment-link"> 评论</a>
					</div>
				
			
			
	<div class="categories">
		<i class="fa fa-folder"></i>
		
			<a href="/categories/java/">java</a>
		
	</div>

			
	<div class="tags">
		<i class="fa fa-tags"></i>
		
			<a href="/tags/springboot/">#springboot</a>
		
	</div>

		</footer>
	</div>
</article>
	

	<nav id="pagination">
	
		<a href="/page/2/" class="prev"><i class="fa fa-chevron-left"></i> 上一页</a>
	
	
		<a href="/page/4/" class="next">下一页 <i class="fa fa-chevron-right"></i></a>
	
</nav>

	
<script>
	(function (disqus_shortname) {
		window.addEventListener('DOMContentLoaded', function () {
			var dsq = document.createElement('script');
			dsq.type = 'text/javascript';
			dsq.async = true;
			dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
			document.getElementsByTagName('head')[0].appendChild(dsq);
		}, false);
	}('dnxbf321'));
</script>



		</div>
		
	</div>
</div>

<footer id="footer">
	<div class="center">
		&copy; 2022
		
			明羽
		.
		&nbsp;&nbsp;
		Blog generated by <a href="http://hexo.io" target="_blank" rel="noopener">hexo</a>
	</div>
</footer>

<script src="/bower_components/jquery/dist/jquery.min.js"></script>
<script src="/js/header-animate.js"></script>


	<script src="/js/title-animate.js"></script>


<script src="/bower_components/jquery_lazyload/jquery.lazyload.js"></script>
<script>
	$('img.lazy').lazyload();
</script>

	<script src="/bower_components/fancybox/source/jquery.fancybox.pack.js"></script>
	<script>
		$('.fancybox').fancybox();
	</script>




</body>
</html>